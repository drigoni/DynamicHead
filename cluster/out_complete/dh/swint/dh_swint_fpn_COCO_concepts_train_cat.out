
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX 
Date:  gio 3 nov 2022, 14.34.49, CET
Directory:  /ceph/hpc/home/eudavider/repository/DynamicHead
Nodelist:  gn[06,08]
Number of nodes:  2
Ntasks per node:  1
NGPUs per node:  4
CUDA_VISIBLE_DEVICES:  0,1,2,3
TORCH_DEVICE_COUNT:  4
SLURM_MASTER_PORT:  15680
SLURM_MASTER_NODE:  gn06
SLURM_MASTER_ADDR:  gn06
SLURM_MASTER_URL:  tcp://gn06:15680
--------------------------------------------- 
MODEL_NUM_GPUS:  4
MODEL_NUM_MACHINES:  2
MODEL_BATCH_SIZE:  40
MODEL_MAX_ITER:  72000
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX 

srun: error: WARNING: Multiple leaf switches contain nodes: gn[01-60]
[nltk_data] Downloading package omw-1.4 to
[nltk_data]     /ceph/hpc/home/eudavider/nltk_data...
[nltk_data]   Package omw-1.4 is already up-to-date!
[nltk_data] Downloading package wordnet to
[nltk_data]     /ceph/hpc/home/eudavider/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
Command Line Args: Namespace(config_file='./configs/COCO/dh/swint/dh_swint_fpn_COCO_concepts_train_cat.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=2, machine_rank=0, dist_url='tcp://gn06:15680', opts=['SOLVER.IMS_PER_BATCH', '40', 'SOLVER.MAX_ITER', '72000'])
[nltk_data] Downloading package omw-1.4 to
[nltk_data]     /ceph/hpc/home/eudavider/nltk_data...
[nltk_data]   Package omw-1.4 is already up-to-date!
[nltk_data] Downloading package wordnet to
[nltk_data]     /ceph/hpc/home/eudavider/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
Command Line Args: Namespace(config_file='./configs/COCO/dh/swint/dh_swint_fpn_COCO_concepts_train_cat.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=2, machine_rank=1, dist_url='tcp://gn06:15680', opts=['SOLVER.IMS_PER_BATCH', '40', 'SOLVER.MAX_ITER', '72000'])
Loading config ./configs/COCO/dh/swint/../base_dh_COCO_concepts.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config ./configs/COCO/dh/swint/../base_dh_COCO_concepts.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config ./configs/COCO/dh/swint/../base_dh_COCO_concepts.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config ./configs/COCO/dh/swint/../base_dh_COCO_concepts.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config ./configs/COCO/dh/swint/../base_dh_COCO_concepts.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config ./configs/COCO/dh/swint/../base_dh_COCO_concepts.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config ./configs/COCO/dh/swint/../base_dh_COCO_concepts.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config ./configs/COCO/dh/swint/../base_dh_COCO_concepts.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
[32m[11/03 14:36:11 detectron2]: [0mRank of current process: 0. World size: 8
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272164809/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[32m[11/03 14:36:16 detectron2]: [0mEnvironment info:
----------------------  ------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]
numpy                   1.23.1
detectron2              0.6 @/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA A100-SXM4-40GB (arch=8.0)
Driver version          510.47.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.2.0
torchvision             0.11.0 @/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     Not found
----------------------  ------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[32m[11/03 14:36:16 detectron2]: [0mCommand line arguments: Namespace(config_file='./configs/COCO/dh/swint/dh_swint_fpn_COCO_concepts_train_cat.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=2, machine_rank=0, dist_url='tcp://gn06:15680', opts=['SOLVER.IMS_PER_BATCH', '40', 'SOLVER.MAX_ITER', '72000'])
[32m[11/03 14:36:16 detectron2]: [0mContents of args.config_file=./configs/COCO/dh/swint/dh_swint_fpn_COCO_concepts_train_cat.yaml:
_BASE_: "../base_dh_COCO_concepts.yaml"
MODEL:
  ATSS:
    NUM_CONVS: 2
CONCEPT:
  CONCEPT_FUSION: "cat" # ["cat", "mul", "add", "zeros"]
OUTPUT_DIR: "./results/COCO/dh/dh_swint_fpn_COCO_concepts_cat/"
[32m[11/03 14:36:17 detectron2]: [0mRunning with full config:
CONCEPT:
  ACTIVATE_CONCEPT_GENERATOR: true
  APPLY_CONDITION: true
  APPLY_CONDITION_FROM_FILE: false
  CONCEPT_FUSION: cat
  DEPTH: 1
  EXTERNAL_CONCEPTS_FOLDER: ./datasets/ewiser_concepts_COCO_valid/
  FILE: ./concept/coco_to_synset.json
  ONLY_NAME: true
  UNIQUE: true
  VOCAB: ./concept/vocab.json
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 16
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_tuning_val
  TRAIN:
  - coco_2017_tuning_train
DEEPSETS:
  AGGREGATE: sum
  EMB: wordnet
  EMB_DIM: 150
  FILE: ./concept/wn30_holE_500_150_0.1_0.2_embeddings.pickle
  FREEZE: true
  MLP1_LAYERS:
  - 150
  - 150
  MLP1_OUTPUT_DIM: 150
  MLP2_LAYERS:
  - 150
  OUTPUT_DIM: 256
EVALUATOR_TYPE: default
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 640
  - 672
  - 704
  - 736
  - 768
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - 1.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.5
    SIZES:
    - - 64
    - - 128
    - - 256
    - - 512
    - - 1024
  ATSS:
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CHANNELS: 256
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    INFERENCE_TH: 0.05
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_TH: 0.6
    NUM_CLASSES: 80
    NUM_CONVS: 2
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_GN: true
  BACKBONE:
    FREEZE_AT: -1
    NAME: build_retinanet_swint_fpn_dyhead_backbone
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - stage3
    - stage4
    - stage5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: CATSS
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWINT:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    MLP_RATIO: 4
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - stage3
    - stage4
    - stage5
    OUT_NORM: true
    VERSION: 1
    WINDOW_SIZE: 7
  WEIGHTS: ./pretrained/dyhead_swint_atss_fpn_2x_ms.pth
OUTPUT_DIR: ./results/COCO/dh/dh_swint_fpn_COCO_concepts_cat/
SEED: 2022
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.0001
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 40
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 72000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 60000
  - 80000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: 0.05
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[32m[11/03 14:36:17 detectron2]: [0mFull config saved to ./results/COCO/dh/dh_swint_fpn_COCO_concepts_cat/config.yaml
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272164809/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272164809/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272164809/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272164809/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272164809/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272164809/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: drigoni. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.4
wandb: Run data is saved locally in /ceph/hpc/scratch/user/eudavider/repository/DynamicHead/wandb/run-20221103_143620-ee6odywa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sponge-449
wandb: ⭐️ View project at https://wandb.ai/drigoni/CATSS
wandb: 🚀 View run at https://wandb.ai/drigoni/CATSS/runs/ee6odywa
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272164809/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Load concept for each category. 
Loading pre-trained concepts embeddings. 
Vocab initialization with 0/82115 elements not found. 
[32m[11/03 14:41:29 d2.engine.defaults]: [0mModel:
CATSS(
  (backbone): DyHead(
    (backbone): FPN(
      (fpn_lateral3): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))
      (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (fpn_lateral4): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))
      (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (fpn_lateral5): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))
      (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (top_block): LastLevelP6P7(
        (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      )
      (bottom_up): SwinTransformer(
        (patch_embed): PatchEmbed(
          (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (pos_drop): Dropout(p=0.0, inplace=False)
        (layers): ModuleList(
          (0): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=96, out_features=288, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=96, out_features=96, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.018)
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=96, out_features=384, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=384, out_features=96, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=384, out_features=192, bias=False)
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            )
          )
          (1): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.036)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=192, out_features=576, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=192, out_features=192, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.055)
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=192, out_features=768, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=768, out_features=192, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=768, out_features=384, bias=False)
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            )
          )
          (2): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.073)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.091)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (2): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.109)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (3): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.127)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (4): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.145)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (5): SwinTransformerBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=384, out_features=1152, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=384, out_features=384, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.164)
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=384, out_features=1536, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=1536, out_features=384, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
            (downsample): PatchMerging(
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
            )
          )
          (3): BasicLayer(
            (blocks): ModuleList(
              (0): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.182)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
              (1): SwinTransformerBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (qkv): Linear(in_features=768, out_features=2304, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=768, out_features=768, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): DropPath(drop_prob=0.200)
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=768, out_features=3072, bias=True)
                  (act): GELU()
                  (fc2): Linear(in_features=3072, out_features=768, bias=True)
                  (drop): Dropout(p=0.0, inplace=False)
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (dyhead_tower): Sequential(
      (0): DyConv(
        (DyConv): ModuleList(
          (0): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
          (1): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
          (2): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=2, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
        )
        (AttnConv): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
          (2): ReLU(inplace=True)
        )
        (h_sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
        (relu): DYReLU(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=64, out_features=1024, bias=True)
            (3): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
        )
        (offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (1): DyConv(
        (DyConv): ModuleList(
          (0): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
          (1): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
          (2): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=2, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
        )
        (AttnConv): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
          (2): ReLU(inplace=True)
        )
        (h_sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
        (relu): DYReLU(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=64, out_features=1024, bias=True)
            (3): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
        )
        (offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): DyConv(
        (DyConv): ModuleList(
          (0): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
          (1): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
          (2): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=2, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
        )
        (AttnConv): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
          (2): ReLU(inplace=True)
        )
        (h_sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
        (relu): DYReLU(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=64, out_features=1024, bias=True)
            (3): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
        )
        (offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): DyConv(
        (DyConv): ModuleList(
          (0): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
          (1): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
          (2): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=2, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
        )
        (AttnConv): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
          (2): ReLU(inplace=True)
        )
        (h_sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
        (relu): DYReLU(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=64, out_features=1024, bias=True)
            (3): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
        )
        (offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (4): DyConv(
        (DyConv): ModuleList(
          (0): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
          (1): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
          (2): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=2, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
        )
        (AttnConv): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
          (2): ReLU(inplace=True)
        )
        (h_sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
        (relu): DYReLU(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=64, out_features=1024, bias=True)
            (3): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
        )
        (offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (5): DyConv(
        (DyConv): ModuleList(
          (0): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
          (1): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
          (2): Conv3x3Norm(
            (conv): ModulatedDeformConv(in_channels=256, out_channels=256, kernel_size=(3, 3), stride=2, dilation=1, padding=1, groups=1, deformable_groups=1, bias=True)
            (bn): GroupNorm(16, 256, eps=1e-05, affine=True)
          )
        )
        (AttnConv): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
          (2): ReLU(inplace=True)
        )
        (h_sigmoid): h_sigmoid(
          (relu): ReLU6(inplace=True)
        )
        (relu): DYReLU(
          (avg_pool): AdaptiveAvgPool2d(output_size=1)
          (fc): Sequential(
            (0): Linear(in_features=256, out_features=64, bias=True)
            (1): ReLU(inplace=True)
            (2): Linear(in_features=64, out_features=1024, bias=True)
            (3): h_sigmoid(
              (relu): ReLU6(inplace=True)
            )
          )
        )
        (offset): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (head): CATSSHead(
    (cls_tower): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): GroupNorm(32, 512, eps=1e-05, affine=True)
      (2): ReLU()
      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): GroupNorm(32, 512, eps=1e-05, affine=True)
      (5): ReLU()
    )
    (bbox_tower): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): GroupNorm(32, 512, eps=1e-05, affine=True)
      (2): ReLU()
      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (4): GroupNorm(32, 512, eps=1e-05, affine=True)
      (5): ReLU()
    )
    (cls_logits): Conv2d(512, 80, kernel_size=(1, 1), stride=(1, 1))
    (bbox_pred): Conv2d(512, 4, kernel_size=(1, 1), stride=(1, 1))
    (centerness): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
    (scales): ModuleList(
      (0): Scale()
      (1): Scale()
      (2): Scale()
      (3): Scale()
      (4): Scale()
    )
  )
  (centerness_loss_func): BCEWithLogitsLoss()
  (classification_loss_func): SigmoidFocalLoss(gamma=2.0, alpha=0.25)
  (anchor_generator): DefaultAnchorGenerator(
    (cell_anchors): BufferList()
  )
  (concept_net): ConceptNet(
    (concept_vocab): Vocab()
    (concept_emb): Embedding(82115, 150)
    (deepset): _DeepSets(
      (mlp1): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=150, out_features=150, bias=True)
          (1): Linear(in_features=150, out_features=150, bias=True)
          (2): Linear(in_features=150, out_features=150, bias=True)
        )
      )
      (mlp2): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=150, out_features=150, bias=True)
          (1): Linear(in_features=150, out_features=256, bias=True)
        )
      )
    )
  )
)
[32m[11/03 14:41:42 d2.data.datasets.coco]: [0mLoading datasets/tuning_coco/annotations/tuning_instances_train2017.json takes 13.42 seconds.
[32m[11/03 14:41:43 d2.data.datasets.coco]: [0mLoaded 113287 images in COCO format from datasets/tuning_coco/annotations/tuning_instances_train2017.json
[32m[11/03 14:41:48 d2.data.build]: [0mRemoved 977 images with no usable annotations. 112310 images left.
[32m[11/03 14:41:52 d2.data.build]: [0mDistribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 246754       |   bicycle    | 6793         |      car      | 41810        |
|  motorcycle   | 8317         |   airplane   | 4913         |      bus      | 5830         |
|     train     | 4362         |    truck     | 9530         |     boat      | 10105        |
| traffic light | 12259        | fire hydrant | 1781         |   stop sign   | 1901         |
| parking meter | 1249         |    bench     | 9469         |     bird      | 9996         |
|      cat      | 4573         |     dog      | 5255         |     horse     | 6260         |
|     sheep     | 8875         |     cow      | 7721         |   elephant    | 5221         |
|     bear      | 1241         |    zebra     | 5041         |    giraffe    | 4916         |
|   backpack    | 8316         |   umbrella   | 10787        |    handbag    | 11816        |
|      tie      | 6162         |   suitcase   | 5841         |    frisbee    | 2581         |
|     skis      | 6333         |  snowboard   | 2597         |  sports ball  | 6052         |
|     kite      | 8489         | baseball bat | 3123         | baseball gl.. | 3578         |
|  skateboard   | 5325         |  surfboard   | 5872         | tennis racket | 4595         |
|    bottle     | 23085        |  wine glass  | 7455         |      cup      | 19785        |
|     fork      | 5265         |    knife     | 7469         |     spoon     | 5907         |
|     bowl      | 13643        |    banana    | 8796         |     apple     | 5586         |
|   sandwich    | 4170         |    orange    | 6021         |   broccoli    | 6943         |
|    carrot     | 7441         |   hot dog    | 2780         |     pizza     | 5581         |
|     donut     | 6728         |     cake     | 5985         |     chair     | 36370        |
|     couch     | 5551         | potted plant | 8253         |      bed      | 4005         |
| dining table  | 15055        |    toilet    | 3980         |      tv       | 5563         |
|    laptop     | 4762         |    mouse     | 2179         |    remote     | 5450         |
|   keyboard    | 2735         |  cell phone  | 6132         |   microwave   | 1603         |
|     oven      | 3195         |   toaster    | 216          |     sink      | 5413         |
| refrigerator  | 2515         |     book     | 23082        |     clock     | 6061         |
|     vase      | 6271         |   scissors   | 1344         |  teddy bear   | 4538         |
|  hair drier   | 193          |  toothbrush  | 1870         |               |              |
|     total     | 814615       |              |              |               |              |[0m
[32m[11/03 14:41:52 d2.data.common]: [0mSerializing 112310 elements to byte tensors and concatenating them all ...
[32m[11/03 14:41:54 d2.data.common]: [0mSerialized dataset takes 432.33 MiB
[5m[31mWARNING[0m [32m[11/03 14:41:55 d2.solver.build]: [0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.
[32m[11/03 14:41:56 fvcore.common.checkpoint]: [0m[Checkpointer] Loading from ./results/COCO/dh/dh_swint_fpn_COCO_concepts_cat/model_0059999.pth ...
[32m[11/03 14:43:21 fvcore.common.checkpoint]: [0mLoading optimizer from ./results/COCO/dh/dh_swint_fpn_COCO_concepts_cat/model_0059999.pth ...
[32m[11/03 14:43:21 fvcore.common.checkpoint]: [0mLoading scheduler from ./results/COCO/dh/dh_swint_fpn_COCO_concepts_cat/model_0059999.pth ...
[32m[11/03 14:43:21 d2.engine.train_loop]: [0mStarting training from iteration 60000
Load concept for each category. 
Loading pre-trained concepts embeddings. 
Vocab initialization with 0/82115 elements not found. 
Load concept for each category. 
Loading pre-trained concepts embeddings. 
Vocab initialization with 0/82115 elements not found. 
Load concept for each category. 
Loading pre-trained concepts embeddings. 
Vocab initialization with 0/82115 elements not found. 
Load concept for each category. 
Loading pre-trained concepts embeddings. 
Vocab initialization with 0/82115 elements not found. 
Load concept for each category. 
Loading pre-trained concepts embeddings. 
Vocab initialization with 0/82115 elements not found. 
Load concept for each category. 
Loading pre-trained concepts embeddings. 
Vocab initialization with 0/82115 elements not found. 
Load concept for each category. 
Loading pre-trained concepts embeddings. 
Vocab initialization with 0/82115 elements not found. 
/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  max_size = (max_size + (stride - 1)) // stride * stride
/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  max_size = (max_size + (stride - 1)) // stride * stride
/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  max_size = (max_size + (stride - 1)) // stride * stride
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/nn/functional.py:3847: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/nn/functional.py:3847: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/nn/functional.py:3847: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  max_size = (max_size + (stride - 1)) // stride * stride
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/nn/functional.py:3847: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  max_size = (max_size + (stride - 1)) // stride * stride
/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  max_size = (max_size + (stride - 1)) // stride * stride
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/nn/functional.py:3847: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/nn/functional.py:3847: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  max_size = (max_size + (stride - 1)) // stride * stride
/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  max_size = (max_size + (stride - 1)) // stride * stride
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/nn/functional.py:3847: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/nn/functional.py:3847: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
[W reducer.cpp:1303] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1303] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1303] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1303] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1303] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1303] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1303] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[W reducer.cpp:1303] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[32m[11/03 14:44:46 d2.utils.events]: [0m eta: 4:18:25  iter: 60019  total_loss: 1.096  loss_cls: 0.1762  loss_ctr: 0.6052  loss_box_reg: 0.3092  time: 1.2836  data_time: 2.7750  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:45:11 d2.utils.events]: [0m eta: 4:16:56  iter: 60039  total_loss: 1.104  loss_cls: 0.1907  loss_ctr: 0.6037  loss_box_reg: 0.31  time: 1.2753  data_time: 0.0131  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:45:37 d2.utils.events]: [0m eta: 4:16:22  iter: 60059  total_loss: 1.063  loss_cls: 0.172  loss_ctr: 0.6026  loss_box_reg: 0.2959  time: 1.2773  data_time: 0.0138  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:46:02 d2.utils.events]: [0m eta: 4:13:38  iter: 60079  total_loss: 1.079  loss_cls: 0.1707  loss_ctr: 0.6031  loss_box_reg: 0.3042  time: 1.2712  data_time: 0.0137  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:46:28 d2.utils.events]: [0m eta: 4:13:00  iter: 60099  total_loss: 1.097  loss_cls: 0.1776  loss_ctr: 0.6052  loss_box_reg: 0.3074  time: 1.2705  data_time: 0.0110  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:46:53 d2.utils.events]: [0m eta: 4:12:19  iter: 60119  total_loss: 1.072  loss_cls: 0.1749  loss_ctr: 0.6015  loss_box_reg: 0.2973  time: 1.2700  data_time: 0.0112  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:47:18 d2.utils.events]: [0m eta: 4:11:53  iter: 60139  total_loss: 1.071  loss_cls: 0.1639  loss_ctr: 0.603  loss_box_reg: 0.3045  time: 1.2700  data_time: 0.0125  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:47:44 d2.utils.events]: [0m eta: 4:11:28  iter: 60159  total_loss: 1.057  loss_cls: 0.1605  loss_ctr: 0.602  loss_box_reg: 0.2871  time: 1.2708  data_time: 0.0143  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:48:10 d2.utils.events]: [0m eta: 4:11:59  iter: 60179  total_loss: 1.062  loss_cls: 0.1683  loss_ctr: 0.6038  loss_box_reg: 0.2966  time: 1.2727  data_time: 0.0138  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:48:35 d2.utils.events]: [0m eta: 4:11:02  iter: 60199  total_loss: 1.068  loss_cls: 0.1691  loss_ctr: 0.6036  loss_box_reg: 0.2948  time: 1.2724  data_time: 0.0139  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:49:00 d2.utils.events]: [0m eta: 4:10:27  iter: 60219  total_loss: 1.083  loss_cls: 0.1773  loss_ctr: 0.6026  loss_box_reg: 0.2996  time: 1.2706  data_time: 0.0131  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:49:26 d2.utils.events]: [0m eta: 4:09:16  iter: 60239  total_loss: 1.062  loss_cls: 0.1662  loss_ctr: 0.602  loss_box_reg: 0.2951  time: 1.2690  data_time: 0.0109  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:49:51 d2.utils.events]: [0m eta: 4:09:21  iter: 60259  total_loss: 1.097  loss_cls: 0.1742  loss_ctr: 0.6078  loss_box_reg: 0.3157  time: 1.2695  data_time: 0.0122  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:50:16 d2.utils.events]: [0m eta: 4:08:34  iter: 60279  total_loss: 1.063  loss_cls: 0.1685  loss_ctr: 0.6043  loss_box_reg: 0.2919  time: 1.2688  data_time: 0.0129  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:50:42 d2.utils.events]: [0m eta: 4:08:30  iter: 60299  total_loss: 1.075  loss_cls: 0.1724  loss_ctr: 0.603  loss_box_reg: 0.3011  time: 1.2690  data_time: 0.0133  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:51:07 d2.utils.events]: [0m eta: 4:07:44  iter: 60319  total_loss: 1.052  loss_cls: 0.1636  loss_ctr: 0.6022  loss_box_reg: 0.2907  time: 1.2696  data_time: 0.0118  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:51:33 d2.utils.events]: [0m eta: 4:07:26  iter: 60339  total_loss: 1.07  loss_cls: 0.1698  loss_ctr: 0.6041  loss_box_reg: 0.3008  time: 1.2705  data_time: 0.0111  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:51:59 d2.utils.events]: [0m eta: 4:06:53  iter: 60359  total_loss: 1.077  loss_cls: 0.1722  loss_ctr: 0.602  loss_box_reg: 0.2952  time: 1.2702  data_time: 0.0120  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:52:24 d2.utils.events]: [0m eta: 4:06:36  iter: 60379  total_loss: 1.044  loss_cls: 0.1598  loss_ctr: 0.6028  loss_box_reg: 0.2925  time: 1.2703  data_time: 0.0119  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:52:50 d2.utils.events]: [0m eta: 4:06:10  iter: 60399  total_loss: 1.05  loss_cls: 0.161  loss_ctr: 0.6012  loss_box_reg: 0.2834  time: 1.2707  data_time: 0.0136  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:53:15 d2.utils.events]: [0m eta: 4:05:36  iter: 60419  total_loss: 1.069  loss_cls: 0.1665  loss_ctr: 0.6019  loss_box_reg: 0.295  time: 1.2704  data_time: 0.0122  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:53:41 d2.utils.events]: [0m eta: 4:05:19  iter: 60439  total_loss: 1.058  loss_cls: 0.1679  loss_ctr: 0.6038  loss_box_reg: 0.2895  time: 1.2711  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:54:07 d2.utils.events]: [0m eta: 4:04:54  iter: 60459  total_loss: 1.055  loss_cls: 0.1656  loss_ctr: 0.6029  loss_box_reg: 0.287  time: 1.2714  data_time: 0.0136  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:54:33 d2.utils.events]: [0m eta: 4:05:05  iter: 60479  total_loss: 1.043  loss_cls: 0.1601  loss_ctr: 0.6021  loss_box_reg: 0.2829  time: 1.2721  data_time: 0.0123  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:54:58 d2.utils.events]: [0m eta: 4:04:47  iter: 60499  total_loss: 1.067  loss_cls: 0.1659  loss_ctr: 0.6025  loss_box_reg: 0.2973  time: 1.2726  data_time: 0.0141  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:55:24 d2.utils.events]: [0m eta: 4:04:21  iter: 60519  total_loss: 1.056  loss_cls: 0.1642  loss_ctr: 0.6033  loss_box_reg: 0.2921  time: 1.2733  data_time: 0.0129  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:55:50 d2.utils.events]: [0m eta: 4:03:53  iter: 60539  total_loss: 1.046  loss_cls: 0.1587  loss_ctr: 0.6028  loss_box_reg: 0.2873  time: 1.2731  data_time: 0.0118  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:56:15 d2.utils.events]: [0m eta: 4:03:23  iter: 60559  total_loss: 1.069  loss_cls: 0.1672  loss_ctr: 0.6034  loss_box_reg: 0.2921  time: 1.2731  data_time: 0.0154  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:56:40 d2.utils.events]: [0m eta: 4:02:55  iter: 60579  total_loss: 1.072  loss_cls: 0.1652  loss_ctr: 0.6028  loss_box_reg: 0.3004  time: 1.2727  data_time: 0.0131  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:57:06 d2.utils.events]: [0m eta: 4:02:58  iter: 60599  total_loss: 1.058  loss_cls: 0.1703  loss_ctr: 0.6008  loss_box_reg: 0.2901  time: 1.2730  data_time: 0.0116  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:57:31 d2.utils.events]: [0m eta: 4:02:04  iter: 60619  total_loss: 1.071  loss_cls: 0.1676  loss_ctr: 0.6033  loss_box_reg: 0.2972  time: 1.2725  data_time: 0.0142  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:57:57 d2.utils.events]: [0m eta: 4:01:37  iter: 60639  total_loss: 1.057  loss_cls: 0.1627  loss_ctr: 0.6045  loss_box_reg: 0.298  time: 1.2724  data_time: 0.0118  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:58:22 d2.utils.events]: [0m eta: 4:01:11  iter: 60659  total_loss: 1.062  loss_cls: 0.1679  loss_ctr: 0.6036  loss_box_reg: 0.2947  time: 1.2723  data_time: 0.0129  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:58:48 d2.utils.events]: [0m eta: 4:00:46  iter: 60679  total_loss: 1.067  loss_cls: 0.1677  loss_ctr: 0.6009  loss_box_reg: 0.2982  time: 1.2722  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:59:13 d2.utils.events]: [0m eta: 4:00:22  iter: 60699  total_loss: 1.072  loss_cls: 0.1672  loss_ctr: 0.6033  loss_box_reg: 0.3018  time: 1.2724  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 14:59:39 d2.utils.events]: [0m eta: 4:00:06  iter: 60719  total_loss: 1.049  loss_cls: 0.1627  loss_ctr: 0.6033  loss_box_reg: 0.2866  time: 1.2731  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:00:06 d2.utils.events]: [0m eta: 4:00:21  iter: 60739  total_loss: 1.042  loss_cls: 0.1599  loss_ctr: 0.6022  loss_box_reg: 0.2797  time: 1.2742  data_time: 0.0123  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:00:31 d2.utils.events]: [0m eta: 3:59:56  iter: 60759  total_loss: 1.076  loss_cls: 0.1709  loss_ctr: 0.6032  loss_box_reg: 0.2952  time: 1.2740  data_time: 0.0136  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:00:56 d2.utils.events]: [0m eta: 3:59:20  iter: 60779  total_loss: 1.048  loss_cls: 0.1635  loss_ctr: 0.6023  loss_box_reg: 0.2853  time: 1.2737  data_time: 0.0136  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:01:22 d2.utils.events]: [0m eta: 3:59:03  iter: 60799  total_loss: 1.041  loss_cls: 0.1549  loss_ctr: 0.6021  loss_box_reg: 0.2809  time: 1.2740  data_time: 0.0142  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:01:48 d2.utils.events]: [0m eta: 3:58:22  iter: 60819  total_loss: 1.069  loss_cls: 0.1709  loss_ctr: 0.605  loss_box_reg: 0.2958  time: 1.2739  data_time: 0.0158  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:02:14 d2.utils.events]: [0m eta: 3:58:09  iter: 60839  total_loss: 1.06  loss_cls: 0.167  loss_ctr: 0.6021  loss_box_reg: 0.2901  time: 1.2741  data_time: 0.0154  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:02:39 d2.utils.events]: [0m eta: 3:57:44  iter: 60859  total_loss: 1.043  loss_cls: 0.1626  loss_ctr: 0.6014  loss_box_reg: 0.2824  time: 1.2744  data_time: 0.0133  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:03:05 d2.utils.events]: [0m eta: 3:57:18  iter: 60879  total_loss: 1.072  loss_cls: 0.1668  loss_ctr: 0.6041  loss_box_reg: 0.2974  time: 1.2746  data_time: 0.0146  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:03:31 d2.utils.events]: [0m eta: 3:56:55  iter: 60899  total_loss: 1.059  loss_cls: 0.1738  loss_ctr: 0.6031  loss_box_reg: 0.2881  time: 1.2747  data_time: 0.0152  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:03:56 d2.utils.events]: [0m eta: 3:56:14  iter: 60919  total_loss: 1.05  loss_cls: 0.1578  loss_ctr: 0.6033  loss_box_reg: 0.2876  time: 1.2741  data_time: 0.0119  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:04:21 d2.utils.events]: [0m eta: 3:55:37  iter: 60939  total_loss: 1.043  loss_cls: 0.1527  loss_ctr: 0.6023  loss_box_reg: 0.2812  time: 1.2738  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:04:47 d2.utils.events]: [0m eta: 3:55:17  iter: 60959  total_loss: 1.043  loss_cls: 0.1636  loss_ctr: 0.6019  loss_box_reg: 0.2808  time: 1.2738  data_time: 0.0119  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:05:12 d2.utils.events]: [0m eta: 3:55:02  iter: 60979  total_loss: 1.063  loss_cls: 0.1622  loss_ctr: 0.6046  loss_box_reg: 0.2981  time: 1.2740  data_time: 0.0124  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:05:38 d2.utils.events]: [0m eta: 3:54:45  iter: 60999  total_loss: 1.071  loss_cls: 0.1629  loss_ctr: 0.6048  loss_box_reg: 0.3018  time: 1.2742  data_time: 0.0129  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:06:04 d2.utils.events]: [0m eta: 3:54:17  iter: 61019  total_loss: 1.055  loss_cls: 0.1663  loss_ctr: 0.6028  loss_box_reg: 0.2849  time: 1.2742  data_time: 0.0147  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:06:29 d2.utils.events]: [0m eta: 3:53:55  iter: 61039  total_loss: 1.068  loss_cls: 0.1704  loss_ctr: 0.6032  loss_box_reg: 0.2965  time: 1.2743  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:06:55 d2.utils.events]: [0m eta: 3:53:28  iter: 61059  total_loss: 1.033  loss_cls: 0.1594  loss_ctr: 0.6006  loss_box_reg: 0.2752  time: 1.2745  data_time: 0.0133  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:07:21 d2.utils.events]: [0m eta: 3:53:00  iter: 61079  total_loss: 1.066  loss_cls: 0.1697  loss_ctr: 0.6032  loss_box_reg: 0.2946  time: 1.2743  data_time: 0.0165  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:07:46 d2.utils.events]: [0m eta: 3:52:34  iter: 61099  total_loss: 1.058  loss_cls: 0.1649  loss_ctr: 0.6027  loss_box_reg: 0.2886  time: 1.2741  data_time: 0.0139  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:08:11 d2.utils.events]: [0m eta: 3:52:09  iter: 61119  total_loss: 1.044  loss_cls: 0.1608  loss_ctr: 0.6015  loss_box_reg: 0.2816  time: 1.2740  data_time: 0.0134  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:08:37 d2.utils.events]: [0m eta: 3:51:33  iter: 61139  total_loss: 1.054  loss_cls: 0.1632  loss_ctr: 0.6036  loss_box_reg: 0.2861  time: 1.2738  data_time: 0.0119  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:09:02 d2.utils.events]: [0m eta: 3:51:05  iter: 61159  total_loss: 1.061  loss_cls: 0.1679  loss_ctr: 0.6018  loss_box_reg: 0.2896  time: 1.2737  data_time: 0.0119  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:09:28 d2.utils.events]: [0m eta: 3:50:30  iter: 61179  total_loss: 1.053  loss_cls: 0.1652  loss_ctr: 0.6032  loss_box_reg: 0.2851  time: 1.2736  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:09:53 d2.utils.events]: [0m eta: 3:50:14  iter: 61199  total_loss: 1.056  loss_cls: 0.1674  loss_ctr: 0.6021  loss_box_reg: 0.284  time: 1.2737  data_time: 0.0118  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:10:18 d2.utils.events]: [0m eta: 3:49:40  iter: 61219  total_loss: 1.045  loss_cls: 0.1586  loss_ctr: 0.603  loss_box_reg: 0.2825  time: 1.2733  data_time: 0.0131  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:10:43 d2.utils.events]: [0m eta: 3:49:13  iter: 61239  total_loss: 1.05  loss_cls: 0.1557  loss_ctr: 0.6037  loss_box_reg: 0.2911  time: 1.2729  data_time: 0.0120  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:11:09 d2.utils.events]: [0m eta: 3:48:47  iter: 61259  total_loss: 1.049  loss_cls: 0.1611  loss_ctr: 0.6012  loss_box_reg: 0.2881  time: 1.2730  data_time: 0.0162  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:11:34 d2.utils.events]: [0m eta: 3:48:21  iter: 61279  total_loss: 1.056  loss_cls: 0.1626  loss_ctr: 0.6024  loss_box_reg: 0.297  time: 1.2728  data_time: 0.0128  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:12:00 d2.utils.events]: [0m eta: 3:47:46  iter: 61299  total_loss: 1.054  loss_cls: 0.1635  loss_ctr: 0.6006  loss_box_reg: 0.2836  time: 1.2727  data_time: 0.0116  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:12:26 d2.utils.events]: [0m eta: 3:47:30  iter: 61319  total_loss: 1.037  loss_cls: 0.1561  loss_ctr: 0.6009  loss_box_reg: 0.2816  time: 1.2729  data_time: 0.0149  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:12:52 d2.utils.events]: [0m eta: 3:47:05  iter: 61339  total_loss: 1.044  loss_cls: 0.1584  loss_ctr: 0.6026  loss_box_reg: 0.2841  time: 1.2732  data_time: 0.0164  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:13:17 d2.utils.events]: [0m eta: 3:46:39  iter: 61359  total_loss: 1.052  loss_cls: 0.1649  loss_ctr: 0.6046  loss_box_reg: 0.2899  time: 1.2730  data_time: 0.0144  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:13:43 d2.utils.events]: [0m eta: 3:46:13  iter: 61379  total_loss: 1.051  loss_cls: 0.1613  loss_ctr: 0.6029  loss_box_reg: 0.2874  time: 1.2731  data_time: 0.0138  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:14:09 d2.utils.events]: [0m eta: 3:45:50  iter: 61399  total_loss: 1.059  loss_cls: 0.1653  loss_ctr: 0.6018  loss_box_reg: 0.2899  time: 1.2735  data_time: 0.0152  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:14:34 d2.utils.events]: [0m eta: 3:45:24  iter: 61419  total_loss: 1.052  loss_cls: 0.1561  loss_ctr: 0.6021  loss_box_reg: 0.2815  time: 1.2733  data_time: 0.0108  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:15:02 d2.utils.events]: [0m eta: 3:45:07  iter: 61439  total_loss: 1.069  loss_cls: 0.1638  loss_ctr: 0.6029  loss_box_reg: 0.301  time: 1.2748  data_time: 0.1268  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:15:27 d2.utils.events]: [0m eta: 3:44:41  iter: 61459  total_loss: 1.059  loss_cls: 0.1628  loss_ctr: 0.6016  loss_box_reg: 0.2884  time: 1.2747  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:15:53 d2.utils.events]: [0m eta: 3:44:05  iter: 61479  total_loss: 1.054  loss_cls: 0.161  loss_ctr: 0.6028  loss_box_reg: 0.2911  time: 1.2746  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:16:19 d2.utils.events]: [0m eta: 3:43:40  iter: 61499  total_loss: 1.042  loss_cls: 0.1629  loss_ctr: 0.6021  loss_box_reg: 0.2844  time: 1.2748  data_time: 0.0136  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:16:44 d2.utils.events]: [0m eta: 3:43:15  iter: 61519  total_loss: 1.062  loss_cls: 0.1606  loss_ctr: 0.6034  loss_box_reg: 0.2898  time: 1.2748  data_time: 0.0152  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:17:10 d2.utils.events]: [0m eta: 3:42:49  iter: 61539  total_loss: 1.036  loss_cls: 0.1567  loss_ctr: 0.6014  loss_box_reg: 0.2835  time: 1.2748  data_time: 0.0112  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:17:35 d2.utils.events]: [0m eta: 3:42:23  iter: 61559  total_loss: 1.035  loss_cls: 0.1553  loss_ctr: 0.6023  loss_box_reg: 0.276  time: 1.2747  data_time: 0.0113  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:18:01 d2.utils.events]: [0m eta: 3:41:52  iter: 61579  total_loss: 1.042  loss_cls: 0.1591  loss_ctr: 0.6022  loss_box_reg: 0.2792  time: 1.2745  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:18:26 d2.utils.events]: [0m eta: 3:41:15  iter: 61599  total_loss: 1.055  loss_cls: 0.1631  loss_ctr: 0.6041  loss_box_reg: 0.2918  time: 1.2743  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:18:51 d2.utils.events]: [0m eta: 3:40:52  iter: 61619  total_loss: 1.059  loss_cls: 0.1593  loss_ctr: 0.6032  loss_box_reg: 0.2978  time: 1.2742  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:19:17 d2.utils.events]: [0m eta: 3:40:27  iter: 61639  total_loss: 1.059  loss_cls: 0.1632  loss_ctr: 0.6036  loss_box_reg: 0.2894  time: 1.2742  data_time: 0.0159  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:19:42 d2.utils.events]: [0m eta: 3:40:00  iter: 61659  total_loss: 1.042  loss_cls: 0.1609  loss_ctr: 0.6001  loss_box_reg: 0.2751  time: 1.2741  data_time: 0.0167  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:20:08 d2.utils.events]: [0m eta: 3:39:30  iter: 61679  total_loss: 1.059  loss_cls: 0.1668  loss_ctr: 0.6009  loss_box_reg: 0.2888  time: 1.2739  data_time: 0.0124  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:20:33 d2.utils.events]: [0m eta: 3:39:06  iter: 61699  total_loss: 1.043  loss_cls: 0.1631  loss_ctr: 0.6028  loss_box_reg: 0.2815  time: 1.2740  data_time: 0.0122  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:20:59 d2.utils.events]: [0m eta: 3:38:31  iter: 61719  total_loss: 1.065  loss_cls: 0.1623  loss_ctr: 0.6055  loss_box_reg: 0.2957  time: 1.2740  data_time: 0.0170  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:21:24 d2.utils.events]: [0m eta: 3:38:03  iter: 61739  total_loss: 1.045  loss_cls: 0.1565  loss_ctr: 0.6041  loss_box_reg: 0.2912  time: 1.2740  data_time: 0.0142  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:21:50 d2.utils.events]: [0m eta: 3:37:37  iter: 61759  total_loss: 1.052  loss_cls: 0.164  loss_ctr: 0.6031  loss_box_reg: 0.2853  time: 1.2739  data_time: 0.0139  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:22:16 d2.utils.events]: [0m eta: 3:37:22  iter: 61779  total_loss: 1.067  loss_cls: 0.1674  loss_ctr: 0.6044  loss_box_reg: 0.2964  time: 1.2740  data_time: 0.0116  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:22:41 d2.utils.events]: [0m eta: 3:36:46  iter: 61799  total_loss: 1.063  loss_cls: 0.1606  loss_ctr: 0.6055  loss_box_reg: 0.2967  time: 1.2737  data_time: 0.0115  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:23:06 d2.utils.events]: [0m eta: 3:36:27  iter: 61819  total_loss: 1.038  loss_cls: 0.156  loss_ctr: 0.6021  loss_box_reg: 0.2844  time: 1.2738  data_time: 0.0134  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:23:32 d2.utils.events]: [0m eta: 3:35:58  iter: 61839  total_loss: 1.067  loss_cls: 0.1631  loss_ctr: 0.6036  loss_box_reg: 0.2924  time: 1.2737  data_time: 0.0164  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:23:58 d2.utils.events]: [0m eta: 3:35:34  iter: 61859  total_loss: 1.052  loss_cls: 0.1584  loss_ctr: 0.6051  loss_box_reg: 0.2864  time: 1.2738  data_time: 0.0142  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:24:23 d2.utils.events]: [0m eta: 3:35:14  iter: 61879  total_loss: 1.04  loss_cls: 0.1551  loss_ctr: 0.6017  loss_box_reg: 0.2862  time: 1.2739  data_time: 0.0135  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:24:49 d2.utils.events]: [0m eta: 3:34:45  iter: 61899  total_loss: 1.055  loss_cls: 0.1628  loss_ctr: 0.6025  loss_box_reg: 0.2802  time: 1.2741  data_time: 0.0320  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:25:15 d2.utils.events]: [0m eta: 3:34:29  iter: 61919  total_loss: 1.064  loss_cls: 0.1664  loss_ctr: 0.6036  loss_box_reg: 0.2981  time: 1.2741  data_time: 0.0124  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:25:41 d2.utils.events]: [0m eta: 3:34:12  iter: 61939  total_loss: 1.072  loss_cls: 0.1663  loss_ctr: 0.6045  loss_box_reg: 0.2948  time: 1.2742  data_time: 0.0156  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:26:06 d2.utils.events]: [0m eta: 3:33:38  iter: 61959  total_loss: 1.051  loss_cls: 0.1573  loss_ctr: 0.6026  loss_box_reg: 0.2862  time: 1.2739  data_time: 0.0134  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:26:32 d2.utils.events]: [0m eta: 3:33:15  iter: 61979  total_loss: 1.049  loss_cls: 0.1562  loss_ctr: 0.6018  loss_box_reg: 0.2831  time: 1.2742  data_time: 0.0138  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:26:57 d2.utils.events]: [0m eta: 3:32:47  iter: 61999  total_loss: 1.042  loss_cls: 0.1622  loss_ctr: 0.6019  loss_box_reg: 0.2801  time: 1.2741  data_time: 0.0115  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:27:22 d2.utils.events]: [0m eta: 3:32:21  iter: 62019  total_loss: 1.053  loss_cls: 0.159  loss_ctr: 0.6037  loss_box_reg: 0.2868  time: 1.2740  data_time: 0.0117  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:27:48 d2.utils.events]: [0m eta: 3:31:52  iter: 62039  total_loss: 1.062  loss_cls: 0.1637  loss_ctr: 0.6037  loss_box_reg: 0.2976  time: 1.2739  data_time: 0.0128  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:28:13 d2.utils.events]: [0m eta: 3:31:26  iter: 62059  total_loss: 1.065  loss_cls: 0.1656  loss_ctr: 0.6019  loss_box_reg: 0.294  time: 1.2739  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:28:39 d2.utils.events]: [0m eta: 3:31:05  iter: 62079  total_loss: 1.054  loss_cls: 0.1581  loss_ctr: 0.6042  loss_box_reg: 0.2878  time: 1.2740  data_time: 0.0130  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:29:04 d2.utils.events]: [0m eta: 3:30:39  iter: 62099  total_loss: 1.046  loss_cls: 0.1541  loss_ctr: 0.6037  loss_box_reg: 0.284  time: 1.2739  data_time: 0.0137  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:29:30 d2.utils.events]: [0m eta: 3:30:14  iter: 62119  total_loss: 1.054  loss_cls: 0.1577  loss_ctr: 0.6022  loss_box_reg: 0.29  time: 1.2741  data_time: 0.0119  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:29:56 d2.utils.events]: [0m eta: 3:29:53  iter: 62139  total_loss: 1.049  loss_cls: 0.1611  loss_ctr: 0.6018  loss_box_reg: 0.2857  time: 1.2741  data_time: 0.0118  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:30:22 d2.utils.events]: [0m eta: 3:29:38  iter: 62159  total_loss: 1.021  loss_cls: 0.1552  loss_ctr: 0.6025  loss_box_reg: 0.2608  time: 1.2744  data_time: 0.0104  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:30:47 d2.utils.events]: [0m eta: 3:29:06  iter: 62179  total_loss: 1.041  loss_cls: 0.1604  loss_ctr: 0.6034  loss_box_reg: 0.2788  time: 1.2742  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:31:13 d2.utils.events]: [0m eta: 3:28:36  iter: 62199  total_loss: 1.074  loss_cls: 0.1717  loss_ctr: 0.6043  loss_box_reg: 0.3009  time: 1.2742  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:31:38 d2.utils.events]: [0m eta: 3:28:18  iter: 62219  total_loss: 1.029  loss_cls: 0.155  loss_ctr: 0.6022  loss_box_reg: 0.2731  time: 1.2742  data_time: 0.0151  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:32:04 d2.utils.events]: [0m eta: 3:27:58  iter: 62239  total_loss: 1.059  loss_cls: 0.1665  loss_ctr: 0.6027  loss_box_reg: 0.2899  time: 1.2742  data_time: 0.0184  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:32:30 d2.utils.events]: [0m eta: 3:27:37  iter: 62259  total_loss: 1.062  loss_cls: 0.1588  loss_ctr: 0.6043  loss_box_reg: 0.2932  time: 1.2745  data_time: 0.0143  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:32:56 d2.utils.events]: [0m eta: 3:27:20  iter: 62279  total_loss: 1.069  loss_cls: 0.1636  loss_ctr: 0.6049  loss_box_reg: 0.297  time: 1.2745  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:33:21 d2.utils.events]: [0m eta: 3:26:52  iter: 62299  total_loss: 1.045  loss_cls: 0.1638  loss_ctr: 0.6033  loss_box_reg: 0.286  time: 1.2743  data_time: 0.0120  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:33:50 d2.utils.events]: [0m eta: 3:26:23  iter: 62319  total_loss: 1.047  loss_cls: 0.1603  loss_ctr: 0.6024  loss_box_reg: 0.281  time: 1.2759  data_time: 0.0148  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:34:15 d2.utils.events]: [0m eta: 3:25:51  iter: 62339  total_loss: 1.031  loss_cls: 0.1585  loss_ctr: 0.6017  loss_box_reg: 0.2765  time: 1.2758  data_time: 0.0162  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:34:41 d2.utils.events]: [0m eta: 3:25:26  iter: 62359  total_loss: 1.054  loss_cls: 0.159  loss_ctr: 0.6046  loss_box_reg: 0.2856  time: 1.2758  data_time: 0.0143  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:35:07 d2.utils.events]: [0m eta: 3:25:06  iter: 62379  total_loss: 1.062  loss_cls: 0.1666  loss_ctr: 0.6033  loss_box_reg: 0.2883  time: 1.2758  data_time: 0.0128  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:35:32 d2.utils.events]: [0m eta: 3:24:34  iter: 62399  total_loss: 1.064  loss_cls: 0.1651  loss_ctr: 0.6018  loss_box_reg: 0.2934  time: 1.2758  data_time: 0.0112  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:35:57 d2.utils.events]: [0m eta: 3:24:08  iter: 62419  total_loss: 1.057  loss_cls: 0.1712  loss_ctr: 0.6032  loss_box_reg: 0.2921  time: 1.2756  data_time: 0.0115  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:36:23 d2.utils.events]: [0m eta: 3:23:42  iter: 62439  total_loss: 1.045  loss_cls: 0.1605  loss_ctr: 0.6026  loss_box_reg: 0.2828  time: 1.2756  data_time: 0.0144  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:36:49 d2.utils.events]: [0m eta: 3:23:22  iter: 62459  total_loss: 1.032  loss_cls: 0.1531  loss_ctr: 0.6011  loss_box_reg: 0.2793  time: 1.2757  data_time: 0.0149  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:37:15 d2.utils.events]: [0m eta: 3:23:04  iter: 62479  total_loss: 1.018  loss_cls: 0.154  loss_ctr: 0.6028  loss_box_reg: 0.2697  time: 1.2758  data_time: 0.0135  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:37:40 d2.utils.events]: [0m eta: 3:22:36  iter: 62499  total_loss: 1.069  loss_cls: 0.1665  loss_ctr: 0.6038  loss_box_reg: 0.2953  time: 1.2758  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:38:06 d2.utils.events]: [0m eta: 3:22:09  iter: 62519  total_loss: 1.063  loss_cls: 0.1607  loss_ctr: 0.6035  loss_box_reg: 0.2978  time: 1.2758  data_time: 0.0118  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:38:31 d2.utils.events]: [0m eta: 3:21:39  iter: 62539  total_loss: 1.04  loss_cls: 0.1602  loss_ctr: 0.6017  loss_box_reg: 0.2809  time: 1.2758  data_time: 0.0144  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:38:57 d2.utils.events]: [0m eta: 3:21:15  iter: 62559  total_loss: 1.04  loss_cls: 0.1583  loss_ctr: 0.6032  loss_box_reg: 0.2762  time: 1.2758  data_time: 0.0160  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:39:23 d2.utils.events]: [0m eta: 3:20:58  iter: 62579  total_loss: 1.058  loss_cls: 0.1632  loss_ctr: 0.6033  loss_box_reg: 0.2912  time: 1.2759  data_time: 0.0143  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:39:48 d2.utils.events]: [0m eta: 3:20:42  iter: 62599  total_loss: 1.039  loss_cls: 0.1631  loss_ctr: 0.6021  loss_box_reg: 0.278  time: 1.2759  data_time: 0.0134  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:40:14 d2.utils.events]: [0m eta: 3:20:22  iter: 62619  total_loss: 1.035  loss_cls: 0.1627  loss_ctr: 0.6005  loss_box_reg: 0.2717  time: 1.2760  data_time: 0.0171  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:40:40 d2.utils.events]: [0m eta: 3:20:00  iter: 62639  total_loss: 1.04  loss_cls: 0.1569  loss_ctr: 0.6022  loss_box_reg: 0.2875  time: 1.2761  data_time: 0.0122  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:41:06 d2.utils.events]: [0m eta: 3:19:37  iter: 62659  total_loss: 1.046  loss_cls: 0.1591  loss_ctr: 0.6031  loss_box_reg: 0.2807  time: 1.2761  data_time: 0.0178  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:41:31 d2.utils.events]: [0m eta: 3:19:13  iter: 62679  total_loss: 1.056  loss_cls: 0.1612  loss_ctr: 0.6037  loss_box_reg: 0.286  time: 1.2761  data_time: 0.0168  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:41:57 d2.utils.events]: [0m eta: 3:18:47  iter: 62699  total_loss: 1.039  loss_cls: 0.1614  loss_ctr: 0.6013  loss_box_reg: 0.2811  time: 1.2761  data_time: 0.0169  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:42:23 d2.utils.events]: [0m eta: 3:18:22  iter: 62719  total_loss: 1.035  loss_cls: 0.1569  loss_ctr: 0.6009  loss_box_reg: 0.283  time: 1.2763  data_time: 0.0119  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:42:48 d2.utils.events]: [0m eta: 3:17:54  iter: 62739  total_loss: 1.049  loss_cls: 0.1602  loss_ctr: 0.6018  loss_box_reg: 0.2865  time: 1.2763  data_time: 0.0131  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:43:14 d2.utils.events]: [0m eta: 3:17:32  iter: 62759  total_loss: 1.051  loss_cls: 0.162  loss_ctr: 0.6011  loss_box_reg: 0.286  time: 1.2764  data_time: 0.0147  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:43:40 d2.utils.events]: [0m eta: 3:17:07  iter: 62779  total_loss: 1.054  loss_cls: 0.1605  loss_ctr: 0.6034  loss_box_reg: 0.2889  time: 1.2765  data_time: 0.0120  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:44:06 d2.utils.events]: [0m eta: 3:16:53  iter: 62799  total_loss: 1.064  loss_cls: 0.161  loss_ctr: 0.6052  loss_box_reg: 0.2975  time: 1.2765  data_time: 0.0137  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:44:32 d2.utils.events]: [0m eta: 3:16:31  iter: 62819  total_loss: 1.038  loss_cls: 0.1559  loss_ctr: 0.6017  loss_box_reg: 0.2788  time: 1.2766  data_time: 0.0172  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:44:57 d2.utils.events]: [0m eta: 3:16:05  iter: 62839  total_loss: 1.063  loss_cls: 0.1554  loss_ctr: 0.6043  loss_box_reg: 0.297  time: 1.2765  data_time: 0.0162  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:45:23 d2.utils.events]: [0m eta: 3:15:40  iter: 62859  total_loss: 1.041  loss_cls: 0.1582  loss_ctr: 0.6023  loss_box_reg: 0.2837  time: 1.2765  data_time: 0.0117  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:45:49 d2.utils.events]: [0m eta: 3:15:13  iter: 62879  total_loss: 1.042  loss_cls: 0.1553  loss_ctr: 0.6021  loss_box_reg: 0.2845  time: 1.2765  data_time: 0.0124  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:46:14 d2.utils.events]: [0m eta: 3:14:42  iter: 62899  total_loss: 1.041  loss_cls: 0.1612  loss_ctr: 0.6029  loss_box_reg: 0.2843  time: 1.2765  data_time: 0.0135  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:46:40 d2.utils.events]: [0m eta: 3:14:16  iter: 62919  total_loss: 1.047  loss_cls: 0.1602  loss_ctr: 0.6  loss_box_reg: 0.2793  time: 1.2765  data_time: 0.0133  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:47:05 d2.utils.events]: [0m eta: 3:13:43  iter: 62939  total_loss: 1.046  loss_cls: 0.1561  loss_ctr: 0.6024  loss_box_reg: 0.2882  time: 1.2764  data_time: 0.0145  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:47:30 d2.utils.events]: [0m eta: 3:13:17  iter: 62959  total_loss: 1.045  loss_cls: 0.1524  loss_ctr: 0.6039  loss_box_reg: 0.2844  time: 1.2763  data_time: 0.0111  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:47:56 d2.utils.events]: [0m eta: 3:12:51  iter: 62979  total_loss: 1.044  loss_cls: 0.1566  loss_ctr: 0.6052  loss_box_reg: 0.2854  time: 1.2763  data_time: 0.0123  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:48:21 d2.utils.events]: [0m eta: 3:12:23  iter: 62999  total_loss: 1.072  loss_cls: 0.168  loss_ctr: 0.6043  loss_box_reg: 0.3001  time: 1.2762  data_time: 0.0146  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:48:47 d2.utils.events]: [0m eta: 3:11:58  iter: 63019  total_loss: 1.038  loss_cls: 0.1515  loss_ctr: 0.6037  loss_box_reg: 0.2813  time: 1.2762  data_time: 0.0188  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:49:12 d2.utils.events]: [0m eta: 3:11:28  iter: 63039  total_loss: 1.047  loss_cls: 0.1549  loss_ctr: 0.6018  loss_box_reg: 0.2884  time: 1.2761  data_time: 0.0151  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:49:38 d2.utils.events]: [0m eta: 3:10:56  iter: 63059  total_loss: 1.054  loss_cls: 0.1614  loss_ctr: 0.6025  loss_box_reg: 0.29  time: 1.2760  data_time: 0.0142  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:50:03 d2.utils.events]: [0m eta: 3:10:18  iter: 63079  total_loss: 1.045  loss_cls: 0.1618  loss_ctr: 0.6009  loss_box_reg: 0.2772  time: 1.2759  data_time: 0.0150  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:50:28 d2.utils.events]: [0m eta: 3:09:59  iter: 63099  total_loss: 1.043  loss_cls: 0.1555  loss_ctr: 0.6019  loss_box_reg: 0.2845  time: 1.2758  data_time: 0.0124  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:50:54 d2.utils.events]: [0m eta: 3:09:24  iter: 63119  total_loss: 1.043  loss_cls: 0.1584  loss_ctr: 0.602  loss_box_reg: 0.2801  time: 1.2758  data_time: 0.0150  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:51:19 d2.utils.events]: [0m eta: 3:08:54  iter: 63139  total_loss: 1.029  loss_cls: 0.1573  loss_ctr: 0.6009  loss_box_reg: 0.276  time: 1.2757  data_time: 0.0154  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:51:44 d2.utils.events]: [0m eta: 3:08:24  iter: 63159  total_loss: 1.022  loss_cls: 0.1485  loss_ctr: 0.6015  loss_box_reg: 0.2732  time: 1.2757  data_time: 0.0158  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:52:10 d2.utils.events]: [0m eta: 3:08:01  iter: 63179  total_loss: 1.031  loss_cls: 0.1482  loss_ctr: 0.6016  loss_box_reg: 0.2754  time: 1.2756  data_time: 0.0138  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:52:36 d2.utils.events]: [0m eta: 3:07:36  iter: 63199  total_loss: 1.038  loss_cls: 0.1579  loss_ctr: 0.6017  loss_box_reg: 0.2774  time: 1.2757  data_time: 0.0126  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:53:02 d2.utils.events]: [0m eta: 3:07:16  iter: 63219  total_loss: 1.026  loss_cls: 0.1521  loss_ctr: 0.6018  loss_box_reg: 0.2747  time: 1.2759  data_time: 0.0150  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:53:28 d2.utils.events]: [0m eta: 3:06:57  iter: 63239  total_loss: 1.018  loss_cls: 0.1577  loss_ctr: 0.6012  loss_box_reg: 0.2679  time: 1.2759  data_time: 0.0123  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:53:53 d2.utils.events]: [0m eta: 3:06:19  iter: 63259  total_loss: 1.042  loss_cls: 0.1553  loss_ctr: 0.602  loss_box_reg: 0.2837  time: 1.2759  data_time: 0.0115  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:54:18 d2.utils.events]: [0m eta: 3:05:41  iter: 63279  total_loss: 1.037  loss_cls: 0.1589  loss_ctr: 0.6025  loss_box_reg: 0.2839  time: 1.2757  data_time: 0.0130  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:54:44 d2.utils.events]: [0m eta: 3:05:23  iter: 63299  total_loss: 1.04  loss_cls: 0.1605  loss_ctr: 0.6017  loss_box_reg: 0.2803  time: 1.2758  data_time: 0.0130  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:55:09 d2.utils.events]: [0m eta: 3:04:58  iter: 63319  total_loss: 1.041  loss_cls: 0.1575  loss_ctr: 0.6024  loss_box_reg: 0.2827  time: 1.2758  data_time: 0.0138  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:55:35 d2.utils.events]: [0m eta: 3:04:31  iter: 63339  total_loss: 1.041  loss_cls: 0.1582  loss_ctr: 0.6025  loss_box_reg: 0.283  time: 1.2756  data_time: 0.0150  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:56:00 d2.utils.events]: [0m eta: 3:04:06  iter: 63359  total_loss: 1.047  loss_cls: 0.156  loss_ctr: 0.6031  loss_box_reg: 0.2866  time: 1.2756  data_time: 0.0139  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:56:26 d2.utils.events]: [0m eta: 3:03:35  iter: 63379  total_loss: 1.032  loss_cls: 0.1619  loss_ctr: 0.6024  loss_box_reg: 0.2758  time: 1.2755  data_time: 0.0170  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:56:51 d2.utils.events]: [0m eta: 3:03:08  iter: 63399  total_loss: 1.059  loss_cls: 0.1566  loss_ctr: 0.603  loss_box_reg: 0.2905  time: 1.2755  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:57:16 d2.utils.events]: [0m eta: 3:02:48  iter: 63419  total_loss: 1.048  loss_cls: 0.155  loss_ctr: 0.6029  loss_box_reg: 0.2849  time: 1.2754  data_time: 0.0125  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:57:42 d2.utils.events]: [0m eta: 3:02:25  iter: 63439  total_loss: 1.039  loss_cls: 0.1504  loss_ctr: 0.6018  loss_box_reg: 0.2855  time: 1.2755  data_time: 0.0165  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:58:08 d2.utils.events]: [0m eta: 3:01:59  iter: 63459  total_loss: 1.053  loss_cls: 0.1559  loss_ctr: 0.6029  loss_box_reg: 0.2876  time: 1.2756  data_time: 0.0131  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:58:34 d2.utils.events]: [0m eta: 3:01:25  iter: 63479  total_loss: 1.042  loss_cls: 0.1601  loss_ctr: 0.6019  loss_box_reg: 0.2798  time: 1.2756  data_time: 0.0143  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:58:59 d2.utils.events]: [0m eta: 3:00:58  iter: 63499  total_loss: 1.031  loss_cls: 0.1521  loss_ctr: 0.5999  loss_box_reg: 0.2719  time: 1.2756  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:59:25 d2.utils.events]: [0m eta: 3:00:31  iter: 63519  total_loss: 1.051  loss_cls: 0.1621  loss_ctr: 0.6027  loss_box_reg: 0.2815  time: 1.2755  data_time: 0.0140  lr: 1e-05  max_mem: 25928M
[32m[11/03 15:59:50 d2.utils.events]: [0m eta: 3:00:10  iter: 63539  total_loss: 1.033  loss_cls: 0.1543  loss_ctr: 0.6007  loss_box_reg: 0.2765  time: 1.2755  data_time: 0.0125  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:00:16 d2.utils.events]: [0m eta: 2:59:45  iter: 63559  total_loss: 1.046  loss_cls: 0.1582  loss_ctr: 0.6016  loss_box_reg: 0.2874  time: 1.2755  data_time: 0.0162  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:00:41 d2.utils.events]: [0m eta: 2:59:16  iter: 63579  total_loss: 1.032  loss_cls: 0.1509  loss_ctr: 0.6027  loss_box_reg: 0.2823  time: 1.2753  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:01:06 d2.utils.events]: [0m eta: 2:58:49  iter: 63599  total_loss: 1.038  loss_cls: 0.1535  loss_ctr: 0.6021  loss_box_reg: 0.2811  time: 1.2753  data_time: 0.0131  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:01:32 d2.utils.events]: [0m eta: 2:58:14  iter: 63619  total_loss: 1.027  loss_cls: 0.1585  loss_ctr: 0.6007  loss_box_reg: 0.2724  time: 1.2752  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:01:57 d2.utils.events]: [0m eta: 2:57:43  iter: 63639  total_loss: 1.029  loss_cls: 0.153  loss_ctr: 0.6027  loss_box_reg: 0.2778  time: 1.2752  data_time: 0.0137  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:02:23 d2.utils.events]: [0m eta: 2:57:16  iter: 63659  total_loss: 1.013  loss_cls: 0.1497  loss_ctr: 0.6005  loss_box_reg: 0.2689  time: 1.2752  data_time: 0.0129  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:02:48 d2.utils.events]: [0m eta: 2:56:54  iter: 63679  total_loss: 1.048  loss_cls: 0.1543  loss_ctr: 0.604  loss_box_reg: 0.2893  time: 1.2751  data_time: 0.0149  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:03:14 d2.utils.events]: [0m eta: 2:56:29  iter: 63699  total_loss: 1.048  loss_cls: 0.1566  loss_ctr: 0.6028  loss_box_reg: 0.2924  time: 1.2751  data_time: 0.0123  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:03:39 d2.utils.events]: [0m eta: 2:56:03  iter: 63719  total_loss: 1.047  loss_cls: 0.1576  loss_ctr: 0.6027  loss_box_reg: 0.2815  time: 1.2752  data_time: 0.0142  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:04:05 d2.utils.events]: [0m eta: 2:55:33  iter: 63739  total_loss: 1.059  loss_cls: 0.1563  loss_ctr: 0.6034  loss_box_reg: 0.2904  time: 1.2751  data_time: 0.0148  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:04:31 d2.utils.events]: [0m eta: 2:55:09  iter: 63759  total_loss: 1.029  loss_cls: 0.1498  loss_ctr: 0.6028  loss_box_reg: 0.2797  time: 1.2752  data_time: 0.0122  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:04:56 d2.utils.events]: [0m eta: 2:54:34  iter: 63779  total_loss: 1.043  loss_cls: 0.159  loss_ctr: 0.6045  loss_box_reg: 0.2858  time: 1.2753  data_time: 0.0150  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:05:22 d2.utils.events]: [0m eta: 2:54:02  iter: 63799  total_loss: 1.034  loss_cls: 0.1564  loss_ctr: 0.6009  loss_box_reg: 0.2731  time: 1.2753  data_time: 0.0125  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:05:48 d2.utils.events]: [0m eta: 2:53:32  iter: 63819  total_loss: 1.04  loss_cls: 0.1516  loss_ctr: 0.6014  loss_box_reg: 0.2698  time: 1.2753  data_time: 0.0119  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:06:13 d2.utils.events]: [0m eta: 2:53:04  iter: 63839  total_loss: 1.063  loss_cls: 0.162  loss_ctr: 0.6035  loss_box_reg: 0.2858  time: 1.2752  data_time: 0.0139  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:06:38 d2.utils.events]: [0m eta: 2:52:34  iter: 63859  total_loss: 1.047  loss_cls: 0.1619  loss_ctr: 0.6016  loss_box_reg: 0.2858  time: 1.2752  data_time: 0.0123  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:07:04 d2.utils.events]: [0m eta: 2:52:09  iter: 63879  total_loss: 1.037  loss_cls: 0.1564  loss_ctr: 0.6013  loss_box_reg: 0.2761  time: 1.2752  data_time: 0.0131  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:07:30 d2.utils.events]: [0m eta: 2:51:49  iter: 63899  total_loss: 1.044  loss_cls: 0.1565  loss_ctr: 0.6043  loss_box_reg: 0.287  time: 1.2753  data_time: 0.0139  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:07:56 d2.utils.events]: [0m eta: 2:51:23  iter: 63919  total_loss: 1.039  loss_cls: 0.1577  loss_ctr: 0.6004  loss_box_reg: 0.281  time: 1.2753  data_time: 0.0152  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:08:21 d2.utils.events]: [0m eta: 2:50:53  iter: 63939  total_loss: 1.031  loss_cls: 0.1548  loss_ctr: 0.602  loss_box_reg: 0.2808  time: 1.2753  data_time: 0.0126  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:08:46 d2.utils.events]: [0m eta: 2:50:23  iter: 63959  total_loss: 1.043  loss_cls: 0.1576  loss_ctr: 0.6034  loss_box_reg: 0.286  time: 1.2751  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:09:12 d2.utils.events]: [0m eta: 2:50:01  iter: 63979  total_loss: 1.049  loss_cls: 0.1599  loss_ctr: 0.602  loss_box_reg: 0.2855  time: 1.2752  data_time: 0.0140  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:09:38 d2.utils.events]: [0m eta: 2:49:45  iter: 63999  total_loss: 1.036  loss_cls: 0.1512  loss_ctr: 0.604  loss_box_reg: 0.2829  time: 1.2752  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:10:04 d2.utils.events]: [0m eta: 2:49:36  iter: 64019  total_loss: 1.043  loss_cls: 0.1542  loss_ctr: 0.6026  loss_box_reg: 0.2748  time: 1.2753  data_time: 0.0153  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:10:29 d2.utils.events]: [0m eta: 2:49:16  iter: 64039  total_loss: 1.036  loss_cls: 0.152  loss_ctr: 0.6026  loss_box_reg: 0.281  time: 1.2753  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:10:55 d2.utils.events]: [0m eta: 2:49:00  iter: 64059  total_loss: 1.034  loss_cls: 0.1516  loss_ctr: 0.6018  loss_box_reg: 0.2779  time: 1.2754  data_time: 0.0187  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:11:21 d2.utils.events]: [0m eta: 2:48:45  iter: 64079  total_loss: 1.05  loss_cls: 0.1564  loss_ctr: 0.6025  loss_box_reg: 0.2906  time: 1.2754  data_time: 0.0124  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:11:46 d2.utils.events]: [0m eta: 2:48:20  iter: 64099  total_loss: 1.042  loss_cls: 0.1617  loss_ctr: 0.6019  loss_box_reg: 0.2863  time: 1.2754  data_time: 0.0160  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:12:12 d2.utils.events]: [0m eta: 2:47:58  iter: 64119  total_loss: 1.032  loss_cls: 0.1499  loss_ctr: 0.6029  loss_box_reg: 0.2775  time: 1.2753  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:12:37 d2.utils.events]: [0m eta: 2:47:35  iter: 64139  total_loss: 1.047  loss_cls: 0.1562  loss_ctr: 0.6029  loss_box_reg: 0.2845  time: 1.2754  data_time: 0.0126  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:13:03 d2.utils.events]: [0m eta: 2:47:12  iter: 64159  total_loss: 1.032  loss_cls: 0.1533  loss_ctr: 0.6007  loss_box_reg: 0.2668  time: 1.2754  data_time: 0.0144  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:13:28 d2.utils.events]: [0m eta: 2:46:44  iter: 64179  total_loss: 1.033  loss_cls: 0.1537  loss_ctr: 0.6005  loss_box_reg: 0.2769  time: 1.2753  data_time: 0.0165  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:13:54 d2.utils.events]: [0m eta: 2:46:19  iter: 64199  total_loss: 1.043  loss_cls: 0.1564  loss_ctr: 0.6028  loss_box_reg: 0.2761  time: 1.2753  data_time: 0.0124  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:14:19 d2.utils.events]: [0m eta: 2:45:50  iter: 64219  total_loss: 1.032  loss_cls: 0.1581  loss_ctr: 0.6008  loss_box_reg: 0.272  time: 1.2753  data_time: 0.0139  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:14:45 d2.utils.events]: [0m eta: 2:45:28  iter: 64239  total_loss: 1.047  loss_cls: 0.1582  loss_ctr: 0.6037  loss_box_reg: 0.2933  time: 1.2753  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:15:10 d2.utils.events]: [0m eta: 2:45:04  iter: 64259  total_loss: 1.048  loss_cls: 0.1586  loss_ctr: 0.6018  loss_box_reg: 0.289  time: 1.2753  data_time: 0.0122  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:15:36 d2.utils.events]: [0m eta: 2:44:50  iter: 64279  total_loss: 1.044  loss_cls: 0.1556  loss_ctr: 0.6029  loss_box_reg: 0.2864  time: 1.2753  data_time: 0.0131  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:16:01 d2.utils.events]: [0m eta: 2:44:26  iter: 64299  total_loss: 1.073  loss_cls: 0.1664  loss_ctr: 0.6058  loss_box_reg: 0.2993  time: 1.2753  data_time: 0.0116  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:16:27 d2.utils.events]: [0m eta: 2:43:57  iter: 64319  total_loss: 1.043  loss_cls: 0.1539  loss_ctr: 0.6028  loss_box_reg: 0.2858  time: 1.2752  data_time: 0.0116  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:16:52 d2.utils.events]: [0m eta: 2:43:35  iter: 64339  total_loss: 1.018  loss_cls: 0.1486  loss_ctr: 0.6006  loss_box_reg: 0.265  time: 1.2752  data_time: 0.0134  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:17:18 d2.utils.events]: [0m eta: 2:43:09  iter: 64359  total_loss: 1.062  loss_cls: 0.1612  loss_ctr: 0.6019  loss_box_reg: 0.2976  time: 1.2752  data_time: 0.0139  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:17:43 d2.utils.events]: [0m eta: 2:42:43  iter: 64379  total_loss: 1.026  loss_cls: 0.1558  loss_ctr: 0.6005  loss_box_reg: 0.2697  time: 1.2752  data_time: 0.0139  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:18:09 d2.utils.events]: [0m eta: 2:42:15  iter: 64399  total_loss: 1.038  loss_cls: 0.1527  loss_ctr: 0.6015  loss_box_reg: 0.2833  time: 1.2751  data_time: 0.0148  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:18:34 d2.utils.events]: [0m eta: 2:41:40  iter: 64419  total_loss: 1.029  loss_cls: 0.1542  loss_ctr: 0.6014  loss_box_reg: 0.269  time: 1.2750  data_time: 0.0143  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:18:59 d2.utils.events]: [0m eta: 2:41:12  iter: 64439  total_loss: 1.039  loss_cls: 0.1588  loss_ctr: 0.6033  loss_box_reg: 0.2759  time: 1.2750  data_time: 0.0146  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:19:25 d2.utils.events]: [0m eta: 2:40:30  iter: 64459  total_loss: 1.024  loss_cls: 0.1536  loss_ctr: 0.601  loss_box_reg: 0.271  time: 1.2749  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:19:50 d2.utils.events]: [0m eta: 2:40:06  iter: 64479  total_loss: 1.045  loss_cls: 0.1589  loss_ctr: 0.6025  loss_box_reg: 0.2816  time: 1.2749  data_time: 0.0141  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:22:00 d2.utils.events]: [0m eta: 2:39:48  iter: 64499  total_loss: 1.027  loss_cls: 0.1527  loss_ctr: 0.6009  loss_box_reg: 0.2764  time: 1.2982  data_time: 5.2437  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:22:25 d2.utils.events]: [0m eta: 2:39:13  iter: 64519  total_loss: 1.04  loss_cls: 0.1543  loss_ctr: 0.6027  loss_box_reg: 0.2857  time: 1.2979  data_time: 0.0169  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:22:51 d2.utils.events]: [0m eta: 2:38:32  iter: 64539  total_loss: 1.028  loss_cls: 0.1554  loss_ctr: 0.5999  loss_box_reg: 0.2726  time: 1.2978  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:23:16 d2.utils.events]: [0m eta: 2:38:08  iter: 64559  total_loss: 1.051  loss_cls: 0.1597  loss_ctr: 0.6041  loss_box_reg: 0.2882  time: 1.2977  data_time: 0.0117  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:23:42 d2.utils.events]: [0m eta: 2:37:59  iter: 64579  total_loss: 1.031  loss_cls: 0.1471  loss_ctr: 0.6011  loss_box_reg: 0.2771  time: 1.2976  data_time: 0.0125  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:24:08 d2.utils.events]: [0m eta: 2:37:39  iter: 64599  total_loss: 1.058  loss_cls: 0.1634  loss_ctr: 0.6033  loss_box_reg: 0.2937  time: 1.2975  data_time: 0.0158  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:24:33 d2.utils.events]: [0m eta: 2:37:24  iter: 64619  total_loss: 1.04  loss_cls: 0.1519  loss_ctr: 0.6023  loss_box_reg: 0.2832  time: 1.2975  data_time: 0.0144  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:24:59 d2.utils.events]: [0m eta: 2:37:07  iter: 64639  total_loss: 1.038  loss_cls: 0.1601  loss_ctr: 0.6017  loss_box_reg: 0.277  time: 1.2974  data_time: 0.0123  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:25:25 d2.utils.events]: [0m eta: 2:36:44  iter: 64659  total_loss: 1.043  loss_cls: 0.1638  loss_ctr: 0.6028  loss_box_reg: 0.2794  time: 1.2973  data_time: 0.0128  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:25:50 d2.utils.events]: [0m eta: 2:36:22  iter: 64679  total_loss: 1.034  loss_cls: 0.1514  loss_ctr: 0.6022  loss_box_reg: 0.2745  time: 1.2972  data_time: 0.0149  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:26:16 d2.utils.events]: [0m eta: 2:35:53  iter: 64699  total_loss: 1.032  loss_cls: 0.1548  loss_ctr: 0.6035  loss_box_reg: 0.279  time: 1.2971  data_time: 0.0129  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:26:41 d2.utils.events]: [0m eta: 2:35:27  iter: 64719  total_loss: 1.044  loss_cls: 0.1603  loss_ctr: 0.6023  loss_box_reg: 0.2819  time: 1.2970  data_time: 0.0148  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:27:07 d2.utils.events]: [0m eta: 2:35:15  iter: 64739  total_loss: 1.047  loss_cls: 0.1601  loss_ctr: 0.6028  loss_box_reg: 0.2854  time: 1.2970  data_time: 0.0140  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:27:33 d2.utils.events]: [0m eta: 2:34:35  iter: 64759  total_loss: 1.048  loss_cls: 0.1585  loss_ctr: 0.6041  loss_box_reg: 0.2771  time: 1.2969  data_time: 0.0137  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:27:58 d2.utils.events]: [0m eta: 2:34:01  iter: 64779  total_loss: 1.049  loss_cls: 0.1494  loss_ctr: 0.6036  loss_box_reg: 0.2959  time: 1.2967  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:28:24 d2.utils.events]: [0m eta: 2:33:44  iter: 64799  total_loss: 1.029  loss_cls: 0.148  loss_ctr: 0.6025  loss_box_reg: 0.2792  time: 1.2967  data_time: 0.0139  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:28:49 d2.utils.events]: [0m eta: 2:33:18  iter: 64819  total_loss: 1.062  loss_cls: 0.1615  loss_ctr: 0.6028  loss_box_reg: 0.2901  time: 1.2965  data_time: 0.0148  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:29:15 d2.utils.events]: [0m eta: 2:32:54  iter: 64839  total_loss: 1.057  loss_cls: 0.159  loss_ctr: 0.6019  loss_box_reg: 0.2928  time: 1.2964  data_time: 0.0163  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:29:40 d2.utils.events]: [0m eta: 2:32:28  iter: 64859  total_loss: 1.06  loss_cls: 0.1665  loss_ctr: 0.6037  loss_box_reg: 0.2897  time: 1.2963  data_time: 0.0124  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:30:05 d2.utils.events]: [0m eta: 2:32:00  iter: 64879  total_loss: 1.048  loss_cls: 0.1536  loss_ctr: 0.603  loss_box_reg: 0.285  time: 1.2962  data_time: 0.0131  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:30:31 d2.utils.events]: [0m eta: 2:31:20  iter: 64899  total_loss: 1.026  loss_cls: 0.152  loss_ctr: 0.6037  loss_box_reg: 0.2736  time: 1.2960  data_time: 0.0164  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:30:57 d2.utils.events]: [0m eta: 2:30:59  iter: 64919  total_loss: 1.044  loss_cls: 0.1593  loss_ctr: 0.6018  loss_box_reg: 0.2805  time: 1.2961  data_time: 0.0174  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:31:22 d2.utils.events]: [0m eta: 2:30:32  iter: 64939  total_loss: 1.034  loss_cls: 0.1575  loss_ctr: 0.6026  loss_box_reg: 0.2796  time: 1.2959  data_time: 0.0145  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:31:48 d2.utils.events]: [0m eta: 2:30:20  iter: 64959  total_loss: 1.045  loss_cls: 0.1616  loss_ctr: 0.6032  loss_box_reg: 0.2861  time: 1.2958  data_time: 0.0192  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:32:13 d2.utils.events]: [0m eta: 2:29:41  iter: 64979  total_loss: 1.024  loss_cls: 0.1474  loss_ctr: 0.5997  loss_box_reg: 0.2722  time: 1.2957  data_time: 0.0186  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:32:39 fvcore.common.checkpoint]: [0mSaving checkpoint to ./results/COCO/dh/dh_swint_fpn_COCO_concepts_cat/model_0064999.pth
[32m[11/03 16:32:40 d2.utils.events]: [0m eta: 2:29:15  iter: 64999  total_loss: 1.046  loss_cls: 0.1587  loss_ctr: 0.6013  loss_box_reg: 0.2849  time: 1.2956  data_time: 0.0155  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:33:06 d2.utils.events]: [0m eta: 2:28:43  iter: 65019  total_loss: 1.04  loss_cls: 0.1628  loss_ctr: 0.6022  loss_box_reg: 0.2813  time: 1.2955  data_time: 0.0151  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:33:31 d2.utils.events]: [0m eta: 2:28:11  iter: 65039  total_loss: 1.05  loss_cls: 0.1564  loss_ctr: 0.602  loss_box_reg: 0.2907  time: 1.2953  data_time: 0.0150  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:33:56 d2.utils.events]: [0m eta: 2:27:26  iter: 65059  total_loss: 1.028  loss_cls: 0.1518  loss_ctr: 0.6001  loss_box_reg: 0.2713  time: 1.2952  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:34:21 d2.utils.events]: [0m eta: 2:26:49  iter: 65079  total_loss: 1.039  loss_cls: 0.1559  loss_ctr: 0.6036  loss_box_reg: 0.2832  time: 1.2950  data_time: 0.0139  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:34:47 d2.utils.events]: [0m eta: 2:26:27  iter: 65099  total_loss: 1.042  loss_cls: 0.1579  loss_ctr: 0.6023  loss_box_reg: 0.282  time: 1.2949  data_time: 0.0133  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:35:12 d2.utils.events]: [0m eta: 2:25:58  iter: 65119  total_loss: 1.039  loss_cls: 0.1605  loss_ctr: 0.6026  loss_box_reg: 0.2803  time: 1.2948  data_time: 0.0222  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:35:38 d2.utils.events]: [0m eta: 2:25:33  iter: 65139  total_loss: 1.047  loss_cls: 0.159  loss_ctr: 0.6015  loss_box_reg: 0.2825  time: 1.2947  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:36:03 d2.utils.events]: [0m eta: 2:25:10  iter: 65159  total_loss: 1.041  loss_cls: 0.1553  loss_ctr: 0.6019  loss_box_reg: 0.2771  time: 1.2946  data_time: 0.0124  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:36:29 d2.utils.events]: [0m eta: 2:24:51  iter: 65179  total_loss: 1.06  loss_cls: 0.1678  loss_ctr: 0.6035  loss_box_reg: 0.2948  time: 1.2946  data_time: 0.0148  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:36:55 d2.utils.events]: [0m eta: 2:24:24  iter: 65199  total_loss: 1.043  loss_cls: 0.1558  loss_ctr: 0.6044  loss_box_reg: 0.2726  time: 1.2945  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:37:20 d2.utils.events]: [0m eta: 2:23:57  iter: 65219  total_loss: 1.028  loss_cls: 0.1522  loss_ctr: 0.6017  loss_box_reg: 0.2743  time: 1.2944  data_time: 0.0144  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:37:46 d2.utils.events]: [0m eta: 2:23:32  iter: 65239  total_loss: 1.027  loss_cls: 0.1586  loss_ctr: 0.6006  loss_box_reg: 0.2768  time: 1.2944  data_time: 0.0137  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:38:12 d2.utils.events]: [0m eta: 2:23:09  iter: 65259  total_loss: 1.043  loss_cls: 0.1542  loss_ctr: 0.6038  loss_box_reg: 0.2772  time: 1.2943  data_time: 0.0145  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:38:37 d2.utils.events]: [0m eta: 2:22:43  iter: 65279  total_loss: 1.042  loss_cls: 0.1556  loss_ctr: 0.6007  loss_box_reg: 0.2791  time: 1.2942  data_time: 0.0166  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:39:03 d2.utils.events]: [0m eta: 2:22:12  iter: 65299  total_loss: 1.029  loss_cls: 0.1572  loss_ctr: 0.6007  loss_box_reg: 0.2805  time: 1.2941  data_time: 0.0142  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:39:29 d2.utils.events]: [0m eta: 2:21:54  iter: 65319  total_loss: 1.039  loss_cls: 0.1565  loss_ctr: 0.6031  loss_box_reg: 0.276  time: 1.2941  data_time: 0.0139  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:39:54 d2.utils.events]: [0m eta: 2:21:32  iter: 65339  total_loss: 1.051  loss_cls: 0.1586  loss_ctr: 0.6018  loss_box_reg: 0.2854  time: 1.2940  data_time: 0.0134  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:40:20 d2.utils.events]: [0m eta: 2:21:08  iter: 65359  total_loss: 1.031  loss_cls: 0.1573  loss_ctr: 0.6016  loss_box_reg: 0.2714  time: 1.2939  data_time: 0.0131  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:40:45 d2.utils.events]: [0m eta: 2:20:43  iter: 65379  total_loss: 1.038  loss_cls: 0.1577  loss_ctr: 0.6023  loss_box_reg: 0.2774  time: 1.2938  data_time: 0.0173  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:41:11 d2.utils.events]: [0m eta: 2:20:22  iter: 65399  total_loss: 1.048  loss_cls: 0.164  loss_ctr: 0.6025  loss_box_reg: 0.2864  time: 1.2937  data_time: 0.0117  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:41:36 d2.utils.events]: [0m eta: 2:20:07  iter: 65419  total_loss: 1.037  loss_cls: 0.1569  loss_ctr: 0.6032  loss_box_reg: 0.2783  time: 1.2936  data_time: 0.0134  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:42:02 d2.utils.events]: [0m eta: 2:19:39  iter: 65439  total_loss: 1.053  loss_cls: 0.1551  loss_ctr: 0.6017  loss_box_reg: 0.2891  time: 1.2936  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:42:27 d2.utils.events]: [0m eta: 2:19:22  iter: 65459  total_loss: 1.052  loss_cls: 0.1571  loss_ctr: 0.6025  loss_box_reg: 0.282  time: 1.2935  data_time: 0.0117  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:42:56 d2.utils.events]: [0m eta: 2:18:57  iter: 65479  total_loss: 1.033  loss_cls: 0.1477  loss_ctr: 0.6023  loss_box_reg: 0.2816  time: 1.2940  data_time: 0.0133  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:43:23 d2.utils.events]: [0m eta: 2:18:29  iter: 65499  total_loss: 1.037  loss_cls: 0.1513  loss_ctr: 0.6022  loss_box_reg: 0.2843  time: 1.2941  data_time: 0.0134  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:43:48 d2.utils.events]: [0m eta: 2:18:10  iter: 65519  total_loss: 1.041  loss_cls: 0.1554  loss_ctr: 0.6002  loss_box_reg: 0.2818  time: 1.2941  data_time: 0.0199  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:44:14 d2.utils.events]: [0m eta: 2:17:45  iter: 65539  total_loss: 1.032  loss_cls: 0.1547  loss_ctr: 0.6006  loss_box_reg: 0.2795  time: 1.2940  data_time: 0.0131  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:44:40 d2.utils.events]: [0m eta: 2:17:22  iter: 65559  total_loss: 1.05  loss_cls: 0.1593  loss_ctr: 0.6013  loss_box_reg: 0.2839  time: 1.2940  data_time: 0.0168  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:45:06 d2.utils.events]: [0m eta: 2:16:56  iter: 65579  total_loss: 1.051  loss_cls: 0.1595  loss_ctr: 0.6017  loss_box_reg: 0.2789  time: 1.2940  data_time: 0.0125  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:45:32 d2.utils.events]: [0m eta: 2:16:31  iter: 65599  total_loss: 1.037  loss_cls: 0.1524  loss_ctr: 0.6026  loss_box_reg: 0.2844  time: 1.2940  data_time: 0.0146  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:45:58 d2.utils.events]: [0m eta: 2:16:01  iter: 65619  total_loss: 1.038  loss_cls: 0.1574  loss_ctr: 0.6004  loss_box_reg: 0.2781  time: 1.2940  data_time: 0.0154  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:46:23 d2.utils.events]: [0m eta: 2:15:36  iter: 65639  total_loss: 1.035  loss_cls: 0.1522  loss_ctr: 0.6029  loss_box_reg: 0.2751  time: 1.2939  data_time: 0.0145  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:46:49 d2.utils.events]: [0m eta: 2:15:07  iter: 65659  total_loss: 1.055  loss_cls: 0.1598  loss_ctr: 0.6035  loss_box_reg: 0.2871  time: 1.2938  data_time: 0.0138  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:47:15 d2.utils.events]: [0m eta: 2:14:36  iter: 65679  total_loss: 1.033  loss_cls: 0.1583  loss_ctr: 0.6011  loss_box_reg: 0.2777  time: 1.2938  data_time: 0.0134  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:47:40 d2.utils.events]: [0m eta: 2:14:11  iter: 65699  total_loss: 1.036  loss_cls: 0.1555  loss_ctr: 0.6013  loss_box_reg: 0.2746  time: 1.2937  data_time: 0.0137  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:48:06 d2.utils.events]: [0m eta: 2:13:44  iter: 65719  total_loss: 1.044  loss_cls: 0.1574  loss_ctr: 0.6028  loss_box_reg: 0.2841  time: 1.2936  data_time: 0.0130  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:48:31 d2.utils.events]: [0m eta: 2:13:20  iter: 65739  total_loss: 1.047  loss_cls: 0.1593  loss_ctr: 0.6018  loss_box_reg: 0.2834  time: 1.2935  data_time: 0.0151  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:48:58 d2.utils.events]: [0m eta: 2:13:02  iter: 65759  total_loss: 1.028  loss_cls: 0.1548  loss_ctr: 0.5987  loss_box_reg: 0.2759  time: 1.2936  data_time: 0.0129  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:49:23 d2.utils.events]: [0m eta: 2:12:38  iter: 65779  total_loss: 1.051  loss_cls: 0.162  loss_ctr: 0.6028  loss_box_reg: 0.2822  time: 1.2935  data_time: 0.0160  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:49:49 d2.utils.events]: [0m eta: 2:12:11  iter: 65799  total_loss: 1.031  loss_cls: 0.1556  loss_ctr: 0.6006  loss_box_reg: 0.2801  time: 1.2934  data_time: 0.0143  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:50:14 d2.utils.events]: [0m eta: 2:11:49  iter: 65819  total_loss: 1.038  loss_cls: 0.1537  loss_ctr: 0.602  loss_box_reg: 0.2792  time: 1.2934  data_time: 0.0170  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:50:40 d2.utils.events]: [0m eta: 2:11:24  iter: 65839  total_loss: 1.021  loss_cls: 0.1531  loss_ctr: 0.6017  loss_box_reg: 0.272  time: 1.2933  data_time: 0.0151  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:51:06 d2.utils.events]: [0m eta: 2:11:03  iter: 65859  total_loss: 1.028  loss_cls: 0.1497  loss_ctr: 0.6023  loss_box_reg: 0.2778  time: 1.2933  data_time: 0.0201  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:51:32 d2.utils.events]: [0m eta: 2:10:39  iter: 65879  total_loss: 1.034  loss_cls: 0.1522  loss_ctr: 0.6007  loss_box_reg: 0.2751  time: 1.2932  data_time: 0.0209  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:51:57 d2.utils.events]: [0m eta: 2:10:15  iter: 65899  total_loss: 1.031  loss_cls: 0.1517  loss_ctr: 0.6016  loss_box_reg: 0.2802  time: 1.2931  data_time: 0.0160  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:52:23 d2.utils.events]: [0m eta: 2:09:48  iter: 65919  total_loss: 1.017  loss_cls: 0.1501  loss_ctr: 0.6012  loss_box_reg: 0.2681  time: 1.2931  data_time: 0.0149  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:52:48 d2.utils.events]: [0m eta: 2:09:24  iter: 65939  total_loss: 1.024  loss_cls: 0.1547  loss_ctr: 0.6018  loss_box_reg: 0.2689  time: 1.2930  data_time: 0.0158  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:53:14 d2.utils.events]: [0m eta: 2:09:00  iter: 65959  total_loss: 1.054  loss_cls: 0.1636  loss_ctr: 0.6033  loss_box_reg: 0.293  time: 1.2930  data_time: 0.0147  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:53:40 d2.utils.events]: [0m eta: 2:08:35  iter: 65979  total_loss: 1.027  loss_cls: 0.1535  loss_ctr: 0.6006  loss_box_reg: 0.2736  time: 1.2930  data_time: 0.0148  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:54:06 d2.utils.events]: [0m eta: 2:08:08  iter: 65999  total_loss: 1.048  loss_cls: 0.1562  loss_ctr: 0.6013  loss_box_reg: 0.2827  time: 1.2930  data_time: 0.0149  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:54:32 d2.utils.events]: [0m eta: 2:07:43  iter: 66019  total_loss: 1.035  loss_cls: 0.1587  loss_ctr: 0.6028  loss_box_reg: 0.2765  time: 1.2930  data_time: 0.0124  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:54:57 d2.utils.events]: [0m eta: 2:07:25  iter: 66039  total_loss: 1.035  loss_cls: 0.1519  loss_ctr: 0.6025  loss_box_reg: 0.2796  time: 1.2929  data_time: 0.0158  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:55:23 d2.utils.events]: [0m eta: 2:07:01  iter: 66059  total_loss: 1.035  loss_cls: 0.1526  loss_ctr: 0.6011  loss_box_reg: 0.2759  time: 1.2929  data_time: 0.0148  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:55:49 d2.utils.events]: [0m eta: 2:06:39  iter: 66079  total_loss: 1.008  loss_cls: 0.1529  loss_ctr: 0.5993  loss_box_reg: 0.2614  time: 1.2928  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:56:14 d2.utils.events]: [0m eta: 2:06:12  iter: 66099  total_loss: 1.035  loss_cls: 0.1575  loss_ctr: 0.602  loss_box_reg: 0.2768  time: 1.2928  data_time: 0.0113  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:56:40 d2.utils.events]: [0m eta: 2:05:48  iter: 66119  total_loss: 1.041  loss_cls: 0.1551  loss_ctr: 0.603  loss_box_reg: 0.2796  time: 1.2927  data_time: 0.0152  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:57:06 d2.utils.events]: [0m eta: 2:05:25  iter: 66139  total_loss: 1.036  loss_cls: 0.1504  loss_ctr: 0.6022  loss_box_reg: 0.2802  time: 1.2927  data_time: 0.0168  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:57:31 d2.utils.events]: [0m eta: 2:04:57  iter: 66159  total_loss: 1.037  loss_cls: 0.1538  loss_ctr: 0.6025  loss_box_reg: 0.2839  time: 1.2926  data_time: 0.0142  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:57:57 d2.utils.events]: [0m eta: 2:04:30  iter: 66179  total_loss: 1.051  loss_cls: 0.1554  loss_ctr: 0.6037  loss_box_reg: 0.2952  time: 1.2925  data_time: 0.0202  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:58:22 d2.utils.events]: [0m eta: 2:04:03  iter: 66199  total_loss: 1.012  loss_cls: 0.1478  loss_ctr: 0.5996  loss_box_reg: 0.2601  time: 1.2924  data_time: 0.0165  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:58:48 d2.utils.events]: [0m eta: 2:03:40  iter: 66219  total_loss: 1.031  loss_cls: 0.1558  loss_ctr: 0.6  loss_box_reg: 0.2796  time: 1.2924  data_time: 0.0153  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:59:14 d2.utils.events]: [0m eta: 2:03:13  iter: 66239  total_loss: 1.039  loss_cls: 0.1524  loss_ctr: 0.6008  loss_box_reg: 0.2785  time: 1.2924  data_time: 0.0164  lr: 1e-05  max_mem: 25928M
[32m[11/03 16:59:39 d2.utils.events]: [0m eta: 2:02:45  iter: 66259  total_loss: 1.034  loss_cls: 0.1575  loss_ctr: 0.6031  loss_box_reg: 0.2785  time: 1.2923  data_time: 0.0122  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:00:05 d2.utils.events]: [0m eta: 2:02:17  iter: 66279  total_loss: 1.034  loss_cls: 0.1628  loss_ctr: 0.6001  loss_box_reg: 0.274  time: 1.2922  data_time: 0.0172  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:00:30 d2.utils.events]: [0m eta: 2:01:54  iter: 66299  total_loss: 1.038  loss_cls: 0.155  loss_ctr: 0.6031  loss_box_reg: 0.2716  time: 1.2921  data_time: 0.0151  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:00:56 d2.utils.events]: [0m eta: 2:01:23  iter: 66319  total_loss: 1.047  loss_cls: 0.1568  loss_ctr: 0.6035  loss_box_reg: 0.2851  time: 1.2921  data_time: 0.0126  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:01:22 d2.utils.events]: [0m eta: 2:01:01  iter: 66339  total_loss: 1.045  loss_cls: 0.158  loss_ctr: 0.6026  loss_box_reg: 0.2829  time: 1.2921  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:01:47 d2.utils.events]: [0m eta: 2:00:35  iter: 66359  total_loss: 1.017  loss_cls: 0.1446  loss_ctr: 0.6003  loss_box_reg: 0.2695  time: 1.2920  data_time: 0.0128  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:02:13 d2.utils.events]: [0m eta: 2:00:10  iter: 66379  total_loss: 1.017  loss_cls: 0.146  loss_ctr: 0.6004  loss_box_reg: 0.2669  time: 1.2919  data_time: 0.0137  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:02:39 d2.utils.events]: [0m eta: 1:59:47  iter: 66399  total_loss: 1.027  loss_cls: 0.1497  loss_ctr: 0.602  loss_box_reg: 0.2746  time: 1.2919  data_time: 0.0168  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:03:04 d2.utils.events]: [0m eta: 1:59:20  iter: 66419  total_loss: 1.045  loss_cls: 0.1572  loss_ctr: 0.6031  loss_box_reg: 0.2876  time: 1.2918  data_time: 0.0145  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:03:30 d2.utils.events]: [0m eta: 1:58:52  iter: 66439  total_loss: 1.035  loss_cls: 0.1499  loss_ctr: 0.6015  loss_box_reg: 0.2802  time: 1.2918  data_time: 0.0141  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:03:55 d2.utils.events]: [0m eta: 1:58:27  iter: 66459  total_loss: 1.032  loss_cls: 0.1454  loss_ctr: 0.6003  loss_box_reg: 0.282  time: 1.2917  data_time: 0.0148  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:04:21 d2.utils.events]: [0m eta: 1:58:01  iter: 66479  total_loss: 1.031  loss_cls: 0.1512  loss_ctr: 0.602  loss_box_reg: 0.2767  time: 1.2916  data_time: 0.0155  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:04:46 d2.utils.events]: [0m eta: 1:57:30  iter: 66499  total_loss: 1.027  loss_cls: 0.1473  loss_ctr: 0.5997  loss_box_reg: 0.2721  time: 1.2915  data_time: 0.0136  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:05:12 d2.utils.events]: [0m eta: 1:57:08  iter: 66519  total_loss: 1.07  loss_cls: 0.1633  loss_ctr: 0.6045  loss_box_reg: 0.2989  time: 1.2915  data_time: 0.0162  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:05:38 d2.utils.events]: [0m eta: 1:56:39  iter: 66539  total_loss: 1.023  loss_cls: 0.1527  loss_ctr: 0.6023  loss_box_reg: 0.2736  time: 1.2914  data_time: 0.0120  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:06:03 d2.utils.events]: [0m eta: 1:56:09  iter: 66559  total_loss: 1.03  loss_cls: 0.1455  loss_ctr: 0.6007  loss_box_reg: 0.2832  time: 1.2914  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:06:29 d2.utils.events]: [0m eta: 1:55:48  iter: 66579  total_loss: 1.028  loss_cls: 0.1584  loss_ctr: 0.6011  loss_box_reg: 0.2681  time: 1.2914  data_time: 0.0135  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:06:55 d2.utils.events]: [0m eta: 1:55:19  iter: 66599  total_loss: 1.017  loss_cls: 0.1564  loss_ctr: 0.6011  loss_box_reg: 0.2699  time: 1.2913  data_time: 0.0148  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:07:21 d2.utils.events]: [0m eta: 1:54:57  iter: 66619  total_loss: 1.04  loss_cls: 0.159  loss_ctr: 0.6019  loss_box_reg: 0.2769  time: 1.2913  data_time: 0.0150  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:07:46 d2.utils.events]: [0m eta: 1:54:30  iter: 66639  total_loss: 1.044  loss_cls: 0.1593  loss_ctr: 0.6033  loss_box_reg: 0.2834  time: 1.2912  data_time: 0.0150  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:08:12 d2.utils.events]: [0m eta: 1:54:05  iter: 66659  total_loss: 1.015  loss_cls: 0.1492  loss_ctr: 0.5997  loss_box_reg: 0.2654  time: 1.2912  data_time: 0.0148  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:08:38 d2.utils.events]: [0m eta: 1:53:43  iter: 66679  total_loss: 1.03  loss_cls: 0.1529  loss_ctr: 0.6016  loss_box_reg: 0.2694  time: 1.2912  data_time: 0.0130  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:09:04 d2.utils.events]: [0m eta: 1:53:19  iter: 66699  total_loss: 1.043  loss_cls: 0.1607  loss_ctr: 0.6027  loss_box_reg: 0.2796  time: 1.2911  data_time: 0.0168  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:09:29 d2.utils.events]: [0m eta: 1:52:51  iter: 66719  total_loss: 1.031  loss_cls: 0.1504  loss_ctr: 0.6013  loss_box_reg: 0.2785  time: 1.2911  data_time: 0.0186  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:09:55 d2.utils.events]: [0m eta: 1:52:23  iter: 66739  total_loss: 1.03  loss_cls: 0.1565  loss_ctr: 0.6031  loss_box_reg: 0.2712  time: 1.2910  data_time: 0.0124  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:10:20 d2.utils.events]: [0m eta: 1:51:54  iter: 66759  total_loss: 1.052  loss_cls: 0.1537  loss_ctr: 0.6023  loss_box_reg: 0.2915  time: 1.2909  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:10:46 d2.utils.events]: [0m eta: 1:51:28  iter: 66779  total_loss: 1.031  loss_cls: 0.1517  loss_ctr: 0.6028  loss_box_reg: 0.274  time: 1.2908  data_time: 0.0147  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:11:11 d2.utils.events]: [0m eta: 1:51:02  iter: 66799  total_loss: 1.05  loss_cls: 0.1531  loss_ctr: 0.603  loss_box_reg: 0.2878  time: 1.2908  data_time: 0.0148  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:11:36 d2.utils.events]: [0m eta: 1:50:32  iter: 66819  total_loss: 1.032  loss_cls: 0.1552  loss_ctr: 0.6012  loss_box_reg: 0.2732  time: 1.2907  data_time: 0.0133  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:12:02 d2.utils.events]: [0m eta: 1:50:11  iter: 66839  total_loss: 1.044  loss_cls: 0.1636  loss_ctr: 0.6015  loss_box_reg: 0.2798  time: 1.2906  data_time: 0.0130  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:12:28 d2.utils.events]: [0m eta: 1:49:45  iter: 66859  total_loss: 1.024  loss_cls: 0.1473  loss_ctr: 0.6015  loss_box_reg: 0.2659  time: 1.2906  data_time: 0.0143  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:12:54 d2.utils.events]: [0m eta: 1:49:20  iter: 66879  total_loss: 1.028  loss_cls: 0.149  loss_ctr: 0.6008  loss_box_reg: 0.2832  time: 1.2907  data_time: 0.0114  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:13:20 d2.utils.events]: [0m eta: 1:48:55  iter: 66899  total_loss: 1.029  loss_cls: 0.1485  loss_ctr: 0.6018  loss_box_reg: 0.281  time: 1.2906  data_time: 0.0119  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:13:46 d2.utils.events]: [0m eta: 1:48:29  iter: 66919  total_loss: 1.036  loss_cls: 0.1529  loss_ctr: 0.6027  loss_box_reg: 0.2803  time: 1.2906  data_time: 0.0141  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:14:11 d2.utils.events]: [0m eta: 1:48:03  iter: 66939  total_loss: 1.049  loss_cls: 0.1565  loss_ctr: 0.6025  loss_box_reg: 0.2883  time: 1.2906  data_time: 0.0138  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:14:37 d2.utils.events]: [0m eta: 1:47:38  iter: 66959  total_loss: 1.024  loss_cls: 0.1544  loss_ctr: 0.6016  loss_box_reg: 0.2677  time: 1.2906  data_time: 0.0144  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:15:02 d2.utils.events]: [0m eta: 1:47:11  iter: 66979  total_loss: 1.043  loss_cls: 0.1536  loss_ctr: 0.6035  loss_box_reg: 0.281  time: 1.2904  data_time: 0.0137  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:15:27 d2.utils.events]: [0m eta: 1:46:46  iter: 66999  total_loss: 1.033  loss_cls: 0.1581  loss_ctr: 0.602  loss_box_reg: 0.2723  time: 1.2904  data_time: 0.0158  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:15:53 d2.utils.events]: [0m eta: 1:46:20  iter: 67019  total_loss: 1.044  loss_cls: 0.1587  loss_ctr: 0.6045  loss_box_reg: 0.2843  time: 1.2903  data_time: 0.0150  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:16:19 d2.utils.events]: [0m eta: 1:45:55  iter: 67039  total_loss: 1.032  loss_cls: 0.1515  loss_ctr: 0.6025  loss_box_reg: 0.2782  time: 1.2903  data_time: 0.0175  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:16:44 d2.utils.events]: [0m eta: 1:45:27  iter: 67059  total_loss: 1.02  loss_cls: 0.1513  loss_ctr: 0.6018  loss_box_reg: 0.2659  time: 1.2902  data_time: 0.0133  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:17:10 d2.utils.events]: [0m eta: 1:45:02  iter: 67079  total_loss: 1.041  loss_cls: 0.1561  loss_ctr: 0.603  loss_box_reg: 0.2793  time: 1.2902  data_time: 0.0137  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:17:36 d2.utils.events]: [0m eta: 1:44:38  iter: 67099  total_loss: 1.038  loss_cls: 0.1609  loss_ctr: 0.6025  loss_box_reg: 0.276  time: 1.2902  data_time: 0.0171  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:18:01 d2.utils.events]: [0m eta: 1:44:12  iter: 67119  total_loss: 1.026  loss_cls: 0.1554  loss_ctr: 0.6007  loss_box_reg: 0.2763  time: 1.2902  data_time: 0.0146  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:18:27 d2.utils.events]: [0m eta: 1:43:46  iter: 67139  total_loss: 1.025  loss_cls: 0.1541  loss_ctr: 0.6027  loss_box_reg: 0.2729  time: 1.2901  data_time: 0.0139  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:18:52 d2.utils.events]: [0m eta: 1:43:19  iter: 67159  total_loss: 1.04  loss_cls: 0.1568  loss_ctr: 0.6026  loss_box_reg: 0.2865  time: 1.2900  data_time: 0.0143  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:19:18 d2.utils.events]: [0m eta: 1:42:53  iter: 67179  total_loss: 1.034  loss_cls: 0.1575  loss_ctr: 0.6036  loss_box_reg: 0.2758  time: 1.2900  data_time: 0.0130  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:19:43 d2.utils.events]: [0m eta: 1:42:27  iter: 67199  total_loss: 1.04  loss_cls: 0.1562  loss_ctr: 0.6015  loss_box_reg: 0.2819  time: 1.2899  data_time: 0.0158  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:20:09 d2.utils.events]: [0m eta: 1:42:03  iter: 67219  total_loss: 1.026  loss_cls: 0.1544  loss_ctr: 0.6014  loss_box_reg: 0.2721  time: 1.2899  data_time: 0.0133  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:20:35 d2.utils.events]: [0m eta: 1:41:39  iter: 67239  total_loss: 1.03  loss_cls: 0.1482  loss_ctr: 0.6008  loss_box_reg: 0.2683  time: 1.2899  data_time: 0.0122  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:21:01 d2.utils.events]: [0m eta: 1:41:13  iter: 67259  total_loss: 1.022  loss_cls: 0.1552  loss_ctr: 0.6011  loss_box_reg: 0.2731  time: 1.2899  data_time: 0.0135  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:21:26 d2.utils.events]: [0m eta: 1:40:48  iter: 67279  total_loss: 1.04  loss_cls: 0.1579  loss_ctr: 0.6027  loss_box_reg: 0.281  time: 1.2898  data_time: 0.0128  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:21:52 d2.utils.events]: [0m eta: 1:40:22  iter: 67299  total_loss: 1.032  loss_cls: 0.1553  loss_ctr: 0.6017  loss_box_reg: 0.2721  time: 1.2898  data_time: 0.0124  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:22:17 d2.utils.events]: [0m eta: 1:39:56  iter: 67319  total_loss: 1.031  loss_cls: 0.1523  loss_ctr: 0.6021  loss_box_reg: 0.2767  time: 1.2897  data_time: 0.0154  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:22:43 d2.utils.events]: [0m eta: 1:39:30  iter: 67339  total_loss: 1.032  loss_cls: 0.1579  loss_ctr: 0.6023  loss_box_reg: 0.2805  time: 1.2896  data_time: 0.0139  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:23:08 d2.utils.events]: [0m eta: 1:39:05  iter: 67359  total_loss: 1.022  loss_cls: 0.1498  loss_ctr: 0.6005  loss_box_reg: 0.2709  time: 1.2896  data_time: 0.0151  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:23:34 d2.utils.events]: [0m eta: 1:38:38  iter: 67379  total_loss: 1.045  loss_cls: 0.1546  loss_ctr: 0.604  loss_box_reg: 0.283  time: 1.2895  data_time: 0.0165  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:24:00 d2.utils.events]: [0m eta: 1:38:11  iter: 67399  total_loss: 1.057  loss_cls: 0.1646  loss_ctr: 0.6044  loss_box_reg: 0.2881  time: 1.2896  data_time: 0.0136  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:24:26 d2.utils.events]: [0m eta: 1:37:47  iter: 67419  total_loss: 1.015  loss_cls: 0.1503  loss_ctr: 0.5989  loss_box_reg: 0.2603  time: 1.2896  data_time: 0.0161  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:24:51 d2.utils.events]: [0m eta: 1:37:22  iter: 67439  total_loss: 1.031  loss_cls: 0.1507  loss_ctr: 0.6033  loss_box_reg: 0.2775  time: 1.2895  data_time: 0.0140  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:25:17 d2.utils.events]: [0m eta: 1:36:56  iter: 67459  total_loss: 1.048  loss_cls: 0.1548  loss_ctr: 0.604  loss_box_reg: 0.2861  time: 1.2894  data_time: 0.0125  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:25:42 d2.utils.events]: [0m eta: 1:36:29  iter: 67479  total_loss: 1.046  loss_cls: 0.1564  loss_ctr: 0.6025  loss_box_reg: 0.2881  time: 1.2894  data_time: 0.0147  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:26:08 d2.utils.events]: [0m eta: 1:36:06  iter: 67499  total_loss: 1.039  loss_cls: 0.1582  loss_ctr: 0.6019  loss_box_reg: 0.282  time: 1.2894  data_time: 0.0153  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:26:34 d2.utils.events]: [0m eta: 1:35:40  iter: 67519  total_loss: 1.017  loss_cls: 0.1455  loss_ctr: 0.6022  loss_box_reg: 0.2782  time: 1.2894  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:26:59 d2.utils.events]: [0m eta: 1:35:14  iter: 67539  total_loss: 1.038  loss_cls: 0.1495  loss_ctr: 0.6049  loss_box_reg: 0.284  time: 1.2893  data_time: 0.0153  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:27:25 d2.utils.events]: [0m eta: 1:34:49  iter: 67559  total_loss: 1.035  loss_cls: 0.1567  loss_ctr: 0.6017  loss_box_reg: 0.277  time: 1.2893  data_time: 0.0138  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:27:50 d2.utils.events]: [0m eta: 1:34:21  iter: 67579  total_loss: 1.029  loss_cls: 0.151  loss_ctr: 0.602  loss_box_reg: 0.2742  time: 1.2892  data_time: 0.0179  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:28:16 d2.utils.events]: [0m eta: 1:33:57  iter: 67599  total_loss: 1.055  loss_cls: 0.155  loss_ctr: 0.6024  loss_box_reg: 0.2876  time: 1.2892  data_time: 0.0167  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:28:42 d2.utils.events]: [0m eta: 1:33:30  iter: 67619  total_loss: 1.044  loss_cls: 0.1591  loss_ctr: 0.6022  loss_box_reg: 0.2875  time: 1.2891  data_time: 0.0143  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:29:07 d2.utils.events]: [0m eta: 1:33:04  iter: 67639  total_loss: 1.049  loss_cls: 0.1605  loss_ctr: 0.6033  loss_box_reg: 0.2885  time: 1.2891  data_time: 0.0157  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:29:33 d2.utils.events]: [0m eta: 1:32:35  iter: 67659  total_loss: 1.042  loss_cls: 0.1594  loss_ctr: 0.6035  loss_box_reg: 0.2854  time: 1.2890  data_time: 0.0128  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:29:58 d2.utils.events]: [0m eta: 1:32:08  iter: 67679  total_loss: 1.017  loss_cls: 0.1508  loss_ctr: 0.6  loss_box_reg: 0.2702  time: 1.2890  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:30:24 d2.utils.events]: [0m eta: 1:31:44  iter: 67699  total_loss: 1.028  loss_cls: 0.1547  loss_ctr: 0.6023  loss_box_reg: 0.2701  time: 1.2890  data_time: 0.0149  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:30:50 d2.utils.events]: [0m eta: 1:31:20  iter: 67719  total_loss: 1.029  loss_cls: 0.1534  loss_ctr: 0.6005  loss_box_reg: 0.2712  time: 1.2890  data_time: 0.0164  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:31:16 d2.utils.events]: [0m eta: 1:30:57  iter: 67739  total_loss: 1.046  loss_cls: 0.1575  loss_ctr: 0.6039  loss_box_reg: 0.2873  time: 1.2890  data_time: 0.0147  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:31:41 d2.utils.events]: [0m eta: 1:30:33  iter: 67759  total_loss: 1.028  loss_cls: 0.156  loss_ctr: 0.6026  loss_box_reg: 0.2751  time: 1.2890  data_time: 0.0156  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:32:07 d2.utils.events]: [0m eta: 1:30:08  iter: 67779  total_loss: 1.047  loss_cls: 0.1559  loss_ctr: 0.6015  loss_box_reg: 0.2847  time: 1.2889  data_time: 0.0159  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:32:32 d2.utils.events]: [0m eta: 1:29:42  iter: 67799  total_loss: 1.022  loss_cls: 0.1532  loss_ctr: 0.5995  loss_box_reg: 0.2699  time: 1.2889  data_time: 0.0151  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:32:58 d2.utils.events]: [0m eta: 1:29:20  iter: 67819  total_loss: 1.028  loss_cls: 0.1485  loss_ctr: 0.6006  loss_box_reg: 0.2744  time: 1.2889  data_time: 0.0137  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:33:24 d2.utils.events]: [0m eta: 1:28:53  iter: 67839  total_loss: 1.045  loss_cls: 0.1551  loss_ctr: 0.6031  loss_box_reg: 0.2809  time: 1.2889  data_time: 0.0184  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:33:50 d2.utils.events]: [0m eta: 1:28:23  iter: 67859  total_loss: 1.032  loss_cls: 0.158  loss_ctr: 0.6022  loss_box_reg: 0.2776  time: 1.2888  data_time: 0.0150  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:34:15 d2.utils.events]: [0m eta: 1:27:57  iter: 67879  total_loss: 1.042  loss_cls: 0.1612  loss_ctr: 0.6017  loss_box_reg: 0.2805  time: 1.2888  data_time: 0.0160  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:34:41 d2.utils.events]: [0m eta: 1:27:28  iter: 67899  total_loss: 1.037  loss_cls: 0.1504  loss_ctr: 0.6018  loss_box_reg: 0.2718  time: 1.2888  data_time: 0.0136  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:35:07 d2.utils.events]: [0m eta: 1:27:00  iter: 67919  total_loss: 1.022  loss_cls: 0.151  loss_ctr: 0.6001  loss_box_reg: 0.2736  time: 1.2887  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:35:32 d2.utils.events]: [0m eta: 1:26:36  iter: 67939  total_loss: 1.024  loss_cls: 0.1471  loss_ctr: 0.6016  loss_box_reg: 0.2786  time: 1.2887  data_time: 0.0138  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:35:58 d2.utils.events]: [0m eta: 1:26:07  iter: 67959  total_loss: 1.043  loss_cls: 0.1564  loss_ctr: 0.6019  loss_box_reg: 0.2798  time: 1.2886  data_time: 0.0123  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:36:23 d2.utils.events]: [0m eta: 1:25:47  iter: 67979  total_loss: 1.034  loss_cls: 0.1559  loss_ctr: 0.6011  loss_box_reg: 0.2751  time: 1.2886  data_time: 0.0153  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:36:49 d2.utils.events]: [0m eta: 1:25:19  iter: 67999  total_loss: 1.055  loss_cls: 0.1547  loss_ctr: 0.6044  loss_box_reg: 0.2858  time: 1.2885  data_time: 0.0167  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:37:14 d2.utils.events]: [0m eta: 1:24:54  iter: 68019  total_loss: 1.051  loss_cls: 0.1611  loss_ctr: 0.6012  loss_box_reg: 0.2837  time: 1.2885  data_time: 0.0147  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:37:39 d2.utils.events]: [0m eta: 1:24:23  iter: 68039  total_loss: 1.042  loss_cls: 0.1566  loss_ctr: 0.6022  loss_box_reg: 0.2784  time: 1.2884  data_time: 0.0137  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:38:05 d2.utils.events]: [0m eta: 1:23:57  iter: 68059  total_loss: 1.039  loss_cls: 0.1537  loss_ctr: 0.6022  loss_box_reg: 0.28  time: 1.2884  data_time: 0.0174  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:38:30 d2.utils.events]: [0m eta: 1:23:30  iter: 68079  total_loss: 1.021  loss_cls: 0.1505  loss_ctr: 0.5998  loss_box_reg: 0.2752  time: 1.2883  data_time: 0.0131  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:38:56 d2.utils.events]: [0m eta: 1:23:03  iter: 68099  total_loss: 1.03  loss_cls: 0.1526  loss_ctr: 0.6003  loss_box_reg: 0.274  time: 1.2883  data_time: 0.0137  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:39:22 d2.utils.events]: [0m eta: 1:22:38  iter: 68119  total_loss: 1.037  loss_cls: 0.156  loss_ctr: 0.6024  loss_box_reg: 0.2801  time: 1.2883  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:39:47 d2.utils.events]: [0m eta: 1:22:12  iter: 68139  total_loss: 1.035  loss_cls: 0.1493  loss_ctr: 0.603  loss_box_reg: 0.2812  time: 1.2883  data_time: 0.0214  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:40:13 d2.utils.events]: [0m eta: 1:21:47  iter: 68159  total_loss: 1.044  loss_cls: 0.1553  loss_ctr: 0.6032  loss_box_reg: 0.2826  time: 1.2882  data_time: 0.0187  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:40:39 d2.utils.events]: [0m eta: 1:21:23  iter: 68179  total_loss: 1.039  loss_cls: 0.1488  loss_ctr: 0.6039  loss_box_reg: 0.2833  time: 1.2882  data_time: 0.0129  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:41:05 d2.utils.events]: [0m eta: 1:21:04  iter: 68199  total_loss: 1.039  loss_cls: 0.1547  loss_ctr: 0.6019  loss_box_reg: 0.2885  time: 1.2882  data_time: 0.0137  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:41:31 d2.utils.events]: [0m eta: 1:20:38  iter: 68219  total_loss: 1.045  loss_cls: 0.1588  loss_ctr: 0.6022  loss_box_reg: 0.2868  time: 1.2882  data_time: 0.0133  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:41:56 d2.utils.events]: [0m eta: 1:20:11  iter: 68239  total_loss: 1.033  loss_cls: 0.1578  loss_ctr: 0.6018  loss_box_reg: 0.2776  time: 1.2882  data_time: 0.0150  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:42:22 d2.utils.events]: [0m eta: 1:19:47  iter: 68259  total_loss: 1.029  loss_cls: 0.15  loss_ctr: 0.6018  loss_box_reg: 0.2777  time: 1.2882  data_time: 0.0164  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:42:48 d2.utils.events]: [0m eta: 1:19:25  iter: 68279  total_loss: 1.026  loss_cls: 0.1509  loss_ctr: 0.6009  loss_box_reg: 0.2765  time: 1.2882  data_time: 0.0209  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:43:14 d2.utils.events]: [0m eta: 1:18:59  iter: 68299  total_loss: 1.022  loss_cls: 0.1479  loss_ctr: 0.6028  loss_box_reg: 0.2749  time: 1.2882  data_time: 0.0118  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:43:39 d2.utils.events]: [0m eta: 1:18:33  iter: 68319  total_loss: 1.032  loss_cls: 0.1549  loss_ctr: 0.601  loss_box_reg: 0.2698  time: 1.2882  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:44:05 d2.utils.events]: [0m eta: 1:18:09  iter: 68339  total_loss: 1.035  loss_cls: 0.1554  loss_ctr: 0.6032  loss_box_reg: 0.2788  time: 1.2881  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:44:30 d2.utils.events]: [0m eta: 1:17:42  iter: 68359  total_loss: 1.043  loss_cls: 0.1519  loss_ctr: 0.603  loss_box_reg: 0.2888  time: 1.2880  data_time: 0.0142  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:44:56 d2.utils.events]: [0m eta: 1:17:18  iter: 68379  total_loss: 1.033  loss_cls: 0.151  loss_ctr: 0.6034  loss_box_reg: 0.2791  time: 1.2880  data_time: 0.0129  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:45:21 d2.utils.events]: [0m eta: 1:16:51  iter: 68399  total_loss: 1.013  loss_cls: 0.1445  loss_ctr: 0.6019  loss_box_reg: 0.2711  time: 1.2879  data_time: 0.0169  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:45:46 d2.utils.events]: [0m eta: 1:16:22  iter: 68419  total_loss: 1.021  loss_cls: 0.148  loss_ctr: 0.6012  loss_box_reg: 0.2704  time: 1.2879  data_time: 0.0159  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:46:12 d2.utils.events]: [0m eta: 1:15:57  iter: 68439  total_loss: 1.02  loss_cls: 0.1455  loss_ctr: 0.602  loss_box_reg: 0.2703  time: 1.2879  data_time: 0.0198  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:46:38 d2.utils.events]: [0m eta: 1:15:34  iter: 68459  total_loss: 1.012  loss_cls: 0.1446  loss_ctr: 0.6008  loss_box_reg: 0.2605  time: 1.2879  data_time: 0.0123  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:47:04 d2.utils.events]: [0m eta: 1:15:11  iter: 68479  total_loss: 1.033  loss_cls: 0.156  loss_ctr: 0.6008  loss_box_reg: 0.2791  time: 1.2879  data_time: 0.0160  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:47:29 d2.utils.events]: [0m eta: 1:14:43  iter: 68499  total_loss: 1.05  loss_cls: 0.1599  loss_ctr: 0.6012  loss_box_reg: 0.277  time: 1.2878  data_time: 0.0153  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:47:55 d2.utils.events]: [0m eta: 1:14:14  iter: 68519  total_loss: 1.018  loss_cls: 0.1513  loss_ctr: 0.6008  loss_box_reg: 0.2744  time: 1.2878  data_time: 0.0160  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:48:20 d2.utils.events]: [0m eta: 1:13:47  iter: 68539  total_loss: 1.035  loss_cls: 0.1508  loss_ctr: 0.6042  loss_box_reg: 0.2848  time: 1.2877  data_time: 0.0178  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:48:46 d2.utils.events]: [0m eta: 1:13:21  iter: 68559  total_loss: 1.025  loss_cls: 0.1518  loss_ctr: 0.6005  loss_box_reg: 0.2729  time: 1.2877  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:49:11 d2.utils.events]: [0m eta: 1:12:57  iter: 68579  total_loss: 1.046  loss_cls: 0.1606  loss_ctr: 0.6029  loss_box_reg: 0.2843  time: 1.2877  data_time: 0.0143  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:49:37 d2.utils.events]: [0m eta: 1:12:31  iter: 68599  total_loss: 1.018  loss_cls: 0.1468  loss_ctr: 0.6028  loss_box_reg: 0.2669  time: 1.2877  data_time: 0.0171  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:50:03 d2.utils.events]: [0m eta: 1:12:07  iter: 68619  total_loss: 1.017  loss_cls: 0.1512  loss_ctr: 0.6012  loss_box_reg: 0.2669  time: 1.2877  data_time: 0.0162  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:50:29 d2.utils.events]: [0m eta: 1:11:43  iter: 68639  total_loss: 1.04  loss_cls: 0.1566  loss_ctr: 0.6003  loss_box_reg: 0.273  time: 1.2877  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:50:55 d2.utils.events]: [0m eta: 1:11:19  iter: 68659  total_loss: 1.047  loss_cls: 0.157  loss_ctr: 0.602  loss_box_reg: 0.284  time: 1.2876  data_time: 0.0134  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:51:20 d2.utils.events]: [0m eta: 1:10:52  iter: 68679  total_loss: 1.032  loss_cls: 0.1511  loss_ctr: 0.6011  loss_box_reg: 0.2765  time: 1.2876  data_time: 0.0126  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:51:46 d2.utils.events]: [0m eta: 1:10:26  iter: 68699  total_loss: 1.016  loss_cls: 0.1436  loss_ctr: 0.6017  loss_box_reg: 0.2712  time: 1.2876  data_time: 0.0138  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:52:12 d2.utils.events]: [0m eta: 1:10:01  iter: 68719  total_loss: 1.023  loss_cls: 0.1507  loss_ctr: 0.6032  loss_box_reg: 0.2745  time: 1.2876  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:52:38 d2.utils.events]: [0m eta: 1:09:33  iter: 68739  total_loss: 1.026  loss_cls: 0.1495  loss_ctr: 0.6017  loss_box_reg: 0.276  time: 1.2876  data_time: 0.0152  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:53:04 d2.utils.events]: [0m eta: 1:09:07  iter: 68759  total_loss: 1.037  loss_cls: 0.151  loss_ctr: 0.6027  loss_box_reg: 0.2854  time: 1.2876  data_time: 0.0138  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:53:30 d2.utils.events]: [0m eta: 1:08:42  iter: 68779  total_loss: 1.034  loss_cls: 0.1569  loss_ctr: 0.602  loss_box_reg: 0.2717  time: 1.2876  data_time: 0.0150  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:53:55 d2.utils.events]: [0m eta: 1:08:15  iter: 68799  total_loss: 1.049  loss_cls: 0.1564  loss_ctr: 0.6017  loss_box_reg: 0.2877  time: 1.2876  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:54:21 d2.utils.events]: [0m eta: 1:07:47  iter: 68819  total_loss: 1.028  loss_cls: 0.1522  loss_ctr: 0.6021  loss_box_reg: 0.2732  time: 1.2876  data_time: 0.0141  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:54:46 d2.utils.events]: [0m eta: 1:07:21  iter: 68839  total_loss: 1.017  loss_cls: 0.1491  loss_ctr: 0.6009  loss_box_reg: 0.2699  time: 1.2875  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:55:12 d2.utils.events]: [0m eta: 1:06:58  iter: 68859  total_loss: 1.039  loss_cls: 0.1568  loss_ctr: 0.6014  loss_box_reg: 0.277  time: 1.2875  data_time: 0.0226  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:55:38 d2.utils.events]: [0m eta: 1:06:31  iter: 68879  total_loss: 1.037  loss_cls: 0.1533  loss_ctr: 0.6022  loss_box_reg: 0.2811  time: 1.2875  data_time: 0.0187  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:56:04 d2.utils.events]: [0m eta: 1:06:10  iter: 68899  total_loss: 1.036  loss_cls: 0.1529  loss_ctr: 0.603  loss_box_reg: 0.2789  time: 1.2875  data_time: 0.0194  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:56:30 d2.utils.events]: [0m eta: 1:05:45  iter: 68919  total_loss: 1.041  loss_cls: 0.1548  loss_ctr: 0.5992  loss_box_reg: 0.2853  time: 1.2875  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:56:55 d2.utils.events]: [0m eta: 1:05:21  iter: 68939  total_loss: 1.022  loss_cls: 0.1481  loss_ctr: 0.6001  loss_box_reg: 0.271  time: 1.2875  data_time: 0.0185  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:57:21 d2.utils.events]: [0m eta: 1:04:56  iter: 68959  total_loss: 1.031  loss_cls: 0.156  loss_ctr: 0.5982  loss_box_reg: 0.2717  time: 1.2875  data_time: 0.0179  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:57:47 d2.utils.events]: [0m eta: 1:04:31  iter: 68979  total_loss: 1.033  loss_cls: 0.152  loss_ctr: 0.602  loss_box_reg: 0.2756  time: 1.2875  data_time: 0.0148  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:58:13 d2.utils.events]: [0m eta: 1:04:05  iter: 68999  total_loss: 1.033  loss_cls: 0.1529  loss_ctr: 0.6015  loss_box_reg: 0.2806  time: 1.2875  data_time: 0.0161  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:58:38 d2.utils.events]: [0m eta: 1:03:38  iter: 69019  total_loss: 1.028  loss_cls: 0.1477  loss_ctr: 0.6006  loss_box_reg: 0.2786  time: 1.2874  data_time: 0.0168  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:59:03 d2.utils.events]: [0m eta: 1:03:13  iter: 69039  total_loss: 1.039  loss_cls: 0.1546  loss_ctr: 0.6022  loss_box_reg: 0.2784  time: 1.2874  data_time: 0.0143  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:59:29 d2.utils.events]: [0m eta: 1:02:48  iter: 69059  total_loss: 1.043  loss_cls: 0.1554  loss_ctr: 0.6017  loss_box_reg: 0.2834  time: 1.2873  data_time: 0.0151  lr: 1e-05  max_mem: 25928M
[32m[11/03 17:59:54 d2.utils.events]: [0m eta: 1:02:22  iter: 69079  total_loss: 1.027  loss_cls: 0.1541  loss_ctr: 0.6005  loss_box_reg: 0.2749  time: 1.2873  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:00:20 d2.utils.events]: [0m eta: 1:01:57  iter: 69099  total_loss: 1.025  loss_cls: 0.1554  loss_ctr: 0.5986  loss_box_reg: 0.2666  time: 1.2873  data_time: 0.0165  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:00:46 d2.utils.events]: [0m eta: 1:01:29  iter: 69119  total_loss: 1.008  loss_cls: 0.1507  loss_ctr: 0.5995  loss_box_reg: 0.2598  time: 1.2873  data_time: 0.0175  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:01:11 d2.utils.events]: [0m eta: 1:01:05  iter: 69139  total_loss: 1.014  loss_cls: 0.1544  loss_ctr: 0.5994  loss_box_reg: 0.2648  time: 1.2872  data_time: 0.0134  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:01:37 d2.utils.events]: [0m eta: 1:00:40  iter: 69159  total_loss: 1.014  loss_cls: 0.1441  loss_ctr: 0.6014  loss_box_reg: 0.2665  time: 1.2872  data_time: 0.0153  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:02:02 d2.utils.events]: [0m eta: 1:00:13  iter: 69179  total_loss: 1.01  loss_cls: 0.1428  loss_ctr: 0.6  loss_box_reg: 0.2718  time: 1.2872  data_time: 0.0136  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:02:28 d2.utils.events]: [0m eta: 0:59:46  iter: 69199  total_loss: 1.035  loss_cls: 0.1523  loss_ctr: 0.6025  loss_box_reg: 0.2765  time: 1.2872  data_time: 0.0128  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:02:54 d2.utils.events]: [0m eta: 0:59:17  iter: 69219  total_loss: 1.022  loss_cls: 0.1569  loss_ctr: 0.6009  loss_box_reg: 0.259  time: 1.2871  data_time: 0.0134  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:03:19 d2.utils.events]: [0m eta: 0:58:55  iter: 69239  total_loss: 1.011  loss_cls: 0.1462  loss_ctr: 0.5994  loss_box_reg: 0.2619  time: 1.2871  data_time: 0.0148  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:03:45 d2.utils.events]: [0m eta: 0:58:30  iter: 69259  total_loss: 1.036  loss_cls: 0.1544  loss_ctr: 0.6023  loss_box_reg: 0.2827  time: 1.2871  data_time: 0.0162  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:04:11 d2.utils.events]: [0m eta: 0:58:04  iter: 69279  total_loss: 1.03  loss_cls: 0.1539  loss_ctr: 0.6012  loss_box_reg: 0.2767  time: 1.2871  data_time: 0.0182  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:04:36 d2.utils.events]: [0m eta: 0:57:34  iter: 69299  total_loss: 1.041  loss_cls: 0.156  loss_ctr: 0.6022  loss_box_reg: 0.281  time: 1.2870  data_time: 0.0163  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:05:02 d2.utils.events]: [0m eta: 0:57:08  iter: 69319  total_loss: 1.027  loss_cls: 0.1518  loss_ctr: 0.6013  loss_box_reg: 0.2716  time: 1.2870  data_time: 0.0190  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:05:27 d2.utils.events]: [0m eta: 0:56:44  iter: 69339  total_loss: 1.021  loss_cls: 0.1504  loss_ctr: 0.6004  loss_box_reg: 0.2675  time: 1.2870  data_time: 0.0146  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:05:53 d2.utils.events]: [0m eta: 0:56:21  iter: 69359  total_loss: 1.029  loss_cls: 0.1507  loss_ctr: 0.6009  loss_box_reg: 0.2753  time: 1.2870  data_time: 0.0125  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:06:19 d2.utils.events]: [0m eta: 0:55:55  iter: 69379  total_loss: 1.022  loss_cls: 0.1546  loss_ctr: 0.6001  loss_box_reg: 0.2683  time: 1.2869  data_time: 0.0143  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:06:44 d2.utils.events]: [0m eta: 0:55:30  iter: 69399  total_loss: 1.028  loss_cls: 0.1487  loss_ctr: 0.6021  loss_box_reg: 0.2795  time: 1.2869  data_time: 0.0151  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:07:10 d2.utils.events]: [0m eta: 0:55:05  iter: 69419  total_loss: 1.036  loss_cls: 0.1487  loss_ctr: 0.6042  loss_box_reg: 0.2832  time: 1.2869  data_time: 0.0156  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:07:36 d2.utils.events]: [0m eta: 0:54:42  iter: 69439  total_loss: 1.051  loss_cls: 0.1566  loss_ctr: 0.604  loss_box_reg: 0.2885  time: 1.2869  data_time: 0.0154  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:08:01 d2.utils.events]: [0m eta: 0:54:15  iter: 69459  total_loss: 1.021  loss_cls: 0.1509  loss_ctr: 0.5997  loss_box_reg: 0.2659  time: 1.2869  data_time: 0.0133  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:08:27 d2.utils.events]: [0m eta: 0:53:50  iter: 69479  total_loss: 1.043  loss_cls: 0.1544  loss_ctr: 0.6018  loss_box_reg: 0.2882  time: 1.2869  data_time: 0.0181  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:08:53 d2.utils.events]: [0m eta: 0:53:24  iter: 69499  total_loss: 1.036  loss_cls: 0.1541  loss_ctr: 0.6012  loss_box_reg: 0.2785  time: 1.2868  data_time: 0.0145  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:09:18 d2.utils.events]: [0m eta: 0:53:00  iter: 69519  total_loss: 1.033  loss_cls: 0.1582  loss_ctr: 0.6024  loss_box_reg: 0.2749  time: 1.2868  data_time: 0.0137  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:09:44 d2.utils.events]: [0m eta: 0:52:36  iter: 69539  total_loss: 1.009  loss_cls: 0.1475  loss_ctr: 0.6002  loss_box_reg: 0.2643  time: 1.2868  data_time: 0.0149  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:10:09 d2.utils.events]: [0m eta: 0:52:09  iter: 69559  total_loss: 1.015  loss_cls: 0.1474  loss_ctr: 0.6014  loss_box_reg: 0.2696  time: 1.2867  data_time: 0.0107  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:10:34 d2.utils.events]: [0m eta: 0:51:44  iter: 69579  total_loss: 1.033  loss_cls: 0.1478  loss_ctr: 0.6023  loss_box_reg: 0.2775  time: 1.2867  data_time: 0.0153  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:11:00 d2.utils.events]: [0m eta: 0:51:17  iter: 69599  total_loss: 1.016  loss_cls: 0.1435  loss_ctr: 0.6004  loss_box_reg: 0.2701  time: 1.2867  data_time: 0.0124  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:11:26 d2.utils.events]: [0m eta: 0:50:49  iter: 69619  total_loss: 1.034  loss_cls: 0.1551  loss_ctr: 0.6025  loss_box_reg: 0.2775  time: 1.2866  data_time: 0.0176  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:11:51 d2.utils.events]: [0m eta: 0:50:24  iter: 69639  total_loss: 1.049  loss_cls: 0.1581  loss_ctr: 0.6003  loss_box_reg: 0.2858  time: 1.2866  data_time: 0.0162  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:12:17 d2.utils.events]: [0m eta: 0:49:59  iter: 69659  total_loss: 1.043  loss_cls: 0.1529  loss_ctr: 0.6039  loss_box_reg: 0.2831  time: 1.2866  data_time: 0.0135  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:12:43 d2.utils.events]: [0m eta: 0:49:34  iter: 69679  total_loss: 1.035  loss_cls: 0.1587  loss_ctr: 0.6022  loss_box_reg: 0.2721  time: 1.2866  data_time: 0.0162  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:13:09 d2.utils.events]: [0m eta: 0:49:07  iter: 69699  total_loss: 1.041  loss_cls: 0.1552  loss_ctr: 0.6044  loss_box_reg: 0.2811  time: 1.2866  data_time: 0.0164  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:13:35 d2.utils.events]: [0m eta: 0:48:42  iter: 69719  total_loss: 1.023  loss_cls: 0.1496  loss_ctr: 0.6014  loss_box_reg: 0.2676  time: 1.2866  data_time: 0.0151  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:14:00 d2.utils.events]: [0m eta: 0:48:16  iter: 69739  total_loss: 1.037  loss_cls: 0.1525  loss_ctr: 0.6025  loss_box_reg: 0.2821  time: 1.2866  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:14:26 d2.utils.events]: [0m eta: 0:47:50  iter: 69759  total_loss: 1.029  loss_cls: 0.1499  loss_ctr: 0.6007  loss_box_reg: 0.2751  time: 1.2866  data_time: 0.0164  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:14:51 d2.utils.events]: [0m eta: 0:47:25  iter: 69779  total_loss: 1.026  loss_cls: 0.1538  loss_ctr: 0.6024  loss_box_reg: 0.2729  time: 1.2865  data_time: 0.0136  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:15:17 d2.utils.events]: [0m eta: 0:47:01  iter: 69799  total_loss: 1.031  loss_cls: 0.1492  loss_ctr: 0.6026  loss_box_reg: 0.2771  time: 1.2865  data_time: 0.0123  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:15:42 d2.utils.events]: [0m eta: 0:46:35  iter: 69819  total_loss: 1.019  loss_cls: 0.1495  loss_ctr: 0.6002  loss_box_reg: 0.264  time: 1.2865  data_time: 0.0166  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:16:08 d2.utils.events]: [0m eta: 0:46:09  iter: 69839  total_loss: 1.025  loss_cls: 0.1533  loss_ctr: 0.6008  loss_box_reg: 0.2752  time: 1.2864  data_time: 0.0150  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:16:33 d2.utils.events]: [0m eta: 0:45:42  iter: 69859  total_loss: 1.045  loss_cls: 0.1535  loss_ctr: 0.603  loss_box_reg: 0.2931  time: 1.2864  data_time: 0.0139  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:16:59 d2.utils.events]: [0m eta: 0:45:17  iter: 69879  total_loss: 1.007  loss_cls: 0.1471  loss_ctr: 0.5983  loss_box_reg: 0.2587  time: 1.2864  data_time: 0.0129  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:17:24 d2.utils.events]: [0m eta: 0:44:51  iter: 69899  total_loss: 1.033  loss_cls: 0.1516  loss_ctr: 0.6017  loss_box_reg: 0.2837  time: 1.2863  data_time: 0.0155  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:17:50 d2.utils.events]: [0m eta: 0:44:23  iter: 69919  total_loss: 1.036  loss_cls: 0.1497  loss_ctr: 0.6012  loss_box_reg: 0.279  time: 1.2863  data_time: 0.0112  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:18:15 d2.utils.events]: [0m eta: 0:43:54  iter: 69939  total_loss: 1.024  loss_cls: 0.1531  loss_ctr: 0.5995  loss_box_reg: 0.276  time: 1.2863  data_time: 0.0126  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:18:41 d2.utils.events]: [0m eta: 0:43:27  iter: 69959  total_loss: 1.024  loss_cls: 0.1522  loss_ctr: 0.6019  loss_box_reg: 0.2727  time: 1.2862  data_time: 0.0145  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:19:06 d2.utils.events]: [0m eta: 0:42:59  iter: 69979  total_loss: 1.03  loss_cls: 0.1537  loss_ctr: 0.6006  loss_box_reg: 0.268  time: 1.2861  data_time: 0.0156  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:19:31 fvcore.common.checkpoint]: [0mSaving checkpoint to ./results/COCO/dh/dh_swint_fpn_COCO_concepts_cat/model_0069999.pth
[32m[11/03 18:19:34 d2.utils.events]: [0m eta: 0:42:34  iter: 69999  total_loss: 1.042  loss_cls: 0.1506  loss_ctr: 0.6054  loss_box_reg: 0.2867  time: 1.2861  data_time: 0.0108  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:20:00 d2.utils.events]: [0m eta: 0:42:10  iter: 70019  total_loss: 1.036  loss_cls: 0.1585  loss_ctr: 0.6021  loss_box_reg: 0.2731  time: 1.2861  data_time: 0.0117  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:20:25 d2.utils.events]: [0m eta: 0:41:43  iter: 70039  total_loss: 1.026  loss_cls: 0.1535  loss_ctr: 0.602  loss_box_reg: 0.2747  time: 1.2860  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:20:51 d2.utils.events]: [0m eta: 0:41:19  iter: 70059  total_loss: 1.041  loss_cls: 0.1579  loss_ctr: 0.6027  loss_box_reg: 0.2783  time: 1.2860  data_time: 0.0124  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:21:16 d2.utils.events]: [0m eta: 0:40:52  iter: 70079  total_loss: 1.031  loss_cls: 0.1483  loss_ctr: 0.6025  loss_box_reg: 0.2748  time: 1.2860  data_time: 0.0125  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:21:42 d2.utils.events]: [0m eta: 0:40:27  iter: 70099  total_loss: 1.032  loss_cls: 0.1489  loss_ctr: 0.6032  loss_box_reg: 0.2724  time: 1.2860  data_time: 0.0140  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:22:08 d2.utils.events]: [0m eta: 0:40:03  iter: 70119  total_loss: 1.022  loss_cls: 0.1485  loss_ctr: 0.6019  loss_box_reg: 0.2708  time: 1.2860  data_time: 0.0156  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:22:33 d2.utils.events]: [0m eta: 0:39:37  iter: 70139  total_loss: 1.029  loss_cls: 0.154  loss_ctr: 0.602  loss_box_reg: 0.2822  time: 1.2860  data_time: 0.0137  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:22:59 d2.utils.events]: [0m eta: 0:39:14  iter: 70159  total_loss: 1.009  loss_cls: 0.1449  loss_ctr: 0.6  loss_box_reg: 0.2667  time: 1.2860  data_time: 0.0109  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:23:25 d2.utils.events]: [0m eta: 0:38:51  iter: 70179  total_loss: 1.044  loss_cls: 0.1487  loss_ctr: 0.5997  loss_box_reg: 0.2823  time: 1.2860  data_time: 0.0126  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:23:51 d2.utils.events]: [0m eta: 0:38:21  iter: 70199  total_loss: 1.019  loss_cls: 0.1518  loss_ctr: 0.6002  loss_box_reg: 0.2721  time: 1.2859  data_time: 0.0120  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:24:16 d2.utils.events]: [0m eta: 0:37:58  iter: 70219  total_loss: 1.027  loss_cls: 0.1543  loss_ctr: 0.6011  loss_box_reg: 0.2745  time: 1.2859  data_time: 0.0123  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:24:42 d2.utils.events]: [0m eta: 0:37:30  iter: 70239  total_loss: 1.034  loss_cls: 0.1567  loss_ctr: 0.6025  loss_box_reg: 0.2759  time: 1.2859  data_time: 0.0141  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:25:07 d2.utils.events]: [0m eta: 0:37:03  iter: 70259  total_loss: 1.035  loss_cls: 0.1561  loss_ctr: 0.6024  loss_box_reg: 0.2865  time: 1.2858  data_time: 0.0129  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:25:32 d2.utils.events]: [0m eta: 0:36:36  iter: 70279  total_loss: 1.028  loss_cls: 0.1528  loss_ctr: 0.5997  loss_box_reg: 0.2757  time: 1.2858  data_time: 0.0110  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:25:58 d2.utils.events]: [0m eta: 0:36:12  iter: 70299  total_loss: 1.022  loss_cls: 0.1453  loss_ctr: 0.6026  loss_box_reg: 0.2649  time: 1.2857  data_time: 0.0129  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:26:23 d2.utils.events]: [0m eta: 0:35:47  iter: 70319  total_loss: 1.019  loss_cls: 0.148  loss_ctr: 0.601  loss_box_reg: 0.2612  time: 1.2857  data_time: 0.0135  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:26:49 d2.utils.events]: [0m eta: 0:35:20  iter: 70339  total_loss: 1.038  loss_cls: 0.1519  loss_ctr: 0.6013  loss_box_reg: 0.277  time: 1.2857  data_time: 0.0118  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:27:14 d2.utils.events]: [0m eta: 0:34:55  iter: 70359  total_loss: 1.022  loss_cls: 0.152  loss_ctr: 0.6014  loss_box_reg: 0.2685  time: 1.2856  data_time: 0.0116  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:27:40 d2.utils.events]: [0m eta: 0:34:29  iter: 70379  total_loss: 1.025  loss_cls: 0.1473  loss_ctr: 0.6011  loss_box_reg: 0.2724  time: 1.2856  data_time: 0.0118  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:28:05 d2.utils.events]: [0m eta: 0:34:03  iter: 70399  total_loss: 1.038  loss_cls: 0.1502  loss_ctr: 0.6003  loss_box_reg: 0.2775  time: 1.2856  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:28:31 d2.utils.events]: [0m eta: 0:33:37  iter: 70419  total_loss: 1.044  loss_cls: 0.1514  loss_ctr: 0.6024  loss_box_reg: 0.2901  time: 1.2855  data_time: 0.0106  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:28:56 d2.utils.events]: [0m eta: 0:33:10  iter: 70439  total_loss: 1.038  loss_cls: 0.1541  loss_ctr: 0.6016  loss_box_reg: 0.2864  time: 1.2855  data_time: 0.0122  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:29:22 d2.utils.events]: [0m eta: 0:32:46  iter: 70459  total_loss: 1.046  loss_cls: 0.1531  loss_ctr: 0.6003  loss_box_reg: 0.287  time: 1.2855  data_time: 0.0129  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:29:47 d2.utils.events]: [0m eta: 0:32:20  iter: 70479  total_loss: 1.031  loss_cls: 0.1541  loss_ctr: 0.6029  loss_box_reg: 0.2811  time: 1.2855  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:30:13 d2.utils.events]: [0m eta: 0:31:55  iter: 70499  total_loss: 1.01  loss_cls: 0.1481  loss_ctr: 0.6006  loss_box_reg: 0.2652  time: 1.2854  data_time: 0.0114  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:30:38 d2.utils.events]: [0m eta: 0:31:29  iter: 70519  total_loss: 1.029  loss_cls: 0.1509  loss_ctr: 0.6042  loss_box_reg: 0.2814  time: 1.2854  data_time: 0.0129  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:31:03 d2.utils.events]: [0m eta: 0:31:03  iter: 70539  total_loss: 1.022  loss_cls: 0.1445  loss_ctr: 0.6016  loss_box_reg: 0.2755  time: 1.2854  data_time: 0.0118  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:31:29 d2.utils.events]: [0m eta: 0:30:39  iter: 70559  total_loss: 1.022  loss_cls: 0.1444  loss_ctr: 0.5999  loss_box_reg: 0.2687  time: 1.2853  data_time: 0.0117  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:31:54 d2.utils.events]: [0m eta: 0:30:13  iter: 70579  total_loss: 1.043  loss_cls: 0.1551  loss_ctr: 0.6036  loss_box_reg: 0.2833  time: 1.2853  data_time: 0.0119  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:32:20 d2.utils.events]: [0m eta: 0:29:47  iter: 70599  total_loss: 1.007  loss_cls: 0.144  loss_ctr: 0.6021  loss_box_reg: 0.2644  time: 1.2853  data_time: 0.0134  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:32:45 d2.utils.events]: [0m eta: 0:29:23  iter: 70619  total_loss: 1.034  loss_cls: 0.1563  loss_ctr: 0.6036  loss_box_reg: 0.2703  time: 1.2853  data_time: 0.0110  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:33:11 d2.utils.events]: [0m eta: 0:28:58  iter: 70639  total_loss: 1.05  loss_cls: 0.1592  loss_ctr: 0.6013  loss_box_reg: 0.2858  time: 1.2853  data_time: 0.0131  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:33:37 d2.utils.events]: [0m eta: 0:28:32  iter: 70659  total_loss: 1.024  loss_cls: 0.1455  loss_ctr: 0.6021  loss_box_reg: 0.2687  time: 1.2852  data_time: 0.0144  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:34:02 d2.utils.events]: [0m eta: 0:28:06  iter: 70679  total_loss: 1.031  loss_cls: 0.1503  loss_ctr: 0.6017  loss_box_reg: 0.2802  time: 1.2852  data_time: 0.0115  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:34:28 d2.utils.events]: [0m eta: 0:27:40  iter: 70699  total_loss: 1.025  loss_cls: 0.1519  loss_ctr: 0.6018  loss_box_reg: 0.2715  time: 1.2851  data_time: 0.0114  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:34:53 d2.utils.events]: [0m eta: 0:27:14  iter: 70719  total_loss: 1.025  loss_cls: 0.1515  loss_ctr: 0.601  loss_box_reg: 0.2744  time: 1.2851  data_time: 0.0124  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:35:18 d2.utils.events]: [0m eta: 0:26:48  iter: 70739  total_loss: 1.03  loss_cls: 0.1537  loss_ctr: 0.6013  loss_box_reg: 0.2756  time: 1.2851  data_time: 0.0112  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:35:43 d2.utils.events]: [0m eta: 0:26:22  iter: 70759  total_loss: 1.018  loss_cls: 0.1515  loss_ctr: 0.5996  loss_box_reg: 0.2656  time: 1.2850  data_time: 0.0116  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:36:09 d2.utils.events]: [0m eta: 0:25:57  iter: 70779  total_loss: 1.032  loss_cls: 0.1515  loss_ctr: 0.6023  loss_box_reg: 0.2749  time: 1.2850  data_time: 0.0119  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:36:34 d2.utils.events]: [0m eta: 0:25:31  iter: 70799  total_loss: 1.039  loss_cls: 0.1549  loss_ctr: 0.603  loss_box_reg: 0.2811  time: 1.2849  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:36:59 d2.utils.events]: [0m eta: 0:25:05  iter: 70819  total_loss: 1.013  loss_cls: 0.1514  loss_ctr: 0.6006  loss_box_reg: 0.2702  time: 1.2849  data_time: 0.0128  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:37:25 d2.utils.events]: [0m eta: 0:24:40  iter: 70839  total_loss: 1.044  loss_cls: 0.1542  loss_ctr: 0.6022  loss_box_reg: 0.2807  time: 1.2849  data_time: 0.0115  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:37:50 d2.utils.events]: [0m eta: 0:24:14  iter: 70859  total_loss: 1.031  loss_cls: 0.1547  loss_ctr: 0.601  loss_box_reg: 0.2746  time: 1.2848  data_time: 0.0145  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:38:16 d2.utils.events]: [0m eta: 0:23:49  iter: 70879  total_loss: 1.023  loss_cls: 0.1468  loss_ctr: 0.5995  loss_box_reg: 0.2712  time: 1.2848  data_time: 0.0114  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:38:41 d2.utils.events]: [0m eta: 0:23:23  iter: 70899  total_loss: 0.9997  loss_cls: 0.1448  loss_ctr: 0.599  loss_box_reg: 0.2582  time: 1.2848  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:39:07 d2.utils.events]: [0m eta: 0:22:58  iter: 70919  total_loss: 1.026  loss_cls: 0.1521  loss_ctr: 0.602  loss_box_reg: 0.275  time: 1.2848  data_time: 0.0136  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:39:33 d2.utils.events]: [0m eta: 0:22:33  iter: 70939  total_loss: 1.043  loss_cls: 0.1542  loss_ctr: 0.6027  loss_box_reg: 0.2828  time: 1.2847  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:39:58 d2.utils.events]: [0m eta: 0:22:08  iter: 70959  total_loss: 1.051  loss_cls: 0.1574  loss_ctr: 0.6041  loss_box_reg: 0.2895  time: 1.2847  data_time: 0.0142  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:40:23 d2.utils.events]: [0m eta: 0:21:43  iter: 70979  total_loss: 1.013  loss_cls: 0.1496  loss_ctr: 0.5997  loss_box_reg: 0.2636  time: 1.2847  data_time: 0.0181  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:40:49 d2.utils.events]: [0m eta: 0:21:19  iter: 70999  total_loss: 1.038  loss_cls: 0.153  loss_ctr: 0.6028  loss_box_reg: 0.2845  time: 1.2846  data_time: 0.0123  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:41:15 d2.utils.events]: [0m eta: 0:20:54  iter: 71019  total_loss: 1.033  loss_cls: 0.1523  loss_ctr: 0.6004  loss_box_reg: 0.2805  time: 1.2847  data_time: 0.0169  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:41:41 d2.utils.events]: [0m eta: 0:20:29  iter: 71039  total_loss: 1.018  loss_cls: 0.1502  loss_ctr: 0.6011  loss_box_reg: 0.2631  time: 1.2847  data_time: 0.0116  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:42:06 d2.utils.events]: [0m eta: 0:20:03  iter: 71059  total_loss: 1.031  loss_cls: 0.1493  loss_ctr: 0.6027  loss_box_reg: 0.2769  time: 1.2846  data_time: 0.0131  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:42:32 d2.utils.events]: [0m eta: 0:19:38  iter: 71079  total_loss: 1.035  loss_cls: 0.1567  loss_ctr: 0.602  loss_box_reg: 0.2797  time: 1.2846  data_time: 0.0144  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:42:57 d2.utils.events]: [0m eta: 0:19:12  iter: 71099  total_loss: 1.023  loss_cls: 0.1507  loss_ctr: 0.601  loss_box_reg: 0.2712  time: 1.2846  data_time: 0.0123  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:43:22 d2.utils.events]: [0m eta: 0:18:45  iter: 71119  total_loss: 1.036  loss_cls: 0.1484  loss_ctr: 0.6011  loss_box_reg: 0.2816  time: 1.2845  data_time: 0.0124  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:43:48 d2.utils.events]: [0m eta: 0:18:20  iter: 71139  total_loss: 1.02  loss_cls: 0.1479  loss_ctr: 0.6022  loss_box_reg: 0.2722  time: 1.2845  data_time: 0.0144  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:44:13 d2.utils.events]: [0m eta: 0:17:53  iter: 71159  total_loss: 1.04  loss_cls: 0.1571  loss_ctr: 0.6015  loss_box_reg: 0.2772  time: 1.2844  data_time: 0.0122  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:44:38 d2.utils.events]: [0m eta: 0:17:27  iter: 71179  total_loss: 1.029  loss_cls: 0.1536  loss_ctr: 0.6029  loss_box_reg: 0.2761  time: 1.2844  data_time: 0.0131  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:45:03 d2.utils.events]: [0m eta: 0:17:02  iter: 71199  total_loss: 1.028  loss_cls: 0.1563  loss_ctr: 0.6018  loss_box_reg: 0.2734  time: 1.2843  data_time: 0.0126  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:45:28 d2.utils.events]: [0m eta: 0:16:35  iter: 71219  total_loss: 1.029  loss_cls: 0.1532  loss_ctr: 0.6015  loss_box_reg: 0.273  time: 1.2842  data_time: 0.0109  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:45:53 d2.utils.events]: [0m eta: 0:16:09  iter: 71239  total_loss: 1.024  loss_cls: 0.15  loss_ctr: 0.6015  loss_box_reg: 0.2782  time: 1.2842  data_time: 0.0116  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:46:18 d2.utils.events]: [0m eta: 0:15:42  iter: 71259  total_loss: 1.032  loss_cls: 0.1522  loss_ctr: 0.6014  loss_box_reg: 0.2799  time: 1.2841  data_time: 0.0139  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:46:43 d2.utils.events]: [0m eta: 0:15:17  iter: 71279  total_loss: 1.025  loss_cls: 0.1522  loss_ctr: 0.6021  loss_box_reg: 0.2749  time: 1.2840  data_time: 0.0121  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:47:08 d2.utils.events]: [0m eta: 0:14:51  iter: 71299  total_loss: 1.044  loss_cls: 0.1532  loss_ctr: 0.6035  loss_box_reg: 0.2865  time: 1.2840  data_time: 0.0135  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:47:33 d2.utils.events]: [0m eta: 0:14:26  iter: 71319  total_loss: 1.027  loss_cls: 0.1553  loss_ctr: 0.6015  loss_box_reg: 0.2717  time: 1.2839  data_time: 0.0128  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:47:59 d2.utils.events]: [0m eta: 0:14:00  iter: 71339  total_loss: 1.023  loss_cls: 0.1505  loss_ctr: 0.6015  loss_box_reg: 0.272  time: 1.2839  data_time: 0.0133  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:48:24 d2.utils.events]: [0m eta: 0:13:35  iter: 71359  total_loss: 1.022  loss_cls: 0.1477  loss_ctr: 0.6023  loss_box_reg: 0.2695  time: 1.2839  data_time: 0.0147  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:48:50 d2.utils.events]: [0m eta: 0:13:09  iter: 71379  total_loss: 1.027  loss_cls: 0.146  loss_ctr: 0.6014  loss_box_reg: 0.2724  time: 1.2839  data_time: 0.0134  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:49:16 d2.utils.events]: [0m eta: 0:12:44  iter: 71399  total_loss: 1.018  loss_cls: 0.1512  loss_ctr: 0.5986  loss_box_reg: 0.2697  time: 1.2839  data_time: 0.0129  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:49:41 d2.utils.events]: [0m eta: 0:12:19  iter: 71419  total_loss: 1.016  loss_cls: 0.1483  loss_ctr: 0.6009  loss_box_reg: 0.2655  time: 1.2839  data_time: 0.0138  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:50:07 d2.utils.events]: [0m eta: 0:11:54  iter: 71439  total_loss: 1.02  loss_cls: 0.1522  loss_ctr: 0.6009  loss_box_reg: 0.2734  time: 1.2838  data_time: 0.0165  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:50:32 d2.utils.events]: [0m eta: 0:11:28  iter: 71459  total_loss: 1.012  loss_cls: 0.1435  loss_ctr: 0.6007  loss_box_reg: 0.2658  time: 1.2838  data_time: 0.0131  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:50:57 d2.utils.events]: [0m eta: 0:11:02  iter: 71479  total_loss: 1.046  loss_cls: 0.1525  loss_ctr: 0.6027  loss_box_reg: 0.2818  time: 1.2837  data_time: 0.0164  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:51:23 d2.utils.events]: [0m eta: 0:10:36  iter: 71499  total_loss: 1.019  loss_cls: 0.1486  loss_ctr: 0.6001  loss_box_reg: 0.2654  time: 1.2837  data_time: 0.0129  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:51:48 d2.utils.events]: [0m eta: 0:10:11  iter: 71519  total_loss: 1.027  loss_cls: 0.1505  loss_ctr: 0.6013  loss_box_reg: 0.2652  time: 1.2837  data_time: 0.0135  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:52:14 d2.utils.events]: [0m eta: 0:09:45  iter: 71539  total_loss: 1.023  loss_cls: 0.1441  loss_ctr: 0.6035  loss_box_reg: 0.2723  time: 1.2837  data_time: 0.0123  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:52:40 d2.utils.events]: [0m eta: 0:09:20  iter: 71559  total_loss: 1.028  loss_cls: 0.1503  loss_ctr: 0.6015  loss_box_reg: 0.2768  time: 1.2837  data_time: 0.0151  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:53:05 d2.utils.events]: [0m eta: 0:08:54  iter: 71579  total_loss: 1.012  loss_cls: 0.1548  loss_ctr: 0.6011  loss_box_reg: 0.2658  time: 1.2837  data_time: 0.0141  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:53:30 d2.utils.events]: [0m eta: 0:08:29  iter: 71599  total_loss: 1.029  loss_cls: 0.1502  loss_ctr: 0.6014  loss_box_reg: 0.2737  time: 1.2836  data_time: 0.0119  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:53:56 d2.utils.events]: [0m eta: 0:08:03  iter: 71619  total_loss: 1.002  loss_cls: 0.1418  loss_ctr: 0.6011  loss_box_reg: 0.2626  time: 1.2836  data_time: 0.0127  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:54:21 d2.utils.events]: [0m eta: 0:07:37  iter: 71639  total_loss: 1.022  loss_cls: 0.1532  loss_ctr: 0.6002  loss_box_reg: 0.2676  time: 1.2836  data_time: 0.0115  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:54:47 d2.utils.events]: [0m eta: 0:07:12  iter: 71659  total_loss: 1.032  loss_cls: 0.1527  loss_ctr: 0.603  loss_box_reg: 0.2797  time: 1.2835  data_time: 0.0134  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:55:12 d2.utils.events]: [0m eta: 0:06:47  iter: 71679  total_loss: 1.034  loss_cls: 0.151  loss_ctr: 0.6035  loss_box_reg: 0.2796  time: 1.2835  data_time: 0.0147  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:55:38 d2.utils.events]: [0m eta: 0:06:21  iter: 71699  total_loss: 1.031  loss_cls: 0.1494  loss_ctr: 0.6036  loss_box_reg: 0.2752  time: 1.2835  data_time: 0.0151  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:56:03 d2.utils.events]: [0m eta: 0:05:56  iter: 71719  total_loss: 1.037  loss_cls: 0.1499  loss_ctr: 0.6012  loss_box_reg: 0.2867  time: 1.2835  data_time: 0.0142  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:56:29 d2.utils.events]: [0m eta: 0:05:31  iter: 71739  total_loss: 1.042  loss_cls: 0.1543  loss_ctr: 0.6026  loss_box_reg: 0.2788  time: 1.2835  data_time: 0.0105  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:56:54 d2.utils.events]: [0m eta: 0:05:05  iter: 71759  total_loss: 1.016  loss_cls: 0.1493  loss_ctr: 0.6004  loss_box_reg: 0.2676  time: 1.2834  data_time: 0.0122  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:57:20 d2.utils.events]: [0m eta: 0:04:40  iter: 71779  total_loss: 1.035  loss_cls: 0.1467  loss_ctr: 0.6016  loss_box_reg: 0.2807  time: 1.2835  data_time: 0.0135  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:57:45 d2.utils.events]: [0m eta: 0:04:14  iter: 71799  total_loss: 1.02  loss_cls: 0.1511  loss_ctr: 0.6013  loss_box_reg: 0.2717  time: 1.2834  data_time: 0.0148  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:58:11 d2.utils.events]: [0m eta: 0:03:49  iter: 71819  total_loss: 1.029  loss_cls: 0.149  loss_ctr: 0.6  loss_box_reg: 0.2751  time: 1.2834  data_time: 0.0157  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:58:37 d2.utils.events]: [0m eta: 0:03:23  iter: 71839  total_loss: 1.035  loss_cls: 0.1524  loss_ctr: 0.6008  loss_box_reg: 0.2781  time: 1.2834  data_time: 0.0109  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:59:02 d2.utils.events]: [0m eta: 0:02:58  iter: 71859  total_loss: 1.029  loss_cls: 0.1529  loss_ctr: 0.602  loss_box_reg: 0.2747  time: 1.2834  data_time: 0.0117  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:59:28 d2.utils.events]: [0m eta: 0:02:32  iter: 71879  total_loss: 1.031  loss_cls: 0.1524  loss_ctr: 0.6008  loss_box_reg: 0.2794  time: 1.2834  data_time: 0.0140  lr: 1e-05  max_mem: 25928M
[32m[11/03 18:59:54 d2.utils.events]: [0m eta: 0:02:07  iter: 71899  total_loss: 1.02  loss_cls: 0.1524  loss_ctr: 0.6016  loss_box_reg: 0.2665  time: 1.2834  data_time: 0.0123  lr: 1e-05  max_mem: 25928M
[32m[11/03 19:00:19 d2.utils.events]: [0m eta: 0:01:41  iter: 71919  total_loss: 0.9981  loss_cls: 0.1472  loss_ctr: 0.5995  loss_box_reg: 0.2616  time: 1.2834  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 19:00:45 d2.utils.events]: [0m eta: 0:01:16  iter: 71939  total_loss: 1.042  loss_cls: 0.153  loss_ctr: 0.6005  loss_box_reg: 0.2814  time: 1.2834  data_time: 0.0172  lr: 1e-05  max_mem: 25928M
[32m[11/03 19:01:11 d2.utils.events]: [0m eta: 0:00:50  iter: 71959  total_loss: 1.016  loss_cls: 0.1487  loss_ctr: 0.5987  loss_box_reg: 0.2668  time: 1.2834  data_time: 0.0132  lr: 1e-05  max_mem: 25928M
[32m[11/03 19:01:36 d2.utils.events]: [0m eta: 0:00:25  iter: 71979  total_loss: 1.015  loss_cls: 0.1449  loss_ctr: 0.6006  loss_box_reg: 0.2662  time: 1.2834  data_time: 0.0148  lr: 1e-05  max_mem: 25928M
[32m[11/03 19:02:02 fvcore.common.checkpoint]: [0mSaving checkpoint to ./results/COCO/dh/dh_swint_fpn_COCO_concepts_cat/model_final.pth
[32m[11/03 19:02:03 d2.utils.events]: [0m eta: 0:00:00  iter: 71999  total_loss: 1.02  loss_cls: 0.1428  loss_ctr: 0.6029  loss_box_reg: 0.2769  time: 1.2834  data_time: 0.0147  lr: 1e-05  max_mem: 25928M
[32m[11/03 19:02:03 d2.engine.hooks]: [0mOverall training speed: 11998 iterations in 4:16:37 (1.2834 s / it)
[32m[11/03 19:02:03 d2.engine.hooks]: [0mTotal training time: 4:17:40 (0:01:02 on hooks)
Load concept for each category. 
Load concept for each category. 
Load concept for each category. 
Load concept for each category. 
[32m[11/03 19:02:05 d2.data.datasets.coco]: [0mLoading datasets/tuning_coco/annotations/tuning_instances_val2017.json takes 1.62 seconds.
[32m[11/03 19:02:05 d2.data.datasets.coco]: [0mLoaded 5000 images in COCO format from datasets/tuning_coco/annotations/tuning_instances_val2017.json
[32m[11/03 19:02:05 d2.data.build]: [0mRemoved 44 images with no usable annotations. 4956 images left.
Load concept for each category. 
Load concept for each category. 
Load concept for each category. 
[32m[11/03 19:02:06 d2.data.build]: [0mDistribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10499        |   bicycle    | 263          |      car      | 1723         |
|  motorcycle   | 337          |   airplane   | 216          |      bus      | 231          |
|     train     | 208          |    truck     | 440          |     boat      | 471          |
| traffic light | 583          | fire hydrant | 84           |   stop sign   | 82           |
| parking meter | 34           |    bench     | 351          |     bird      | 546          |
|      cat      | 193          |     dog      | 245          |     horse     | 307          |
|     sheep     | 348          |     cow      | 293          |   elephant    | 263          |
|     bear      | 53           |    zebra     | 228          |    giraffe    | 212          |
|   backpack    | 398          |   umbrella   | 478          |    handbag    | 526          |
|      tie      | 286          |   suitcase   | 271          |    frisbee    | 100          |
|     skis      | 290          |  snowboard   | 84           |  sports ball  | 247          |
|     kite      | 313          | baseball bat | 150          | baseball gl.. | 169          |
|  skateboard   | 211          |  surfboard   | 223          | tennis racket | 212          |
|    bottle     | 985          |  wine glass  | 384          |      cup      | 789          |
|     fork      | 209          |    knife     | 291          |     spoon     | 252          |
|     bowl      | 680          |    banana    | 399          |     apple     | 190          |
|   sandwich    | 186          |    orange    | 281          |   broccoli    | 318          |
|    carrot     | 317          |   hot dog    | 104          |     pizza     | 226          |
|     donut     | 277          |     cake     | 311          |     chair     | 1703         |
|     couch     | 228          | potted plant | 378          |      bed      | 187          |
| dining table  | 640          |    toilet    | 169          |      tv       | 240          |
|    laptop     | 198          |    mouse     | 82           |    remote     | 250          |
|   keyboard    | 119          |  cell phone  | 290          |   microwave   | 69           |
|     oven      | 139          |   toaster    | 9            |     sink      | 196          |
| refrigerator  | 119          |     book     | 995          |     clock     | 259          |
|     vase      | 306          |   scissors   | 120          |  teddy bear   | 191          |
|  hair drier   | 5            |  toothbrush  | 75           |               |              |
|     total     | 35334        |              |              |               |              |[0m
[32m[11/03 19:02:06 d2.data.common]: [0mSerializing 4956 elements to byte tensors and concatenating them all ...
Load concept for each category. 
[32m[11/03 19:02:06 d2.data.common]: [0mSerialized dataset takes 18.88 MiB
[5m[31mWARNING[0m [32m[11/03 19:02:06 d2.evaluation.coco_evaluation]: [0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.
[32m[11/03 19:02:06 d2.evaluation.evaluator]: [0mStart inference on 620 batches
[32m[11/03 19:04:10 d2.evaluation.evaluator]: [0mInference done 11/620. Dataloading: 0.0006 s/iter. Inference: 0.1009 s/iter. Eval: 0.0003 s/iter. Total: 0.1019 s/iter. ETA=0:01:02
[32m[11/03 19:04:15 d2.evaluation.evaluator]: [0mInference done 46/620. Dataloading: 0.0039 s/iter. Inference: 0.1334 s/iter. Eval: 0.0006 s/iter. Total: 0.1406 s/iter. ETA=0:01:20
[32m[11/03 19:04:20 d2.evaluation.evaluator]: [0mInference done 74/620. Dataloading: 0.0040 s/iter. Inference: 0.1500 s/iter. Eval: 0.0005 s/iter. Total: 0.1561 s/iter. ETA=0:01:25
[32m[11/03 19:04:25 d2.evaluation.evaluator]: [0mInference done 98/620. Dataloading: 0.0039 s/iter. Inference: 0.1666 s/iter. Eval: 0.0004 s/iter. Total: 0.1723 s/iter. ETA=0:01:29
[32m[11/03 19:04:30 d2.evaluation.evaluator]: [0mInference done 122/620. Dataloading: 0.0046 s/iter. Inference: 0.1737 s/iter. Eval: 0.0004 s/iter. Total: 0.1798 s/iter. ETA=0:01:29
[32m[11/03 19:04:35 d2.evaluation.evaluator]: [0mInference done 145/620. Dataloading: 0.0053 s/iter. Inference: 0.1796 s/iter. Eval: 0.0004 s/iter. Total: 0.1862 s/iter. ETA=0:01:28
[32m[11/03 19:04:40 d2.evaluation.evaluator]: [0mInference done 164/620. Dataloading: 0.0051 s/iter. Inference: 0.1904 s/iter. Eval: 0.0004 s/iter. Total: 0.1967 s/iter. ETA=0:01:29
[32m[11/03 19:04:46 d2.evaluation.evaluator]: [0mInference done 185/620. Dataloading: 0.0051 s/iter. Inference: 0.1958 s/iter. Eval: 0.0004 s/iter. Total: 0.2020 s/iter. ETA=0:01:27
[32m[11/03 19:04:51 d2.evaluation.evaluator]: [0mInference done 204/620. Dataloading: 0.0049 s/iter. Inference: 0.2020 s/iter. Eval: 0.0004 s/iter. Total: 0.2079 s/iter. ETA=0:01:26
[32m[11/03 19:04:56 d2.evaluation.evaluator]: [0mInference done 229/620. Dataloading: 0.0048 s/iter. Inference: 0.2018 s/iter. Eval: 0.0004 s/iter. Total: 0.2077 s/iter. ETA=0:01:21
[32m[11/03 19:05:01 d2.evaluation.evaluator]: [0mInference done 261/620. Dataloading: 0.0049 s/iter. Inference: 0.1956 s/iter. Eval: 0.0004 s/iter. Total: 0.2015 s/iter. ETA=0:01:12
[32m[11/03 19:05:06 d2.evaluation.evaluator]: [0mInference done 293/620. Dataloading: 0.0047 s/iter. Inference: 0.1909 s/iter. Eval: 0.0004 s/iter. Total: 0.1965 s/iter. ETA=0:01:04
[32m[11/03 19:05:11 d2.evaluation.evaluator]: [0mInference done 337/620. Dataloading: 0.0045 s/iter. Inference: 0.1805 s/iter. Eval: 0.0004 s/iter. Total: 0.1859 s/iter. ETA=0:00:52
[32m[11/03 19:05:16 d2.evaluation.evaluator]: [0mInference done 379/620. Dataloading: 0.0044 s/iter. Inference: 0.1733 s/iter. Eval: 0.0004 s/iter. Total: 0.1785 s/iter. ETA=0:00:43
[32m[11/03 19:05:21 d2.evaluation.evaluator]: [0mInference done 422/620. Dataloading: 0.0043 s/iter. Inference: 0.1672 s/iter. Eval: 0.0004 s/iter. Total: 0.1722 s/iter. ETA=0:00:34
[32m[11/03 19:05:26 d2.evaluation.evaluator]: [0mInference done 469/620. Dataloading: 0.0042 s/iter. Inference: 0.1610 s/iter. Eval: 0.0004 s/iter. Total: 0.1659 s/iter. ETA=0:00:25
[32m[11/03 19:05:31 d2.evaluation.evaluator]: [0mInference done 520/620. Dataloading: 0.0041 s/iter. Inference: 0.1545 s/iter. Eval: 0.0004 s/iter. Total: 0.1593 s/iter. ETA=0:00:15
[32m[11/03 19:05:36 d2.evaluation.evaluator]: [0mInference done 585/620. Dataloading: 0.0039 s/iter. Inference: 0.1456 s/iter. Eval: 0.0004 s/iter. Total: 0.1501 s/iter. ETA=0:00:05
[32m[11/03 19:05:40 d2.evaluation.evaluator]: [0mTotal inference time: 0:01:30.643538 (0.147388 s / iter per device, on 8 devices)
[32m[11/03 19:05:40 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:01:27 (0.141497 s / iter per device, on 8 devices)
[32m[11/03 19:05:42 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[11/03 19:05:42 d2.evaluation.coco_evaluation]: [0mSaving results to ./results/COCO/dh/dh_swint_fpn_COCO_concepts_cat/inference/coco_instances_results.json
[32m[11/03 19:05:43 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with official COCO API...
Loading and preparing results...
DONE (t=1.22s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=24.22s).
Accumulating evaluation results...
DONE (t=3.50s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.443
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.599
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.483
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.295
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.562
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.316
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.524
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.562
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.409
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.685
[32m[11/03 19:06:12 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 44.349 | 59.915 | 48.274 | 29.504 | 47.611 | 56.210 |
[32m[11/03 19:06:12 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 46.499 | bicycle      | 30.923 | car            | 38.399 |
| motorcycle    | 45.760 | airplane     | 66.238 | bus            | 59.004 |
| train         | 60.646 | truck        | 41.617 | boat           | 33.249 |
| traffic light | 26.467 | fire hydrant | 67.184 | stop sign      | 69.842 |
| parking meter | 58.082 | bench        | 32.514 | bird           | 42.769 |
| cat           | 58.253 | dog          | 63.863 | horse          | 62.134 |
| sheep         | 70.087 | cow          | 63.361 | elephant       | 75.347 |
| bear          | 84.851 | zebra        | 73.059 | giraffe        | 79.248 |
| backpack      | 23.285 | umbrella     | 36.327 | handbag        | 22.715 |
| tie           | 41.896 | suitcase     | 44.356 | frisbee        | 59.189 |
| skis          | 33.136 | snowboard    | 45.185 | sports ball    | 36.932 |
| kite          | 42.474 | baseball bat | 38.597 | baseball glove | 31.806 |
| skateboard    | 46.910 | surfboard    | 40.444 | tennis racket  | 42.740 |
| bottle        | 34.623 | wine glass   | 42.066 | cup            | 37.985 |
| fork          | 33.896 | knife        | 26.651 | spoon          | 27.019 |
| bowl          | 38.574 | banana       | 29.856 | apple          | 38.281 |
| sandwich      | 36.088 | orange       | 34.519 | broccoli       | 30.156 |
| carrot        | 31.447 | hot dog      | 46.896 | pizza          | 55.432 |
| donut         | 60.104 | cake         | 40.929 | chair          | 26.934 |
| couch         | 42.835 | potted plant | 30.181 | bed            | 50.090 |
| dining table  | 33.233 | toilet       | 60.445 | tv             | 45.287 |
| laptop        | 59.658 | mouse        | 45.054 | remote         | 39.069 |
| keyboard      | 43.574 | cell phone   | 39.973 | microwave      | 48.348 |
| oven          | 35.114 | toaster      | 30.762 | sink           | 40.425 |
| refrigerator  | 42.198 | book         | 18.520 | clock          | 52.141 |
| vase          | 52.807 | scissors     | 38.486 | teddy bear     | 48.269 |
| hair drier    | 8.317  | toothbrush   | 36.253 |                |        |
[32m[11/03 19:06:12 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[11/03 19:06:12 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[11/03 19:06:12 d2.evaluation.testing]: [0mcopypaste: 44.3486,59.9153,48.2743,29.5040,47.6109,56.2101
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                bbox/AP ▁
wandb:       bbox/AP-airplane ▁
wandb:          bbox/AP-apple ▁
wandb:       bbox/AP-backpack ▁
wandb:         bbox/AP-banana ▁
wandb:   bbox/AP-baseball bat ▁
wandb: bbox/AP-baseball glove ▁
wandb:           bbox/AP-bear ▁
wandb:            bbox/AP-bed ▁
wandb:          bbox/AP-bench ▁
wandb:        bbox/AP-bicycle ▁
wandb:           bbox/AP-bird ▁
wandb:           bbox/AP-boat ▁
wandb:           bbox/AP-book ▁
wandb:         bbox/AP-bottle ▁
wandb:           bbox/AP-bowl ▁
wandb:       bbox/AP-broccoli ▁
wandb:            bbox/AP-bus ▁
wandb:           bbox/AP-cake ▁
wandb:            bbox/AP-car ▁
wandb:         bbox/AP-carrot ▁
wandb:            bbox/AP-cat ▁
wandb:     bbox/AP-cell phone ▁
wandb:          bbox/AP-chair ▁
wandb:          bbox/AP-clock ▁
wandb:          bbox/AP-couch ▁
wandb:            bbox/AP-cow ▁
wandb:            bbox/AP-cup ▁
wandb:   bbox/AP-dining table ▁
wandb:            bbox/AP-dog ▁
wandb:          bbox/AP-donut ▁
wandb:       bbox/AP-elephant ▁
wandb:   bbox/AP-fire hydrant ▁
wandb:           bbox/AP-fork ▁
wandb:        bbox/AP-frisbee ▁
wandb:        bbox/AP-giraffe ▁
wandb:     bbox/AP-hair drier ▁
wandb:        bbox/AP-handbag ▁
wandb:          bbox/AP-horse ▁
wandb:        bbox/AP-hot dog ▁
wandb:       bbox/AP-keyboard ▁
wandb:           bbox/AP-kite ▁
wandb:          bbox/AP-knife ▁
wandb:         bbox/AP-laptop ▁
wandb:      bbox/AP-microwave ▁
wandb:     bbox/AP-motorcycle ▁
wandb:          bbox/AP-mouse ▁
wandb:         bbox/AP-orange ▁
wandb:           bbox/AP-oven ▁
wandb:  bbox/AP-parking meter ▁
wandb:         bbox/AP-person ▁
wandb:          bbox/AP-pizza ▁
wandb:   bbox/AP-potted plant ▁
wandb:   bbox/AP-refrigerator ▁
wandb:         bbox/AP-remote ▁
wandb:       bbox/AP-sandwich ▁
wandb:       bbox/AP-scissors ▁
wandb:          bbox/AP-sheep ▁
wandb:           bbox/AP-sink ▁
wandb:     bbox/AP-skateboard ▁
wandb:           bbox/AP-skis ▁
wandb:      bbox/AP-snowboard ▁
wandb:          bbox/AP-spoon ▁
wandb:    bbox/AP-sports ball ▁
wandb:      bbox/AP-stop sign ▁
wandb:       bbox/AP-suitcase ▁
wandb:      bbox/AP-surfboard ▁
wandb:     bbox/AP-teddy bear ▁
wandb:  bbox/AP-tennis racket ▁
wandb:            bbox/AP-tie ▁
wandb:        bbox/AP-toaster ▁
wandb:         bbox/AP-toilet ▁
wandb:     bbox/AP-toothbrush ▁
wandb:  bbox/AP-traffic light ▁
wandb:          bbox/AP-train ▁
wandb:          bbox/AP-truck ▁
wandb:             bbox/AP-tv ▁
wandb:       bbox/AP-umbrella ▁
wandb:           bbox/AP-vase ▁
wandb:     bbox/AP-wine glass ▁
wandb:          bbox/AP-zebra ▁
wandb:              bbox/AP50 ▁
wandb:              bbox/AP75 ▁
wandb:               bbox/APl ▁
wandb:               bbox/APm ▁
wandb:               bbox/APs ▁
wandb:              data_time ▃▂▂▃▃▃▃▄▂▃▂▄▃▃▁▃▅▃▄▄▁▄▅▇▃▂█▃▂▅▅▄▄▂▁▂▂▂▄▄
wandb:            eta_seconds ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:            global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:           loss_box_reg ▆▇█▅█▇█▇▄▆▆▆▆▅▆▄▆▅▅▃▁▄▄▄▃▃▆▃▃▃▁▆▄▄▄▄▂▃▅▄
wandb:               loss_cls ▆▇▇▇▇▇██▆▅▅▅▄▃▄▆▇▅▄▃▄▃▃▄▃▃▅▅▅▅▃▅▃▃▃▄▃▂▃▁
wandb:               loss_ctr ▅▅█▅▆▇▇▆▇▅▅▆▇▇▆▅▆▄▆▄▂▅▄▆▄▃█▄▃▁▂▇▄▆▃▄▄▆▇▆
wandb:                     lr ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                   time ▅▃▃▅▁▁▅▄▅▆▂▄▃▅▃▆▅▅█▅▅▆▂▆▅▆▁▆▆▅▃▇▄▃▄▃▆▃▃▆
wandb:             total_loss ▇▇▇▅▇▇█▇▅▅▆▆▆▅▅▅▆▅▅▂▁▃▄▄▃▂▇▄▅▄▁▆▄▄▅▃▂▃▄▂
wandb: 
wandb: Run summary:
wandb:                bbox/AP 44.34855
wandb:       bbox/AP-airplane 66.23763
wandb:          bbox/AP-apple 38.28139
wandb:       bbox/AP-backpack 23.28534
wandb:         bbox/AP-banana 29.85592
wandb:   bbox/AP-baseball bat 38.597
wandb: bbox/AP-baseball glove 31.80597
wandb:           bbox/AP-bear 84.8511
wandb:            bbox/AP-bed 50.09013
wandb:          bbox/AP-bench 32.51437
wandb:        bbox/AP-bicycle 30.92311
wandb:           bbox/AP-bird 42.76947
wandb:           bbox/AP-boat 33.24916
wandb:           bbox/AP-book 18.52013
wandb:         bbox/AP-bottle 34.62349
wandb:           bbox/AP-bowl 38.57389
wandb:       bbox/AP-broccoli 30.15642
wandb:            bbox/AP-bus 59.00389
wandb:           bbox/AP-cake 40.92922
wandb:            bbox/AP-car 38.39922
wandb:         bbox/AP-carrot 31.44687
wandb:            bbox/AP-cat 58.2527
wandb:     bbox/AP-cell phone 39.97348
wandb:          bbox/AP-chair 26.9336
wandb:          bbox/AP-clock 52.14059
wandb:          bbox/AP-couch 42.83472
wandb:            bbox/AP-cow 63.36067
wandb:            bbox/AP-cup 37.98491
wandb:   bbox/AP-dining table 33.23278
wandb:            bbox/AP-dog 63.86285
wandb:          bbox/AP-donut 60.10396
wandb:       bbox/AP-elephant 75.34731
wandb:   bbox/AP-fire hydrant 67.18423
wandb:           bbox/AP-fork 33.89565
wandb:        bbox/AP-frisbee 59.18919
wandb:        bbox/AP-giraffe 79.24821
wandb:     bbox/AP-hair drier 8.31683
wandb:        bbox/AP-handbag 22.71546
wandb:          bbox/AP-horse 62.13393
wandb:        bbox/AP-hot dog 46.89573
wandb:       bbox/AP-keyboard 43.57408
wandb:           bbox/AP-kite 42.47388
wandb:          bbox/AP-knife 26.6509
wandb:         bbox/AP-laptop 59.65799
wandb:      bbox/AP-microwave 48.34806
wandb:     bbox/AP-motorcycle 45.76031
wandb:          bbox/AP-mouse 45.05374
wandb:         bbox/AP-orange 34.51883
wandb:           bbox/AP-oven 35.11418
wandb:  bbox/AP-parking meter 58.08206
wandb:         bbox/AP-person 46.4992
wandb:          bbox/AP-pizza 55.43172
wandb:   bbox/AP-potted plant 30.1807
wandb:   bbox/AP-refrigerator 42.19775
wandb:         bbox/AP-remote 39.06908
wandb:       bbox/AP-sandwich 36.08751
wandb:       bbox/AP-scissors 38.48564
wandb:          bbox/AP-sheep 70.08668
wandb:           bbox/AP-sink 40.4253
wandb:     bbox/AP-skateboard 46.9104
wandb:           bbox/AP-skis 33.1364
wandb:      bbox/AP-snowboard 45.1849
wandb:          bbox/AP-spoon 27.01877
wandb:    bbox/AP-sports ball 36.93206
wandb:      bbox/AP-stop sign 69.84235
wandb:       bbox/AP-suitcase 44.35602
wandb:      bbox/AP-surfboard 40.44441
wandb:     bbox/AP-teddy bear 48.26915
wandb:  bbox/AP-tennis racket 42.73956
wandb:            bbox/AP-tie 41.8965
wandb:        bbox/AP-toaster 30.76184
wandb:         bbox/AP-toilet 60.44495
wandb:     bbox/AP-toothbrush 36.25286
wandb:  bbox/AP-traffic light 26.46744
wandb:          bbox/AP-train 60.64589
wandb:          bbox/AP-truck 41.61671
wandb:             bbox/AP-tv 45.28717
wandb:       bbox/AP-umbrella 36.32651
wandb:           bbox/AP-vase 52.80676
wandb:     bbox/AP-wine glass 42.06631
wandb:          bbox/AP-zebra 73.05895
wandb:              bbox/AP50 59.9153
wandb:              bbox/AP75 48.27433
wandb:               bbox/APl 56.21013
wandb:               bbox/APm 47.61094
wandb:               bbox/APs 29.50403
wandb:              data_time 0.0128
wandb:            eta_seconds 0.0
wandb:            global_step 72000
wandb:           loss_box_reg 0.2769
wandb:               loss_cls 0.14276
wandb:               loss_ctr 0.60289
wandb:                     lr 1e-05
wandb:                   time 1.29185
wandb:             total_loss 1.01958
wandb: 
wandb: Synced gentle-sponge-449: https://wandb.ai/drigoni/CATSS/runs/ee6odywa
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)
wandb: Find logs at: ./wandb/run-20221103_143620-ee6odywa/logs


Job done.
Date:  gio 3 nov 2022, 19.07.45, CET
