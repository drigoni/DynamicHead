
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX 
Date:  mer 19 ott 2022, 17.58.05, CEST
Directory:  /ceph/hpc/home/eudavider/repository/DynamicHead
Nodelist:  gn21
Number of nodes:  1
Ntasks per node:  1
NGPUs per node:  4
CUDA_VISIBLE_DEVICES:  0,1,2,3
TORCH_DEVICE_COUNT:  4
SLURM_MASTER_PORT:  11671
SLURM_MASTER_NODE:  gn21
SLURM_MASTER_ADDR:  gn21
SLURM_MASTER_URL:  tcp://gn21:11671
--------------------------------------------- 
MODEL_NUM_GPUS:  4
MODEL_NUM_MACHINES:  1
MODEL_BATCH_SIZE:  16
MODEL_MAX_ITER:  90000
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX 

srun: error: WARNING: Multiple leaf switches contain nodes: gn[01-60]
[nltk_data] Downloading package omw-1.4 to
[nltk_data]     /ceph/hpc/home/eudavider/nltk_data...
[nltk_data]   Package omw-1.4 is already up-to-date!
[nltk_data] Downloading package wordnet to
[nltk_data]     /ceph/hpc/home/eudavider/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
Command Line Args: Namespace(config_file='./configs/OID/retinanet/r50/retinanet_r50_fpn_OID_concepts_train_cat.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://gn21:11671', opts=['SOLVER.IMS_PER_BATCH', '16', 'SOLVER.MAX_ITER', '90000'])
Loading config ./configs/OID/retinanet/r50/../base_retinanet_OID_concepts.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config ./configs/OID/retinanet/r50/../base_retinanet_OID_concepts.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config ./configs/OID/retinanet/r50/../base_retinanet_OID_concepts.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Loading config ./configs/OID/retinanet/r50/../base_retinanet_OID_concepts.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
[32m[10/19 17:58:51 detectron2]: [0mRank of current process: 0. World size: 4
[32m[10/19 17:58:56 detectron2]: [0mEnvironment info:
----------------------  ------------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]
numpy                   1.23.1
detectron2              0.6 @/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 11.3
detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5, 8.0, 8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.0 @/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA A100-SXM4-40GB (arch=8.0)
Driver version          510.47.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.2.0
torchvision             0.11.0 @/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20220512
iopath                  0.1.9
cv2                     Not found
----------------------  ------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[32m[10/19 17:58:56 detectron2]: [0mCommand line arguments: Namespace(config_file='./configs/OID/retinanet/r50/retinanet_r50_fpn_OID_concepts_train_cat.yaml', resume=False, eval_only=False, num_gpus=4, num_machines=1, machine_rank=0, dist_url='tcp://gn21:11671', opts=['SOLVER.IMS_PER_BATCH', '16', 'SOLVER.MAX_ITER', '90000'])
[32m[10/19 17:58:56 detectron2]: [0mContents of args.config_file=./configs/OID/retinanet/r50/retinanet_r50_fpn_OID_concepts_train_cat.yaml:
_BASE_: "../base_retinanet_OID_concepts.yaml"
MODEL:
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  MASK_ON: False
  RESNETS:
    DEPTH: 50
CONCEPT:
  CONCEPT_FUSION: "cat" # ["cat", "mul", "add", "zeros"]
OUTPUT_DIR: "./results/OID/retinanet/retinanet_r50_fpn_OID_concepts_cat/"
[32m[10/19 17:58:56 detectron2]: [0mRunning with full config:
CONCEPT:
  APPLY_CONDITION: true
  APPLY_CONDITION_FROM_FILE: false
  ACTIVATE_CONCEPT_GENERATOR: true
  CONCEPT_FUSION: cat
  DEPTH: 2
  EXTERNAL_CONCEPTS_FOLDER: ./datasets/ewiser_concepts_oid_valid/
  FILE: ./concept/oid_to_synset.json
  ONLY_NAME: true
  UNIQUE: true
  VOCAB: ./concept/vocab.json
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 32
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - oid_v4_val
  TRAIN:
  - oid_v4_train
DEEPSETS:
  AGGREGATE: sum
  EMB: wordnet
  EMB_DIM: 150
  FILE: ./concept/wn30_holE_500_150_0.1_0.2_embeddings.pickle
  FREEZE: false
  MLP1_LAYERS:
  - 150
  - 256
  MLP1_OUTPUT_DIM: 256
  MLP2_LAYERS:
  - 256
  - 256
  OUTPUT_DIM: 256
EVALUATOR_TYPE: default
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: false
    SIZE:
    - 0.9
    - 0.9
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN:
  - 800
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 40.31747359663594
      - 50.79683366298238
    - - 64
      - 80.63494719327188
      - 101.59366732596476
    - - 128
      - 161.26989438654377
      - 203.18733465192952
    - - 256
      - 322.53978877308754
      - 406.37466930385904
    - - 512
      - 645.0795775461751
      - 812.7493386077181
  ATSS:
    BBOX_REG_WEIGHTS:
    - 10.0
    - 10.0
    - 5.0
    - 5.0
    CHANNELS: 256
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    INFERENCE_TH: 0.05
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_TH: 0.6
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    REG_LOSS_WEIGHT: 2.0
    TOPK: 9
    USE_GN: true
  BACKBONE:
    FREEZE_AT: -1
    NAME: build_retinanet_resnet_fpn_backbone
  DEVICE: cuda
  DYHEAD:
    CHANNELS: 256
    NUM_CONVS: 6
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res3
    - res4
    - res5
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: ConceptRetinaNet
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 601
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.0
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: FastRCNNConvFCHead
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 601
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SWINT:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.2
    EMBED_DIM: 96
    MLP_RATIO: 4
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - stage2
    - stage3
    - stage4
    - stage5
    OUT_NORM: true
    VERSION: 1
    WINDOW_SIZE: 7
  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl
OUTPUT_DIR: ./results/OID/retinanet/retinanet_r50_fpn_OID_concepts_cat/
SEED: 2022
SOLVER:
  AMP:
    ENABLED: false
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: false
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 90000
  MOMENTUM: 0.9
  NESTEROV: false
  OPTIMIZER: SGD
  REFERENCE_WORLD_SIZE: 0
  STEPS:
  - 60000
  - 80000
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[32m[10/19 17:58:56 detectron2]: [0mFull config saved to ./results/OID/retinanet/retinanet_r50_fpn_OID_concepts_cat/config.yaml
wandb: Currently logged in as: drigoni. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.13.4
wandb: Run data is saved locally in /ceph/hpc/scratch/user/eudavider/repository/DynamicHead/wandb/run-20221019_175859-27gqjrgk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-aardvark-354
wandb: ⭐️ View project at https://wandb.ai/drigoni/CATSS
wandb: 🚀 View run at https://wandb.ai/drigoni/CATSS/runs/27gqjrgk
Load concept for each category. 
Loading pre-trained concepts embeddings. 
Vocab initialization with 0/82115 elements not found. 
[32m[10/19 18:04:25 d2.engine.defaults]: [0mModel:
ConceptRetinaNet(
  (backbone): FPN(
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (head): RetinaNetHead(
    (cls_subnet): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (bbox_subnet): Sequential(
      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (3): ReLU()
      (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (5): ReLU()
      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (7): ReLU()
    )
    (cls_score): Conv2d(512, 5409, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (bbox_pred): Conv2d(512, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (anchor_generator): DefaultAnchorGenerator(
    (cell_anchors): BufferList()
  )
  (concept_net): ConceptNet(
    (concept_vocab): Vocab()
    (concept_emb): Embedding(82115, 150)
    (deepset): _DeepSets(
      (mlp1): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=150, out_features=150, bias=True)
          (1): Linear(in_features=150, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (mlp2): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
    )
  )
)
[32m[10/19 18:05:45 d2.data.datasets.coco]: [0mLoading datasets/OpenImagesDataset/annotations/openimages_v4_train_bbox.json takes 80.47 seconds.
[32m[10/19 18:05:54 d2.data.datasets.coco]: [0mLoaded 1743042 images in COCO format from datasets/OpenImagesDataset/annotations/openimages_v4_train_bbox.json
[32m[10/19 18:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1743042 images left.
[32m[10/19 18:08:06 d2.data.build]: [0mDistribution of instances among all 601 categories:
[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|   Tortoise    | 1998         |   Container   | 0            |    Magpie     | 145          |
|  Sea turtle   | 1132         |   Football    | 5097         |   Ambulance   | 447          |
|    Ladder     | 994          |  Toothbrush   | 219          |    Syringe    | 127          |
|     Sink      | 1648         |      Toy      | 70963        |     Organ     | 398          |
| Cassette deck | 74           |     Apple     | 3898         |   Human eye   | 77233        |
|   Cosmetics   | 2394         |    Paddle     | 6951         |    Snowman    | 770          |
|     Beer      | 9565         |  Chopsticks   | 617          |  Human beard  | 3157         |
|     Bird      | 47921        | Parking meter | 209          | Traffic light | 7426         |
|   Croissant   | 447          |   Cucumber    | 1194         |    Radish     | 688          |
|     Towel     | 338          |     Doll      | 6442         |     Skull     | 2661         |
| Washing mac.. | 655          |     Glove     | 1198         |     Tick      | 143          |
|     Belt      | 422          |  Sunglasses   | 23996        |     Banjo     | 264          |
|     Cart      | 2755         |     Ball      | 6845         |   Backpack    | 1216         |
|    Bicycle    | 40161        | Home applia.. | 2086         |   Centipede   | 280          |
|     Boat      | 79113        |   Surfboard   | 2594         |     Boot      | 3132         |
|  Headphones   | 1255         |    Hot dog    | 482          |    Shorts     | 16981        |
|   Fast food   | 24991        |      Bus      | 11927        |      Boy      | 87555        |
|  Screwdriver  | 85           | Bicycle wheel | 59521        |     Barge     | 983          |
|    Laptop     | 9327         |   Miniskirt   | 954          |     Drill     | 203          |
|     Dress     | 52999        |     Bear      | 427          |    Waffle     | 710          |
|    Pancake    | 775          |  Brown bear   | 647          |  Woodpecker   | 515          |
|   Blue jay    | 259          |    Pretzel    | 294          |     Bagel     | 640          |
|     Tower     | 67945        |    Teapot     | 632          |    Person     | 1034721      |
| Bow and arrow | 594          |   Swimwear    | 10079        |    Beehive    | 511          |
|   Brassiere   | 1694         |      Bee      | 11401        |      Bat      | 655          |
|   Starfish    | 639          |    Popcorn    | 362          |    Burrito    | 262          |
|   Chainsaw    | 130          |    Balloon    | 13505        |    Wrench     | 204          |
|     Tent      | 6907         | Vehicle reg.. | 7852         |    Lantern    | 5429         |
|    Toaster    | 73           |  Flashlight   | 88           |   Billboard   | 9823         |
|     Tiara     | 411          |   Limousine   | 366          |   Necklace    | 2735         |
|   Carnivore   | 3501         |   Scissors    | 399          |    Stairs     | 5981         |
| Computer ke.. | 4542         |    Printer    | 263          | Traffic sign  | 6112         |
|     Chair     | 132483       |     Shirt     | 7465         |    Poster     | 23566        |
|    Cheese     | 1560         |     Sock      | 1425         | Fire hydrant  | 432          |
| Land vehicle  | 81108        |   Earrings    | 1446         |      Tie      | 10545        |
|  Watercraft   | 5202         |   Cabinetry   | 9191         |   Suitcase    | 630          |
|    Muffin     | 4608         |     Bidet     | 440          |     Snack     | 37374        |
|  Snowmobile   | 366          |     Clock     | 1222         | Medical equ.. | 2060         |
|    Cattle     | 11603        |     Cello     | 2004         |    Jet ski    | 543          |
|     Camel     | 1340         |     Coat      | 6523         |     Suit      | 110848       |
|     Desk      | 11693        |      Cat      | 15183        | Bronze scul.. | 2748         |
|     Juice     | 2838         |    Gondola    | 1868         |    Beetle     | 3523         |
|    Cannon     | 1087         | Computer mo.. | 733          |    Cookie     | 4158         |
| Office buil.. | 4986         |   Fountain    | 3691         |     Coin      | 3042         |
|  Calculator   | 210          |   Cocktail    | 4458         | Computer mo.. | 6112         |
|      Box      | 5364         |    Stapler    | 59           | Christmas t.. | 4243         |
|  Cowboy hat   | 3068         | Hiking equi.. | 10505        | Studio couch  | 1889         |
|     Drum      | 24818        |    Dessert    | 27407        |   Wine rack   | 254          |
|     Drink     | 40323        |   Zucchini    | 1098         |     Ladle     | 54           |
|  Human mouth  | 44197        |     Dairy     | 8146         |     Dice      | 714          |
|     Oven      | 637          |   Dinosaur    | 1721         |    Ratchet    | 327          |
|     Couch     | 4259         | Cricket ball  | 132          | Winter melon  | 43           |
|    Spatula    | 64           |  Whiteboard   | 1003         | Pencil shar.. | 21           |
|     Door      | 19256        |      Hat      | 13245        |    Shower     | 235          |
|    Eraser     | 53           |    Fedora     | 3660         |   Guacamole   | 224          |
|    Dagger     | 370          |     Scarf     | 2303         |    Dolphin    | 1532         |
|   Sombrero    | 651          |    Tin can    | 2988         |      Mug      | 2272         |
|      Tap      | 1695         |  Harbor seal  | 2084         |   Stretcher   | 174          |
|  Can opener   | 7            |    Goggles    | 9636         |  Human body   | 175244       |
| Roller skates | 5476         |  Coffee cup   | 5327         | Cutting board | 213          |
|    Blender    | 235          | Plumbing fi.. | 481          |   Stop sign   | 394          |
| Office supp.. | 6198         |  Volleyball   | 661          |     Vase      | 2468         |
|  Slow cooker  | 125          |   Wardrobe    | 238          |    Coffee     | 2384         |
|     Whisk     | 180          |  Paper towel  | 210          | Personal care | 409          |
|     Food      | 88422        |    Sun hat    | 6979         |  Tree house   | 110          |
|  Flying disc  | 249          |     Skirt     | 1259         |   Gas stove   | 526          |
| Salt and pe.. | 180          | Mechanical .. | 681          |  Face powder  | 80           |
|      Fax      | 28           |     Fruit     | 26236        | French fries  | 2114         |
|  Nightstand   | 1125         |    Barrel     | 2086         |     Kite      | 1766         |
|     Tart      | 973          |   Treadmill   | 247          |      Fox      | 565          |
|     Flag      | 29246        |     Horn      | 1239         | Window blind  | 570          |
|  Human foot   | 2237         |   Golf cart   | 595          |    Jacket     | 25957        |
|      Egg      | 1865         | Street light  | 44697        |    Guitar     | 25896        |
|    Pillow     | 3508         |   Human leg   | 71479        |    Isopod     | 154          |
|     Grape     | 2787         |   Human ear   | 17774        | Power plugs.. | 290          |
|     Panda     | 882          |    Giraffe    | 1431         |     Woman     | 767337       |
|  Door handle  | 751          |  Rhinoceros   | 724          |    Bathtub    | 545          |
|   Goldfish    | 2204         |  Houseplant   | 22834        |     Goat      | 2075         |
| Baseball bat  | 1228         | Baseball gl.. | 2529         |  Mixing bowl  | 1005         |
| Marine inve.. | 9112         | Kitchen ute.. | 549          | Light switch  | 97           |
|     House     | 136152       |     Horse     | 13368        | Stationary .. | 338          |
|    Hammer     | 139          |  Ceiling fan  | 478          |   Sofa bed    | 1501         |
| Adhesive tape | 255          |     Harp      | 231          |    Sandal     | 2938         |
| Bicycle hel.. | 15952        |    Saucer     | 2819         |  Harpsichord  | 212          |
|  Human hair   | 234057       |    Heater     | 35           |   Harmonica   | 38           |
|    Hamster    | 546          |    Curtain    | 4872         |      Bed      | 3563         |
|    Kettle     | 657          |   Fireplace   | 711          |     Scale     | 139          |
| Drinking st.. | 292          |    Insect     | 8981         |  Hair dryer   | 27           |
|  Kitchenware  | 0            | Indoor rower  | 35           | Invertebrate  | 1568         |
| Food proces.. | 192          |   Bookcase    | 5307         | Refrigerator  | 592          |
| Wood-burnin.. | 300          | Punching bag  | 336          |  Common fig   | 317          |
| Cocktail sh.. | 27           |    Jaguar     | 586          |   Golf ball   | 434          |
| Fashion acc.. | 91024        |  Alarm clock  | 169          | Filing cabi.. | 374          |
|   Artichoke   | 376          |     Table     | 85691        |   Tableware   | 41086        |
|   Kangaroo    | 778          |     Koala     | 418          |     Knife     | 850          |
|    Bottle     | 40188        | Bottle opener | 21           |     Lynx      | 237          |
|   Lavender    | 6472         |  Lighthouse   | 1518         |   Dumbbell    | 413          |
|  Human head   | 201633       |     Bowl      | 4507         |  Humidifier   | 11           |
|     Porch     | 3854         |    Lizard     | 2120         | Billiard ta.. | 912          |
|    Mammal     | 156154       |     Mouse     | 857          |  Motorcycle   | 13382        |
| Musical ins.. | 16503        |   Swim cap    | 615          |  Frying pan   | 377          |
|   Snowplow    | 300          | Bathroom ca.. | 358          |    Missile    | 603          |
|     Bust      | 1060         |      Man      | 1418594      |  Waffle iron  | 31           |
|     Milk      | 214          |  Ring binder  | 84           |     Plate     | 5416         |
| Mobile phone  | 6365         |  Baked goods  | 23010        |   Mushroom    | 4497         |
|    Crutch     | 150          |    Pitcher    | 347          |    Mirror     | 1572         |
|  Lifejacket   | 3678         | Table tenni.. | 849          |  Pencil case  | 132          |
| Musical key.. | 1771         |  Scoreboard   | 517          |   Briefcase   | 162          |
| Kitchen knife | 350          |     Nail      | 491          |  Tennis ball  | 502          |
|  Plastic bag  | 986          |     Oboe      | 162          | Chest of dr.. | 1526         |
|    Ostrich    | 640          |     Piano     | 1374         |     Girl      | 197155       |
|     Plant     | 267913       |    Potato     | 599          |  Hair spray   | 10           |
| Sports equi.. | 44900        |     Pasta     | 769          |    Penguin    | 4197         |
|    Pumpkin    | 6150         |     Pear      | 923          |  Infant bed   | 462          |
|  Polar bear   | 664          |     Mixer     | 216          |   Cupboard    | 1353         |
|    Jacuzzi    | 103          |     Pizza     | 2008         | Digital clock | 199          |
|      Pig      | 1613         |    Reptile    | 578          |     Rifle     | 2540         |
|   Lipstick    | 1343         |  Skateboard   | 1810         |     Raven     | 567          |
|  High heels   | 3124         |   Red panda   | 423          |     Rose      | 12053        |
|    Rabbit     | 1641         |   Sculpture   | 34533        |   Saxophone   | 1208         |
|    Shotgun    | 580          |    Seafood    | 3063         | Submarine s.. | 273          |
|   Snowboard   | 944          |     Sword     | 567          | Picture frame | 11957        |
|     Sushi     | 2088         |   Loveseat    | 631          |      Ski      | 3505         |
|   Squirrel    | 1940         |    Tripod     | 1446         |  Stethoscope  | 78           |
|   Submarine   | 81           |   Scorpion    | 204          |    Segway     | 565          |
| Training be.. | 194          |     Snake     | 1378         | Coffee table  | 5314         |
|  Skyscraper   | 81261        |     Sheep     | 3438         |  Television   | 3789         |
|   Trombone    | 953          |      Tea      | 1342         |     Tank      | 1716         |
|     Taco      | 677          |   Telephone   | 274          |     Torch     | 20           |
|     Tiger     | 1260         |  Strawberry   | 7944         |    Trumpet    | 1546         |
|     Tree      | 1051344      |    Tomato     | 6254         |     Train     | 13050        |
|     Tool      | 2075         | Picnic basket | 425          | Cooking spray | 45           |
|   Trousers    | 8481         | Bowling equ.. | 3846         | Football he.. | 11705        |
|     Truck     | 12135        | Measuring cup | 74           |  Coffeemaker  | 323          |
|    Violin     | 2828         |    Vehicle    | 50959        |    Handbag    | 2495         |
| Paper cutter  | 4            |     Wine      | 15400        |    Weapon     | 2960         |
|     Wheel     | 340639       |     Worm      | 270          |      Wok      | 730          |
|     Whale     | 1014         |     Zebra     | 1120         |   Auto part   | 13586        |
|      Jug      | 590          | Pizza cutter  | 20           |     Cream     | 123          |
|    Monkey     | 3026         |     Lion      | 1653         |     Bread     | 3846         |
|    Platter    | 3462         |    Chicken    | 3059         |     Eagle     | 1704         |
|  Helicopter   | 3023         |      Owl      | 1663         |     Duck      | 15451        |
|    Turtle     | 205          | Hippopotamus  | 685          |   Crocodile   | 1069         |
|    Toilet     | 1099         | Toilet paper  | 377          |     Squid     | 221          |
|   Clothing    | 1438128      |   Footwear    | 744474       |     Lemon     | 1756         |
|    Spider     | 2033         |     Deer      | 3867         |     Frog      | 1608         |
|    Banana     | 1612         |    Rocket     | 918          |  Wine glass   | 12934        |
|  Countertop   | 3113         | Tablet comp.. | 975          | Waste conta.. | 1807         |
| Swimming pool | 3881         |      Dog      | 28675        |     Book      | 41280        |
|   Elephant    | 3272         |     Shark     | 625          |    Candle     | 5886         |
|    Leopard    | 811          |      Axe      | 148          |  Hand dryer   | 70           |
| Soap dispen.. | 78           |   Porcupine   | 229          |    Flower     | 345296       |
|    Canary     | 387          |    Cheetah    | 715          |   Palm tree   | 42026        |
|   Hamburger   | 1486         |     Maple     | 4923         |   Building    | 178634       |
|     Fish      | 23195        |    Lobster    | 597          |   Asparagus   | 387          |
|   Furniture   | 38527        |   Hedgehog    | 261          |   Airplane    | 21285        |
|     Spoon     | 1709         |     Otter     | 752          |     Bull      | 1736         |
|    Oyster     | 1038         | Horizontal .. | 75           | Convenience.. | 1817         |
|     Bomb      | 8            |     Bench     | 7229         |   Ice cream   | 2834         |
|  Caterpillar  | 884          |   Butterfly   | 10127        |   Parachute   | 2672         |
|    Orange     | 6195         |   Antelope    | 1568         |    Beaker     | 168          |
| Moths and b.. | 1857         |    Window     | 503467       |    Closet     | 661          |
|    Castle     | 4310         |   Jellyfish   | 2064         |     Goose     | 8436         |
|     Mule      | 1117         |     Swan      | 4523         |     Peach     | 756          |
|    Coconut    | 874          |   Seat belt   | 461          |    Raccoon    | 381          |
|    Chisel     | 33           |     Fork      | 1687         |     Lamp      | 3663         |
|    Camera     | 6404         |    Squash     | 375          |    Racket     | 281          |
|  Human face   | 1037710      |   Human arm   | 208982       |   Vegetable   | 18621        |
|    Diaper     | 152          |   Unicycle    | 194          |    Falcon     | 1717         |
|     Chime     | 41           |     Snail     | 943          |   Shellfish   | 1287         |
|    Cabbage    | 435          |    Carrot     | 1456         |     Mango     | 429          |
|     Jeans     | 78473        |   Flowerpot   | 22760        |   Pineapple   | 660          |
|    Drawer     | 4414         |     Stool     | 1254         |   Envelope    | 177          |
|     Cake      | 5784         |   Dragonfly   | 1490         |   Sunflower   | 6815         |
| Microwave o.. | 485          |   Honeycomb   | 383          | Marine mammal | 1746         |
|   Sea lion    | 1823         |    Ladybug    | 734          |     Shelf     | 22899        |
|     Watch     | 1903         |     Candy     | 2261         |     Salad     | 3088         |
|    Parrot     | 2388         |    Handgun    | 727          |    Sparrow    | 1651         |
|      Van      | 7720         |    Grinder    | 14           |  Spice rack   | 131          |
|  Light bulb   | 1816         | Corded phone  | 433          | Sports unif.. | 19396        |
| Tennis racket | 985          |  Wall clock   | 1067         | Serving tray  | 118          |
| Kitchen & d.. | 2127         |    Dog bed    | 266          |  Cake stand   | 337          |
| Cat furniture | 208          | Bathroom ac.. | 2678         | Facial tiss.. | 20           |
| Pressure co.. | 14           | Kitchen app.. | 4662         |     Tire      | 122615       |
|     Ruler     | 253          | Luggage and.. | 2220         |  Microphone   | 27272        |
|   Broccoli    | 1128         |   Umbrella    | 7204         |    Pastry     | 5852         |
|  Grapefruit   | 1283         |   Band-aid    | 36           |    Animal     | 17442        |
|  Bell pepper  | 802          |    Turkey     | 734          |     Lily      | 2252         |
|  Pomegranate  | 677          |   Doughnut    | 930          |    Glasses    | 57946        |
|  Human nose   | 60142        |      Pen      | 1705         |      Ant      | 925          |
|      Car      | 248075       |   Aircraft    | 1898         |  Human hand   | 75307        |
|     Skunk     | 56           |  Teddy bear   | 1587         |  Watermelon   | 844          |
|  Cantaloupe   | 166          |  Dishwasher   | 92           |     Flute     | 362          |
| Balance beam  | 326          |   Sandwich    | 1157         |    Shrimp     | 1856         |
| Sewing mach.. | 453          |  Binoculars   | 123          | Rays and sk.. | 485          |
|     Ipod      | 595          |   Accordion   | 955          |    Willow     | 735          |
|     Crab      | 1041         |     Crown     | 687          |   Seahorse    | 314          |
|    Perfume    | 363          |    Alpaca     | 829          |     Taxi      | 4199         |
|     Canoe     | 4543         | Remote cont.. | 236          |  Wheelchair   | 1464         |
|  Rugby ball   | 294          |   Armadillo   | 56           |    Maracas    | 10           |
|    Helmet     | 16502        |               |              |               |              |
|     total     | 14610229     |               |              |               |              |[0m
[32m[10/19 18:08:06 d2.data.common]: [0mSerializing 1743042 elements to byte tensors and concatenating them all ...
[32m[10/19 18:08:25 d2.data.common]: [0mSerialized dataset takes 1195.87 MiB
[32m[10/19 18:08:31 fvcore.common.checkpoint]: [0m[Checkpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[32m[10/19 18:08:31 d2.checkpoint.c2_model_loading]: [0mRenaming Caffe2 weights ......
[32m[10/19 18:08:31 d2.checkpoint.c2_model_loading]: [0mFollowing weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[5m[31mWARNING[0m [32m[10/19 18:09:35 fvcore.common.checkpoint]: [0mSome model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mconcept_net.concept_emb.weight[0m
[34mconcept_net.deepset.mlp1.layers.0.{bias, weight}[0m
[34mconcept_net.deepset.mlp1.layers.1.{bias, weight}[0m
[34mconcept_net.deepset.mlp1.layers.2.{bias, weight}[0m
[34mconcept_net.deepset.mlp2.layers.0.{bias, weight}[0m
[34mconcept_net.deepset.mlp2.layers.1.{bias, weight}[0m
[34mconcept_net.deepset.mlp2.layers.2.{bias, weight}[0m
[34mhead.bbox_pred.{bias, weight}[0m
[34mhead.bbox_subnet.0.{bias, weight}[0m
[34mhead.bbox_subnet.2.{bias, weight}[0m
[34mhead.bbox_subnet.4.{bias, weight}[0m
[34mhead.bbox_subnet.6.{bias, weight}[0m
[34mhead.cls_score.{bias, weight}[0m
[34mhead.cls_subnet.0.{bias, weight}[0m
[34mhead.cls_subnet.2.{bias, weight}[0m
[34mhead.cls_subnet.4.{bias, weight}[0m
[34mhead.cls_subnet.6.{bias, weight}[0m
[5m[31mWARNING[0m [32m[10/19 18:09:35 fvcore.common.checkpoint]: [0mThe checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[32m[10/19 18:09:35 d2.engine.train_loop]: [0mStarting training from iteration 0
Load concept for each category. 
Loading pre-trained concepts embeddings. 
Vocab initialization with 0/82115 elements not found. 
Load concept for each category. 
Loading pre-trained concepts embeddings. 
Vocab initialization with 0/82115 elements not found. 
Load concept for each category. 
Loading pre-trained concepts embeddings. 
Vocab initialization with 0/82115 elements not found. 
/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  max_size = (max_size + (stride - 1)) // stride * stride
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272164809/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[W reducer.cpp:1303] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  max_size = (max_size + (stride - 1)) // stride * stride
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272164809/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[W reducer.cpp:1303] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  max_size = (max_size + (stride - 1)) // stride * stride
/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  max_size = (max_size + (stride - 1)) // stride * stride
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272164809/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[W reducer.cpp:1303] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272164809/work/aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[W reducer.cpp:1303] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[32m[10/19 18:12:32 d2.utils.events]: [0m eta: 1 day, 10:58:39  iter: 19  total_loss: 3.228  loss_cls: 2.335  loss_box_reg: 0.907  time: 1.4816  data_time: 7.3603  lr: 0.00019981  max_mem: 34034M
[32m[10/19 18:12:53 d2.utils.events]: [0m eta: 1 day, 5:30:16  iter: 39  total_loss: 2.494  loss_cls: 1.787  loss_box_reg: 0.6978  time: 1.2492  data_time: 0.0193  lr: 0.00039961  max_mem: 34034M
[32m[10/19 18:13:14 d2.utils.events]: [0m eta: 1 day, 2:00:15  iter: 59  total_loss: 2.109  loss_cls: 1.567  loss_box_reg: 0.5425  time: 1.1749  data_time: 0.0157  lr: 0.00059941  max_mem: 34034M
[32m[10/19 18:13:36 d2.utils.events]: [0m eta: 1 day, 2:00:31  iter: 79  total_loss: 2.426  loss_cls: 1.801  loss_box_reg: 0.6457  time: 1.1500  data_time: 0.0280  lr: 0.00079921  max_mem: 34039M
[32m[10/19 18:13:57 d2.utils.events]: [0m eta: 1 day, 1:52:39  iter: 99  total_loss: 2.25  loss_cls: 1.657  loss_box_reg: 0.6115  time: 1.1226  data_time: 0.0155  lr: 0.00099901  max_mem: 34039M
[32m[10/19 18:14:17 d2.utils.events]: [0m eta: 1 day, 1:37:27  iter: 119  total_loss: 2.422  loss_cls: 1.77  loss_box_reg: 0.6521  time: 1.1015  data_time: 0.0174  lr: 0.0011988  max_mem: 34039M
[32m[10/19 18:14:37 d2.utils.events]: [0m eta: 1 day, 1:37:07  iter: 139  total_loss: 2.283  loss_cls: 1.659  loss_box_reg: 0.6098  time: 1.0887  data_time: 0.0191  lr: 0.0013986  max_mem: 34039M
[32m[10/19 18:14:58 d2.utils.events]: [0m eta: 1 day, 1:39:23  iter: 159  total_loss: 2.171  loss_cls: 1.587  loss_box_reg: 0.5844  time: 1.0809  data_time: 0.0148  lr: 0.0015984  max_mem: 34039M
[32m[10/19 18:15:18 d2.utils.events]: [0m eta: 1 day, 1:34:37  iter: 179  total_loss: 2.253  loss_cls: 1.613  loss_box_reg: 0.6409  time: 1.0730  data_time: 0.0153  lr: 0.0017982  max_mem: 34040M
[32m[10/19 18:15:39 d2.utils.events]: [0m eta: 1 day, 1:34:16  iter: 199  total_loss: 2.134  loss_cls: 1.556  loss_box_reg: 0.6004  time: 1.0669  data_time: 0.0197  lr: 0.001998  max_mem: 34040M
[32m[10/19 18:15:59 d2.utils.events]: [0m eta: 1 day, 1:31:55  iter: 219  total_loss: 2.115  loss_cls: 1.538  loss_box_reg: 0.6154  time: 1.0612  data_time: 0.0104  lr: 0.0021978  max_mem: 34040M
[32m[10/19 18:16:20 d2.utils.events]: [0m eta: 1 day, 1:31:35  iter: 239  total_loss: 1.907  loss_cls: 1.32  loss_box_reg: 0.5698  time: 1.0572  data_time: 0.0126  lr: 0.0023976  max_mem: 34040M
[32m[10/19 18:16:40 d2.utils.events]: [0m eta: 1 day, 1:31:14  iter: 259  total_loss: 1.823  loss_cls: 1.245  loss_box_reg: 0.5963  time: 1.0547  data_time: 0.0161  lr: 0.0025974  max_mem: 34040M
[32m[10/19 18:17:01 d2.utils.events]: [0m eta: 1 day, 1:27:18  iter: 279  total_loss: 1.962  loss_cls: 1.324  loss_box_reg: 0.6508  time: 1.0515  data_time: 0.0163  lr: 0.0027972  max_mem: 34040M
[32m[10/19 18:17:21 d2.utils.events]: [0m eta: 1 day, 1:27:46  iter: 299  total_loss: 1.988  loss_cls: 1.348  loss_box_reg: 0.5752  time: 1.0496  data_time: 0.0155  lr: 0.002997  max_mem: 34040M
[32m[10/19 18:17:42 d2.utils.events]: [0m eta: 1 day, 1:32:23  iter: 319  total_loss: 2.118  loss_cls: 1.43  loss_box_reg: 0.6453  time: 1.0494  data_time: 0.0115  lr: 0.0031968  max_mem: 34040M
[32m[10/19 18:18:03 d2.utils.events]: [0m eta: 1 day, 1:28:34  iter: 339  total_loss: 1.795  loss_cls: 1.255  loss_box_reg: 0.5909  time: 1.0475  data_time: 0.0145  lr: 0.0033966  max_mem: 34040M
[32m[10/19 18:18:24 d2.utils.events]: [0m eta: 1 day, 1:30:47  iter: 359  total_loss: 1.971  loss_cls: 1.32  loss_box_reg: 0.6176  time: 1.0476  data_time: 0.0150  lr: 0.0035964  max_mem: 34040M
[32m[10/19 18:18:45 d2.utils.events]: [0m eta: 1 day, 1:30:27  iter: 379  total_loss: 1.943  loss_cls: 1.34  loss_box_reg: 0.6157  time: 1.0464  data_time: 0.0189  lr: 0.0037962  max_mem: 34040M
[32m[10/19 18:19:06 d2.utils.events]: [0m eta: 1 day, 1:32:29  iter: 399  total_loss: 1.939  loss_cls: 1.276  loss_box_reg: 0.6624  time: 1.0457  data_time: 0.0136  lr: 0.003996  max_mem: 34040M
[32m[10/19 18:19:26 d2.utils.events]: [0m eta: 1 day, 1:32:09  iter: 419  total_loss: 2.537  loss_cls: 1.676  loss_box_reg: 0.8544  time: 1.0443  data_time: 0.0161  lr: 0.0041958  max_mem: 34040M
[4m[5m[31mERROR[0m [32m[10/19 18:19:32 d2.engine.train_loop]: [0mException during training:
Traceback (most recent call last):
  File "/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/engine/train_loop.py", line 287, in run_step
    self._write_metrics(loss_dict, data_time)
  File "/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/engine/train_loop.py", line 302, in _write_metrics
    SimpleTrainer.write_metrics(loss_dict, data_time, prefix)
  File "/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/engine/train_loop.py", line 338, in write_metrics
    raise FloatingPointError(
FloatingPointError: Loss became infinite or NaN at iteration=424!
loss_dict = {'loss_cls': nan, 'loss_box_reg': inf}
[32m[10/19 18:19:32 d2.engine.hooks]: [0mOverall training speed: 422 iterations in 0:07:21 (1.0466 s / it)
[32m[10/19 18:19:32 d2.engine.hooks]: [0mTotal training time: 0:07:26 (0:00:05 on hooks)
[32m[10/19 18:19:32 d2.utils.events]: [0m eta: 1 day, 1:32:04  iter: 424  total_loss: 2.917  loss_cls: 1.743  loss_box_reg: 0.9763  time: 1.0439  data_time: 0.0152  lr: 0.0042358  max_mem: 34040M
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: 
wandb: Run history:
wandb:       data_time ▁▄▄█▃▃▃▂▃▃▂▂▃▃▂▂▃▂▃▃▂▂
wandb:     eta_seconds █▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     global_step ▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▇▇▇███
wandb:    loss_box_reg ▇▄▁▃▂▃▂▂▃▂▂▁▂▃▂▃▂▂▂▃▆█
wandb:        loss_cls █▄▃▅▄▄▄▃▃▃▃▁▁▂▂▂▁▁▂▁▄▄
wandb:              lr ▁▁▂▂▂▃▃▃▄▄▄▅▅▆▆▆▇▇▇███
wandb: num_pos_anchors ▅▄▂▆▂▃▃▆▂▂▆▃▃█▁▄▂▇▂▆▄▁
wandb:            time █▁▁▂▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▂▁▂
wandb:      total_loss █▄▃▄▃▄▃▃▃▃▃▂▁▂▂▃▁▂▂▂▅▆
wandb: 
wandb: Run summary:
wandb:       data_time 0.00816
wandb:     eta_seconds 91924.15625
wandb:     global_step 424
wandb:    loss_box_reg 0.97629
wandb:        loss_cls 1.74282
wandb:              lr 0.00424
wandb: num_pos_anchors 89.125
wandb:            time 1.03324
wandb:      total_loss 2.91672
wandb: 
wandb: Synced trim-aardvark-354: https://wandb.ai/drigoni/CATSS/runs/27gqjrgk
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)
wandb: Find logs at: ./wandb/run-20221019_175859-27gqjrgk/logs
Traceback (most recent call last):
  File "/ceph/hpc/scratch/user/eudavider/repository/DynamicHead/train_net.py", line 344, in <module>
    launch(
  File "/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/engine/launch.py", line 67, in launch
    mp.spawn(
  File "/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 230, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 150, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/ceph/hpc/home/eudavider/.conda/envs/dynamicHead/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 59, in _wrap
    fn(i, *args)
  File "/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/engine/launch.py", line 126, in _distributed_worker
    main_func(*args)
  File "/ceph/hpc/scratch/user/eudavider/repository/DynamicHead/train_net.py", line 334, in main
    return trainer.train()
  File "/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/engine/defaults.py", line 484, in train
    super().train(self.start_iter, self.max_iter)
  File "/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/engine/train_loop.py", line 149, in train
    self.run_step()
  File "/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/engine/defaults.py", line 494, in run_step
    self._trainer.run_step()
  File "/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/engine/train_loop.py", line 287, in run_step
    self._write_metrics(loss_dict, data_time)
  File "/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/engine/train_loop.py", line 302, in _write_metrics
    SimpleTrainer.write_metrics(loss_dict, data_time, prefix)
  File "/ceph/hpc/home/eudavider/.local/lib/python3.9/site-packages/detectron2/engine/train_loop.py", line 338, in write_metrics
    raise FloatingPointError(
FloatingPointError: Loss became infinite or NaN at iteration=424!
loss_dict = {'loss_cls': nan, 'loss_box_reg': inf}

srun: error: gn21: task 0: Exited with exit code 1


Job done.
Date:  mer 19 ott 2022, 18.21.06, CEST
